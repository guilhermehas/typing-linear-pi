\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{enumitem}
\setlist{parsep=0pt,listparindent=\parindent}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage{mathtools}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Typing a linear \picalc}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi calculus, linear, types, concurrency}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{We want to thank Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Processes
\newcommand{\PO}{\mathbf{0}}
\newcommand{\comp}[2]{#1 \parallel #2}
\newcommand{\new}{\boldsymbol{\nu} \,}
\newcommand{\send}[2]{#1 \, \langle#2\rangle \,}
\newcommand{\recv}[1]{#1 \, \mathbb{()} \,}

\newcommand{\subst}[3]{#1[#2/#3]}
\newcommand{\lamcalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\reduce}{\longrightarrow}
\newcommand{\types}[4]{#1 \propto #2 \vdash #3 \boxtimes #4}
\newcommand{\contains}[5]{#1 \propto #2 \ni #3 \propto #4 \boxtimes #5}
\newcommand{\suc}{{\scriptscriptstyle 1+}}
\newcommand{\op}[3]{#1 \coloneqq #2 \cdot #3}

% Types
\newcommand{\Var}{\mathrm{VAR}}
\newcommand{\Process}{\mathrm{PROCESS}}
\newcommand{\Unused}{\mathrm{UNUSED}}
\newcommand{\PreCtx}{\mathrm{PRECTX}}
\newcommand{\Ctx}{\mathrm{CTX}}
\newcommand{\Type}{\mathrm{TYPE}\;}
\newcommand{\Idx}{\mathrm{IDX}\;}
\newcommand{\Idxs}{\mathrm{IDXS}}
\newcommand{\Carrier}{\mathrm{CARRIER}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Channel}{\mathrm{CHANNEL}}
\newcommand{\Rec}{\mathrm{REC}}
\newcommand{\Quantifier}{\mathrm{QUANTIFIER}}
\newcommand{\Quantifiers}{\mathrm{QUANTIFIERS}}
\newcommand{\constr}[1]{\mathtt{#1}}


\begin{document}

\maketitle
\todo{remove todo notes}

\begin{abstract}
  We present the syntax, operational semantics, and typing rules of a \picalc{} with linear and shared types.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalize the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, affine, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  This formalization has been fully mechanized with Agda and is available at \url{https://github.com/umazalakain/typing-linear-pi}.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

We live in a concurrent world where any given state is often decided by the interaction between a myriad of parties --- people, machines, processors, services, networks.
As humans, we aim to model, predict, and even construct such interactive systems.
As mathematicians, abstraction is our tool of choice to do so.

The \picalc models communication.

The properties guaranteed by the picalc

why resource-aware typing

extensional typing rules for a given syntax and operational semantics

leftover typing

\subsection{Contribution}

\begin{description}
  \item [Machine verified formalisation of the linear pi calculus]

  \item [Typing with leftovers applied to the pi calculus]

  \item [Abstraction over multiplicities]

  \item [Full formalisation available in Agda]
\end{description}

\subsection{Notation}

\begin{figure}[h]
  \begin{mathpar}
    {\mprset{fraction={===}}
      \inferrule
      { }
      {\N : Set}}

    \inferrule
    { }
    {0 : \N}

    \inferrule
    {n : \N}
    {\suc n : \N}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Double rule for type-level definitions.
We omit universe levels for brevity.
Constructors are $\constr{teletyped}$ unless they are symbols.
Some constructors are shared across types. They can however always be disambiguated through the type of the goal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}

Abstraction is one of the key reasoning tools in a language: it allows for features to be defined over a range of inputs.
Such is the case of the \picalc{} too, where both scope restriction and input introduce abstractions.
The bodies of these constructs must have a way of referring to their argument.
Using names as variable references is a popular option amongst humans.
However, names are cumbersome to mechanize: inserting a new variable into an environment means proving that the name of such variable is different to all other variable names in the environment.
Moreover, to a machine names are of no significance whatsoever.

Machines prefer things they can algorithmically act upon. Like natural numbers!
What does it mean to use a number as a variable reference?
The idea de Bruijn had \cite{} was to use the index $n$ to refer to the variable introduced $n$ binders ago.
The binders themselves introduce no names anymore.
The expression $\lambda g . (\lambda f . f g) g$ in the \lamcalc{} would translate as $\lambda (\lambda 0 1) 0$.
That is, terms at different \emph{depths} must use different indices to refer to the same binding.
Humans find this often confusing.
There is however no reason not to keep the original names bestowed by the humans together with the indices.
Machines can then manipulate references mechanically and still use names to present them to humans.

A variable occurring under $n$ abstractions has $n$ things to refer to.
References outside of that range have no associated meaning.
It is useful to rule out these nonsensical terms syntactically.
In Figure \ref{var} we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Var_n : Set}}

  \inferrule
  {n : \N}
  {0 : \Var_{\suc n}}

  \inferrule
  {x : \Var_n}
  {\suc x : \Var_{\suc n}}
\end{mathpar}
\caption{Types of size $n$}
\label{var}
\end{figure}

Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
As shown in Figure \ref{process}, we increase the \emph{depth} counter every time we create a new channel or receive some input.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Process_n : Set}}
\end{mathpar}
  
\begin{equation*} \label{pi-calc-syntax}
\begin{split}
  \Process_n ::=& \; \PO_n                    \\
              |& \; \new{} \Process_{\suc n}          \\
              |& \; \comp{\Process_n}{\Process_n}          \\
              |& \; \recv{\Var_n}{}\Process_{\suc n} \\
              |& \; \send{\Var_n}{\Var_n}\Process_n
\end{split}
\end{equation*}
\caption{Well-scoped grammar using de Bruijn indices}
\label{process}
\end{figure}

Unlike with names, using type-level de Bruijn indices makes our syntax well-scoped by construction.
As a consequence, the semantics of our language can be defined on the totality of the syntax.
User-friendliness can still be recovered through a function that converts processes with names into (possibly) processes with indices.
This function would keep track of what index is associated with what name, and would traverse the process recursively, taking note of new binders and substituting variable references.
If the process is ill-scoped, the function would return nothing.
To print things back to the user names can be substituted with an index together with the name.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}

In the \lamcalc{} $\beta$-reduction operates on syntactically adjacent terms.
In the \picalc{} however, the syntax introduces unnecessary distinctions
(e.g. semantically parallel composition is defined modulo associativity and commutativity).
There are several ways around this, a structural congruence relation being one of the historical ones.
(Others include labeled transition systems and higher inductive types.)

\subsection{Structural Congruence}

Structural congruence is a congruent equivalence relation on processes.
Any two structurally congruent processes are strongly bisimilar: they are can follow each other's reduction steps \cite{}.
Figure \ref{struct-cong-base} lists the base cases of structural congruence.
The type $\Unused_0 \; Q$ witnesses that index $0$ does not appear nor in the inputs nor in the outputs of process $Q$ --- it does so by traversing $Q$.
The function $lower \; 0 \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $0$.
Finally, $swap \; 0 \; P$ traverses $P$ (scoped under $\suc \suc n$) and swaps variable references $0$ and $\suc 0$.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    { }
    {P \equiv Q : Set}}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{\comp{Q}{R}} \equiv \comp{\comp{P}{Q}}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \equiv \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \equiv P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \equiv \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \, Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \equiv \comp{(\new P)}{lower \; 0 \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \equiv \new \new swap \; 0 \; P}
\end{mathpar}
\caption{Structural rewriting rules. Premises $P$, $Q$ and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong-base}
\end{figure}

Structural congruence is a congruent equivalence relation.
As such, rewrites can happen at any point in a process' recursive definition, and they are closed under reflexivity, symmetry and transitivity as shown in Figure \ref{struct-cong}.
In \S \ref{subject-congruence} we will prove that if two processes $P$ and $Q$ are structurally congruent and $P$ is well-typed, then $Q$ is well-typed.
Specifically, in the case of transitivity we must prove that if $P$ is structurally congruent with $Q$ and $Q$ with $R$, and $P$ is well-typed, then so is $R$.
To do so, we will have to proceed by induction and first get a proof of the well-typedness of $Q$, then use that to reach $R$.
To show that the doubly recursive call terminates we index the equivalence relation $=$ by the type $\Rec$, which models the structure of the recursion.

\begin{figure}[h]
\begin{mathpar}
  \mprset{flushleft}
  
  {\mprset{fraction={===}}
    \inferrule
    { }
    {\Rec : Set}}

  \inferrule
  { }
  {\constr{zero} : \Rec}
  
  \inferrule
  {r : \Rec}
  {\constr{one} \; r : \Rec}

  \inferrule
  {r \; s : \Rec}
  {\constr{two} \; r \; s : \Rec}
  
  {\mprset{fraction={===}}
    \inferrule
    {P \, Q : \Process_n \\ r : \Rec}
    {P =_r Q : Set}}

  \inferrule
  {eq : P \equiv Q}
  {\constr{struct} \; eq : P =_{\constr{zero}} Q}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-scope} \; eq : \new P =_{\constr{one} \; r} \new P'}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-comp} \; eq : \comp{P}{Q} =_{\constr{one} \; r} \comp{P'}{Q}}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-recv} \; eq : \recv{x}P =_{\constr{one} \; r} \recv{x}P'}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-send} \; eq : \send{x}{y}P =_{\constr{one} \; r} \send{x}{y}P'}

  \inferrule
  { }
  {\constr{refl} : P =_{\constr{zero}} P}

  \inferrule
  {eq : P =_r Q}
  {\constr{sym} \; eq : Q =_{\constr{one} \; r} P}

  \inferrule
  {eq_1 : P =_r Q \\ \; eq_2 : Q =_s R}
  {\constr{trans} \; eq_1 \; eq_2 : P =_{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.
  Premises $P$, $P'$, $Q$, and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong}
\end{figure}
  
\subsection{Operational Semantics}

Figure \ref{reduction} models the operational semantics of the \picalc{}.
Processes put in parallel reduce when they communicate over a common variable.
The receiving process substitutes references to its most immediate variable with references to the variable sent by the process doing the output, and is then \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under structural congruence and goes under parallel composition and scope restriction
--- but notably not under input nor output, otherwise the sequencing of actions would not be preserved.
In \S \ref{subject-reduction} we prove that if $P$ reduces to $Q$ and $P$ is well-typed, so is $Q$.
However, this reduction operation is effectful: it consumes the variable over which communication happens.
If this variable is external to $P$ (it resides in its context) then the context in which $Q$ is typed must change.
To keep track of this information, we lift the variable index over which communication occurs to the type level.
Every time we come out of a binder we decrement this variable.
To do so, we make use of a $dec$ function that saturates at $\constr{internal}$ --- as opposed to an $inc$ function that would not.


\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Channel_n : Set}}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  {\mprset{fraction={===}}
    \inferrule
    {i : \Channel_n \\ P \; Q : \Process_n}
    {P \reduce_i Q : Set}}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n \\ uP : \Unused_0 \, P}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce_{external \; i} \comp{lower \; 0 \; \subst{P}{j}{0} \; uP}{Q}}

  \inferrule
  {red : P \reduce_i P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce_i \comp{P'}{Q}}

  \inferrule
  {red : P \reduce_i Q}
  {\constr{res} \; red : \new P \reduce_{dec\; i} \new Q}

  \inferrule
  {eq : P = P' \\ red : P' \reduce_i Q}
  {\constr{struct} \; eq \; red : P \reduce_i Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}

A type system is in the business of further constraining a language, filtering out terms that (although well-formed) are meaningless.
In the simply typed \lamcalc{}, a term has a meaning iff it has a type.
This typing judgment is a proof of the form $\Gamma \vdash t : T$, where the term $t$ has type $T$ under the typing context $\Gamma$ -- the typing context associates variables (possibly occurring within $t$) to types.
In the simply typed \picalc{} however, it is the channels that are typed, and a process has a meaning iff it \emph{uses} its channels according to their types.
The typing judgment is therefore of the form $\Gamma \vdash p$, where the process $p$ (which has no type of its own) uses the channels in $\Gamma$ according to their types.

A resource-aware type system uses both types and usage counting to constraint a language.
It uses typing contexts to keep track of both types and usage counts.
In the case of a linear type system, resources must be used exactly once, and usages transition from available to consumed as soon as they are used.
In the linear \picalc{} however, every channel must be used exactly once to receive and exactly once to send.
In \S \ref{multiplicities}, we generalize this usage counting algebra so that the same type system can be used for a combination of linear, shared, gradual and affine types.


Syntax directed
Continuations.
\ref{leftover-typing}

\subsection{Multiplicities}\label{multiplicities}

In its usual representation, the linear \picalc{} distinguishes between \emph{capabilities} -- $\ell_{\o}$ for cannot send or receive, $\ell_i$ for input, $\ell_o$ for output, and $\ell_\#$ for both input and output -- and multiplicities -- $0$ or $1$.
This introduces unnecessary semantic duplication: the semantic meaning of a multiplicity of $0$ on a capability $c$ is independent of $c$; a multiplicity of 1 $\ell_\#$ is equivalent to a multiplicity of 1 $\ell_i$ and 1 $\ell_o$.
In this paper, we merge multiplicities and capabilities into a single set and provide an algebra that generalizes the rules of the linear \picalc{} into rules that are suitable for shared, linear, affine and gradual typing.

The algebra $\Quantifier_C$ on the set of capabilities $C$ presented in Figure \ref{capabilities} is based on a \emph{partial commutative monoid} with a few special elements.
The operation of the partial monoid is defined as a relation $\op{x}{y}{z}$ on a carrier $C$.
This relation must be commutative, associative, and absorb the neutral element $\ell_{\o}$.
To recover the computability of the relation, $\constr{\cdot-compute}$ requires that given two elements $y$ and $z$, it is decidable whether a third element $x$ exists such that $\op{x}{y}{z}$.
To recover the functionality, $\constr{\cdot-unique}$ requires that given any two elements $y$ and $z$, if a third one exists, it is uniquely defined.
A consequence of using leftover typing (\S \ref{leftover-typing}) is that this algebra needs to be injective, and thus $\constr{\cdot-unique^l}$ requires for an operand to be uniquely defined as well.
In addition to these rules, we define the special elements $\ell_i$ and $\ell_o$, to be subtracted every time an input or output occurs, respectively.
Finally, we require for $\ell_i$ and $\ell_o$ to be compatible, and refer to the result as $\ell_\#$.

\begin{figure}[h]
\begin{equation}
\begin{aligned}
  &\ell_{\o}                &:{} &                      &     & C \\
  &\ell_i                   &:{} &                      &     & C \\
  &\ell_o                   &:{} &                      &     & C \\
  &\op{\_}{\_}{\_}          &:{} &                      &     & C \to C \to C \to Set \\
  &\constr{\cdot-join}      &:{} &                      &     & \exists \ell_\# . \; \op{\ell_\#}{\ell_i}{\ell_o} \\
  &\constr{\cdot-compute}   &:{} &\forall y z           & \to & Dec \; (\exists x . \; (\op{x}{y}{z})) \\
  &\constr{\cdot-unique}    &:{} &\forall \{x x' y z\}  & \to & \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
  &\constr{\cdot-unique^l}  &:{} &\forall \{x y y' z\}  & \to & \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
  &\constr{\cdot-id^l}      &:{} &\forall x             & \to & \op{x}{\ell_{\o}}{x} \\
  &\constr{\cdot-comm}      &:{} &\forall \{x y z\}     & \to & \op{x}{y}{z} \to \op{x}{z}{y} \\
  &\constr{\cdot-assoc}     &:{} &\forall \{x y z u v\} & \to & \op{x}{y}{z} \to \op{y}{u}{v} \to \exists w . \; (\op{x}{u}{w} \times \op{w}{v}{z})
\end{aligned}
\end{equation}
\caption{Quantifier algebra $\Quantifier_C$ algebra on a partial commutative monoid with special elements $\ell_i$, $\ell_o$ and $\ell_\#$.}
\label{capabilities}
\end{figure}

To allow for several capability algebras to coexist on the same type system, in Figure \ref{indexed-capabilities} we index the algebra carriers by an index $\Idx$.
Such an index is a type with one element for each algebra of our type system.
To be able to prove subject congruence, we require for at least one such algebra to exist.
Finally, the field $\constr{\Quantifiers}$ requires for each index $i$ to have an algebra defined on the carrier set $\constr{\Carrier_i}$.

\begin{figure}[h]
\begin{equation}
\begin{split}
  \constr{\Idx}          &: Set \\
  \constr{\exists \Idx}  &: Idx \\
  \constr{\Carrier}      &: \Idx \to Set \\
  \constr{\Quantifiers}  &: \forall i : \Idx \to \Quantifier_{\Carrier_i}
\end{split}
\end{equation}
\caption{Indexed set of partial commutative monoids}
\label{indexed-capabilities}
\end{figure}

\subsubsection{Example Type Systems}

\paragraph{Shared}

The carrier $C$ is implemented as a type $\constr{One}$ with a single trivial constructor $\omega$.
All of $\ell_{\o}$, $\ell_i$, $\ell_o$ and $\ell_\#$ are instantiated to $\omega$.
The relation $\op{\omega}{\omega}{\omega}$ is inhabited.
All other laws are trivially satisfied.

\paragraph{Linear}

The carrier $C$ is implemented as a type $\constr{Four}$ with the trivial elements $\ell_{\o}$, $\ell_i$, $\ell_o$ and $\ell_\#$.
The partial monoid is defined with the element $\ell_{\o}$ being neutral on both sides, and the element $\ell_\#$ splitting into $\ell_i$ and $\ell_o$ or $\ell_o$ and $\ell_i$ -- and is uninhabited in every other case.
All other rules follow trivially.

\paragraph{Affine}

The algebra of an affine system is exactly the one of a linear one, the only difference is the output context must satisfy a trivial predicate.

\paragraph{Gradual}

The carrier $C$ is implemented as a tuple $(\N , \N)$ of natural numbers.
The element $\ell_{\o}$ corresponds to the tuple $(0 , 0)$, $\ell_i$ to $(1 , 0)$, $\ell_o$ to $(0 , 1)$, and $\ell_\#$ to $(1 , 1)$.
The partial monoid is defined exactly when $\op{(x_l + y_l , x_r + y_r)}{(x_l , x_r)}{(y_l , y_r)}$.
All other rules follow trivially from the algebraic rules for the addition of naturals.

\subsection{Contexts}

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\PreCtx_n : Set}
  }

  \inferrule
  { }
  {[] : \PreCtx_0}

  \inferrule
  {\gamma : \PreCtx_n \\ t : \Type}
  {\gamma , t : \PreCtx_{\suc n}}
\end{mathpar}
\caption{This is...}
\end{figure}
  
\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Idxs_n : Set}}

  \inferrule
  { }
  {[] : \Idxs_0}

  \inferrule
  {is : \Idxs_n \\ i : \Idx}
  {is , i : \Idxs_{\suc n}}

  \\
  
  {\mprset{fraction={===}}
    \inferrule
    {is : \Idxs_n}
    {\Ctx_{is} : Set}}
  
  \inferrule
  { }
  {[] : Ctx_{[]}}
  
  \inferrule
  {\Gamma : \Ctx_{is} \\ x : \Carrier_i}
  {\Gamma , x : \Ctx_{is , i}}
\end{mathpar}
\caption{This is...}
\end{figure}
two-layered approach: types on one hand, capabilities on the other
removing from context vs keeping in context but marking it used

\subsection{Typing with Leftovers}\label{leftover typing}

Variable references as proofs of capability

Context splits at each variable reference

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule{
      \gamma : \PreCtx_n \\
      \inferrule*{}{
        is : \Idxs_n \\\\
        \Gamma : \Ctx_{is}} \\
      t : \Type \\
      x : \Carrier_i \\
      \Delta : \Ctx_{is}}
    {\contains{\gamma}{\Gamma}{t}{x}{\Delta} : Set}}

  \inferrule
  {\Gamma : \Ctx_{is} \\ y \; z : \Carrier_i \\ True (\constr{\cdot-compute} \; y \; z)}
  {\constr{zero} : \contains{\gamma , t}{\Gamma , x}{t}{y}{\Gamma , z}}
  
  \inferrule
  {\Gamma : \Ctx_{is} \\ x : \Carrier_i \\ x' : \Carrier_j \\ \Delta : \Ctx_{is} \\\\
    loc_x : \contains{\gamma}{\Gamma}{t}{x}{\Delta}}
  {\constr{suc} \; loc_x : \contains{\gamma , t}{\Gamma , x'}{t}{x}{\Delta , x'}}
\end{mathpar}
\caption{This is...}
\end{figure}

\todo{comment on scope restriction rule and capabilities}

\begin{figure}[h]
\begin{mathpar}
  \mprset{flushleft}
  
  {\mprset{fraction={===}}
    \inferrule{
      \gamma : \PreCtx_n \\
      \inferrule*{}{
        is : \Idxs_n \\\\
        \Gamma : \Ctx_{is}} \\
      P : \Process_n \\
      \Delta : \Ctx_{is}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : Set}}
  
  \inferrule
  { }
  {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}

  \inferrule
  {t : \Type \\ x : \Carrier_i \\ y : \Carrier_j \\\\
   cont : \types{\gamma , C[ t \propto x ]}{\Gamma , y}{P}{\Delta , 0.}}
  {\constr{chan} \; t \; x \; y : \types{\gamma}{\Gamma}{\new P}{\Delta}}

  \inferrule
  {chan_x : \contains{\gamma}{\Gamma}{C[ t \propto x]}{+\cdot}{\Xi} \\\\
   cont : \types{\gamma , t}{\Xi , x}{P}{\Theta , 0\cdot}}
  {\constr{recv} \; chan_x \; cont : \types{\gamma}{\Gamma}{\recv{toFin \; chan_x}{P}}{\Theta}}

  \inferrule
  {chan_x : \contains{\gamma}{\Gamma}{C[t \propto x]}{-\cdot}{\Delta} \\\\
   loc_y : \contains{\gamma}{\Delta}{t}{x}{\Xi} \\\\
   cont : \types{\gamma}{\Xi}{P}{\Theta}}
  {\constr{send} \; chan_x \; loc_y \; cont : \types{\gamma}{\Gamma}{\send{toFin \; chan_x}{toFin \; loc_y}P}{\Theta}}

  \inferrule
  {l : \types{\gamma}{\Gamma}{P}{\Delta} \\\\
   r : \types{\gamma}{\Delta}{Q}{\Xi}}
  {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
\end{mathpar}
\caption{This is...}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Subject Reduction}\label{subject-reduction}

\subsection{Framing}


\subsection{Weakening}

Order preserving embeddings model a series of insertions. We only ever need one insertion to prove subject congruence, but there is no loss of generality.

\subsection{Strengthening}

\subsection{Swapping}

\subsection{Subject Congruence}\label{subject-congruence}

\subsection{Substitution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\cite{previous-work} polymorphic tokens, HOAS

\cite{typing-with-leftovers}

\cite{Higher-inductive-types-for-congruence}

\cite{LTS-semantics}

\cite{work-on-session-types}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permiting:

\begin{description}

\item [Affine types]
  
\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}


\bibliography{paper}
\end{document}
