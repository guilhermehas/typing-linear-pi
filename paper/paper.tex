\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[dvipsnames]{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage{mathtools}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Example code
\usepackage{listings}

% Diagrams
\usepackage{tikz}

% Mathbb doesn't support digits
\usepackage{bbm}

% Less margins around figures
\usepackage{changepage}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

% Do not use italics in definitions and theorems
\theoremstyle{definition}
\newtheorem{nidefinition}[theorem]{Definition}
\newtheorem{nitheorem}[theorem]{Theorem}
\newtheorem{nilemma}[theorem]{Lemma}

% An i with a heart on top
\usepackage{pifont}
\usepackage{graphics}
\newcommand\iheart{%
    \begingroup
    \settowidth{\dimen0}{i}%
    i%
    \llap{\makebox[\dimen0][c]{%
        \color{white}%
        \raisebox{1.23ex}{\scalebox{0.40}{$\blacksquare$}}%
      }}%
    \llap{\makebox[\dimen0][c]{%
        \raisebox{1.23ex}{\scalebox{0.20}{\ding{170}}}%
    }}%
    \endgroup
}

% No line numbers
\nolinenumbers

% Abbreviations
\newcommand{\lambdacalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}

% Typing rules
\newcommand{\stacked}[1]{\mprset{flushleft} \inferrule*{}{#1}}
\newcommand{\datatype}[2]{{\mprset{fraction={===}} \inferrule{#1}{#2}}}

\newcommand{\type}[1]{\textcolor{BlueViolet}{\operatorname{#1}}}
\newcommand{\constr}[1]{\textcolor{BurntOrange}{\operatorname{#1}}}
\newcommand{\func}[1]{\textcolor{OliveGreen}{\operatorname{#1}}}

% Constructors
\newcommand{\PO}{\constr{\mathbf{0}}}
\newcommand{\comp}[2]{#1 \; \constr{\parallel} \; #2}
\newcommand{\new}{\constr{\boldsymbol{\nu}} \;}
\newcommand{\send}[2]{#1 \; \constr{\langle} \; #2 \;\constr{\rangle} \;}
\newcommand{\sendp}[2]{#1 \; \constr{\langle} \; #2 \; \constr{\rangle} \;}
\newcommand{\recv}[1]{#1 \; \constr{\mathbb{()}} \;}
\newcommand{\recvp}[2]{#1 \; \constr{(} \; #2 \; \constr{)} \;}
\newcommand{\suc}{\constr{\scriptstyle 1+}}
\newcommand{\unit}{\constr{\mathbbm{1}}}
\newcommand{\base}[1]{\constr{B[} \; #1 \; \constr{]}}
\newcommand{\channel}[2]{\constr{C[} \; #1 \; \constr{\propto} \; #2 \; \constr{]}}
\newcommand{\comma}{\; \constr{,} \;}

% Functions
\newcommand{\subst}[3]{#1 \; \func{[} \; #3 \; \func{\mapsto} \;#2 \; \func{]}}
\newcommand{\op}[3]{#1 \; \func{\coloneqq} \; #2 \; \func{\cdot} \; #3}
\newcommand{\opsquared}[3]{#1 \, \func{\coloneqq} \, #2 \, \func{\cdot^2} \, #3}
\newcommand{\opctx}[3]{#1 \, \func{\coloneqq} \, #2 \, \func{\otimes} \, #3}
\newcommand{\zero}{\func{0\cdot}}
\newcommand{\one}{\func{1\cdot}}
\newcommand{\li}{\func{\ell_i}}
\newcommand{\lo}{\func{\ell_o}}
\newcommand{\lz}{\func{\ell_{\o}}}
\newcommand{\lio}{\func{\ell_{\#}}}

% Types
\newcommand{\Set}{\type{SET}}
\newcommand{\reduce}[1]{\; \type{\longrightarrow}_{#1} \;}
\newcommand{\types}[4]{#1 \; \type{\propto} \; #2 \; \type{\vdash} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\contains}[6]{#1 \; \type{\propto} \; #2 \; \type{\ni}_{#3} \; #4 \; \type{\propto} \; #5 \; \type{\boxtimes} \; #6}
\newcommand{\containsusage}[4]{#1 \; \type{\ni}_{#2} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\Var}{\type{VAR}}
\newcommand{\Process}{\type{PROCESS}}
\newcommand{\Unused}{\type{UNUSED}}
\newcommand{\PreCtx}{\type{PRECTX}}
\newcommand{\Ctx}{\type{CTX}}
\newcommand{\Type}{\type{TYPE}\;}
\newcommand{\Idx}{\type{IDX}\;}
\newcommand{\Idxs}{\type{IDXS}}
\newcommand{\Usage}{\type{USAGE}}
\newcommand{\N}{\type{\mathbb{N}}}
\newcommand{\Channel}{\type{CHANNEL}}
\newcommand{\Rec}{\type{REC}}
\newcommand{\Quantifier}{\type{QUANTIFIER}}
\newcommand{\eq}[1]{\; \type{=}_{#1} \;}
\newcommand{\eqeq}{\; \type{\equiv} \;}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{$\pi$ with leftovers: \\ a mechanisation in Agda}
\titlerunning{$\pi$ with leftovers: all mechanisation in Agda}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi-calculus, linear types, leftover typing, concurrency, mechanization, Agda}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{We want to thank Er\iheart ka Kreuter, Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}
\funding{Supported by the UK EPSRC grant EP/K034413/1, ``From Data Types to Session Types: A Basis for Concurrency and Distribution'' (ABCD), and by the EU HORIZON 2020 MSCA RISE project 778233
  ``Behavioural Application Program Interfaces'' (BehAPI).}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
  The \picalc{} is a computational model for communication and concurrency.
  The \emph{linear} \picalc{} is a typed version of the \picalc{} where channel resources must be used exactly once.
  With the rise of session types as a formalism to model real-world distributed systems, the linear \picalc{} has re-emerged as the underlying theoretical and practical framework for session types and communication-based distributed programming \cite{DardhaGS12,Padovani17,ScalasY16,ScalasDHY17}.
  While there have been several extensions to the session typed \picalc{}, the linear \picalc{} remains essentially unchanged and stable as a foundational calculus.

  We present the \emph{first} fully mechanised \picalc{} featuring linear types, as well as gradual and shared types.
  We present its syntax, operational semantics, and typing rules and the corresponding type safety properties.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalise the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  Our formalisation is fully mechanised in Agda. \cite{Zalakain2020Agda}
\end{abstract}

\todo{make sure all citations are there}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
% The way I want to write the intro:
% -- describe what is the picalc and why it is IMPORTATNT
% -- describe what are linear types and why programming with them is IMPORTATNT
% -- join together by saying that is why we focus on linear pi calculus but we do more than just that: we have linear, gradual and shared types
% -- put emphasis on mechanisation in Agda

\todo{highlight that we can talk about a resource even if it has been exhausted (e.g. we can send 0 multiplicities of a channel over another channel}

We live in a concurrent world where any given state is often computed interactively by a myriad of parties --- people, machines, processors, services, networks.
As humans, we aim to model, predict, and build such interactive systems; as mathematicians, abstraction is our tool of choice to do so.

The \picalc{} \cite{MilnerPW92,Milner99} is the most successful computational model for communication and concurrency.
It abstracts over the details of concurrent processing and boils the interactions down to the sending and receiving of data through communication channels.
Notably, it features \emph{channel mobility}: the channels themselves are first order constructs, and can therefore be transmitted.
The \picalc{} acts as a foundation for the design and implementation of programming languages for concurrency, such as Pict \cite{Pierce} and (more recently) Go \cite{Golang}.
Moreover, at the state-of-the-art, the \picalc{} features a wide plethora of types: basic types, linear types, types for liveness properties (such as deadlock freedom, livelock freedom or termination), and most notably, session types \cite{K07}. This makes the \picalc{} a fully-fledged tool for the modeling and verification of concurrent and distributed systems.

In a parallel track, J.-Y. Girard's development of linear logic \cite{Girard87} in the early '90s opened new avenues in computing science by introducing \emph{linear types} for (functional) programming languages \cite{Curry-Howard,Wadler90,Bernardy2018}.
Linear type systems guarantee that resources are used \emph{exactly once}.
Enforcing ``no duplicating'' and ``no discarding'' of resources via linearity allows for resource-aware programming and more efficient implementations \cite{Wadler90}.
Later on, linearity inspired unique types (as in Clean \cite{BarendsenS96}) and ownership types (as in Rust \cite{MatsakisK14}).

The \picalc{} also benefited from this linearity wave in the early '90s.
Kobayashi et al. \cite{KPT96} defined the {linear} \picalc{}, a typed version of the \picalc{} where the linear type system restricts the usage of channels, which must be used exactly once.

In the meantime, the rise of session types \cite{H93,THK94,HVK98} gave a different flavour to the linearity in the \picalc{}.
Session types are a type formalism used in communication-centric programming.
In session types, linearity ensures that a channel must be owned by exactly one communicating participant, even if the channel itself can be used multiple times, as specified by the structure of its session type.
Linearity in session types is the key ingredient that guarantees type safety.

Recent work \cite{DardhaGS12,Dardha14,DardhaGS17} pushed the linear \picalc{} into the spotlight again \cite{KPT96}, thanks to an encoding of session types into linear types.
This encoding not only has theoretical benefits in terms of expressivity of session types and reusability of theoretical results from the linear \picalc{}, but is useful at a practical level too.
The encoding has been used as a technique to implement session types in mainstream programming languages such as OCaml \cite{Padovani17} and Scala \cite{ScalasY16,ScalasDHY17}.
This means that we can use the linear \picalc{} as an underlying theoretical and practical framework on top of which session types can be built.

Considering the importance of the \picalc{} and of linearity in modeling concurrent and distributed systems, in this paper we focus our research on both and go beyond.
We present for the first time a full mechanisation in Agda of a \picalc{} with linear, gradual and shared types, all under the same unified framework.
We do so by defining a specification for an algebra on multiplicities and using it to apply leftover typing (following Allais \cite{Allais2018a}) to the \picalc{} for the first time.
The user is able to choose any mix of algebras for the type system --- as long as they comply with the specification.
Ultimately, we can use $\pi$ with leftovers as a unified framework for type safe distributed modeling and programming with a variety of type systems, on top of which more advanced types, theories and languages can be built.
While linearity is needed for type safety, gradual types and shared types are needed for real-world systems.

\subsection{Contributions}
Our contributions are the following:
\begin{itemize}
\item \textbf{Formalisation of the syntax and the semantics of the \picalc{}}:
  \autoref{syntax} uses type level de Bruijn indices \cite{deBruijn1972} to introduce a syntax that is well-scoped by construction: every free variable is accounted for in the type of the process that uses it.
  \autoref{semantics} provides an operational semantics for the untyped \picalc{}, prior to any typing.
  This operational semantics is given as a reduction relation on processes.
  The reduction relation tracks at the type level what channel the communication occurs on, so that this information can then be used to state subject reduction --- aka type preservation.
  It is also defined modulo structural congruence --- a relation that acts as a quotient type that gets rid of the unnecessary syntactic minutiae introduced by the syntax of the \picalc{}.

  \item \textbf{Leftover typing for the \picalc{}, with linear, gradual and shared types}:
  \autoref{type-system} provides the type system for a resource-aware \picalc{}.
  The type system is \emph{resource-aware} in that it allows the user to provide a resource-aware algebra that is then applied to the type-system.
  Linear types, gradual types and shared types are all instances of such a resource-aware algebra too.
  Any \emph{partial commutative monoid} that is cancellative and has a minimal element is a valid such algebra.
  Multiple of these algebras can be applied to a single type system --- contexts keep information about what algebra should be applied to which element.

  The typing judgments use \emph{leftover typing} to model the resource-aware \picalc{}.
  This approach adds a leftover usage context to the typing judgments.
  Typing derivations take the resources of their input usage context, consume some of them, and leave the rest as leftovers in the output usage context.
  These technique renders explicit context splits unnecessary.

  \item \textbf{Machine verified proofs of subject reduction and auxiliary theorems}:
  \autoref{type-safety} builds on several theorems to proof subject reduction for our type system.
  Here too, leftover typing renders the proofs for some of these lemmas straightforward, while for others it makes it possible to state them in the first place.
  We prove \textbf{framing} (well-typedness is independent of the unused resources of a process), \textbf{weakening} (new variables that are added to both the input and output usage context preserve well-typedness), and \textbf{strengthening} (removing the variables that are unused by a process preserves well-typedness).
  We use these to prove \textbf{subject congruence} (structural congruence rules can be freely applied while preserving well-typedness) and \textbf{substitution} (a variable can be substituted for another as long as this other variable is capable of doing everything the original one did), and use these to prove \textbf{subject reduction} (a well-typed process that reduces will still be well-typed).

  \item \textbf{Fully mechanised formalisation available in Agda}:
  This work has been fully formalised in Agda and is publicly available \cite{Zalakain2020Agda}.

\end{itemize}


\subsection{Notation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\type{\N} : \Set}
    \; \textsc{Nat}

    \inferrule
    { }
    {\constr{0} : \type{\N}}

    \inferrule
    {n : \type{\N}}
    {\suc n : \type{\N}}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Data type definitions use double lines and index-free synonyms as rule names (for ease of reference).
We otherwise use the constructor name as the name of a typing rule.
Universe levels and universe polymorphism are omitted for brevity --- all our types are of type $\Set$.
Implicit arguments are mentioned by type definitions but omitted in constructors.
$\type{TYPES}$ are blue volet (uppercased, with indices as subscripts), $\constr{constructors}$ are burnt orange, $\func{functions}$ are olive green, variables are black, and some constructor names are overloaded --- and disambiguated by context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}
\label{syntax}
Let $x, y,\ldots$ range over \emph{variables} and $P, Q,\ldots$ over processes.
The syntax of the \picalc{} \cite{Sangio01} is given by grammar in \autoref{fig:syntax-names}.

\begin{figure}[h]
  \begin{subfigure}{1\textwidth}
    \begin{mathpar}
      \datatype
      {n : \N}
      {\Var_n : \Set}
      \; \textsc{Var}

      \inferrule
      {n : \N}
      {\constr{0} : \Var_{\suc n}}

      \inferrule
      {x : \Var_n}
      {\suc x : \Var_{\suc n}}

      \datatype
      {n : \N}
      {\Process_n : \Set}
      \; \textsc{Process}
    \end{mathpar}
  \end{subfigure}
  \begin{subfigure}[t]{.2\textwidth}
    \begin{equation*}
      \begin{split}
        P,Q ::=      & \; \PO                \\ 
                    |& \; (\new{}x)  P       \\ 
                    |& \; \comp{P}{Q}        \\ 
                    |& \; \recvp{x}{y}. \; P \\ 
                    |& \; \sendp{x}{y}. \; P 
      \end{split}
    \end{equation*}
    \caption{Ill-scoped grammar with names}
    \label{fig:syntax-names}
  \end{subfigure}
  \hspace{.1\textwidth}
  \begin{subfigure}[t]{.7\textwidth}
    \begin{equation*}
      \begin{split}
        \Process_n ::=& \; \PO_n               &&\text{(process termination)}   \\ 
        |& \; \new{} \Process_{\suc n}         &&\text{(restriction)}          \\ 
        |& \; \comp{\Process_n}{\Process_n}    &&\text{(parallel composition)} \\ 
        |& \; \recv{\Var_n}{}\Process_{\suc n} &&\text{(input)}                \\ 
        |& \; \send{\Var_n}{\Var_n}\Process_n  &&\text{(output)}                  
      \end{split}
    \end{equation*}
    \caption{Well-scoped grammar with type-level de Bruijn indices}
    \label{fig:syntax}
  \end{subfigure}
  \caption{}
\end{figure}

Process $\PO$ denotes the terminated process, where no operations can further occur.
Process $(\new{}x)P$ creates a new channel $x$ bound with scope $P$.
Process $\comp{P}{Q}$ is the parallel composition of processes $P$ and $Q$.
Processes $\recvp{x}{y}. \; P$ and $\sendp{x}{y}. \; P$ denote respectively the input and output processes of a variable $y$ over a channel $x$, with continuation $P$.

Scope restriction $(\new{}x) \; P$ and input $\recvp{x}{y}. \; P$ both introduce bound names in $P$.
In order to mechanise the \picalc{} syntax in Agda, we need to deal with bound names in continuation processes.
Names are cumbersome to mechanise: inserting a new variable into a context means proving that its name differs from all other variable names in context.
Furthermore, names do not guarantee that the syntax well-scoped.
Instead, we use de Bruijn indices \cite{deBruijn1972}, where a natural number $n$ (aka \emph{index}) is used to refer to the variable introduced $n$ binders ago --- hence binders no longer introduce names.
\begin{example}
  \begin{equation*}
    \begin{split}
      & (\new{}x ) && (\comp {\recvp{x}{y} && . \; \sendp{y}{\texttt{"Hello world!"}} . \; \PO} {(\new{} y) && (\sendp{x}{y} . \; \recvp{y}{z} && . \; \PO)})
      & \text{names}
      \\
      & \new{} && (\comp {\recv{0} && . \; \send{0}{\texttt{"Hello world!"}} . \; \PO} {\new{} && (\send{1}{0} . \; \recv{0} && . \; \PO)})
      & \text{de Bruijn}
      \\
    \end{split}
  \end{equation*}
\end{example}
That is, terms at different \emph{depths} use different indices to refer to the same binding.

A variable occurring under $n$ abstractions has $n$ possible variables to refer to.
References outside of that range are meaningless.
It is useful to rule out these nonsensical terms syntactically.
In \autoref{fig:syntax}, we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.


Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
We increase the \emph{depth} counter by 1 in channel restriction and input processes.
\autoref{fig:syntax} showcases a \picalc{} syntax that is well-scoped by construction using type-level de Bruijn indices.

The semantics of our language can now be defined on the totality of the syntax.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
\label{semantics}
We introduce the operational semantics for the \picalc{}, starting with structural congruence.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Structural Congruence}
\label{structural-congruence}

We define the base cases of a structural congruence relation \textsc{StructCong} in \autoref{fig:struct-cong-base}.
Its congruent equivalence closure \textsc{Equals} is provided in \autoref{app:struct}.

\todo{remove space between inferrules}
\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {P \eqeq Q : \Set}
  \; \textsc{StructCong}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{(\comp{Q}{R})} \eqeq \comp{(\comp{P}{Q})}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \eqeq \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \eqeq P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \eqeq \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \; Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \eqeq \comp{(\new P)}{\func{lower}_{\constr{0}} \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \eqeq \new \new \func{swap}_{\constr{0}} \; P}
\end{mathpar}
\caption{Base cases of structural congruence.}
\label{fig:struct-cong-base}
\end{figure}

The first three rules ($\constr{comp}-$*) state associativity, symmetry, and $\PO$ as the neutral element of parallel composition, respectively.
The last three ($\constr{scope}-$*) state garbage collection, scope extrusion and commutativity of restrictions, respectively.

In $\constr{scope-ext}$ the type $\Unused_i \; Q$ is an inductive proof asserting that the variable index $i$ does not appear neither in the inputs nor in the outputs of $Q$.
The function $\func{lower}_i \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $i$.
In $\constr{scope-comm}$ the function $\func{swap}_i \; P$ traverses $P$ (of type $\Process_{\suc \suc n}$) and swaps variable references $i$ and $\suc i$.
In all the above, $i$ is incremented every time we go under a binder.
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reduction Relation}
\label{operational-semantics}

The operational semantics of the \picalc{} is defined as a reduction relation \textsc{Reduces} indexed by the channel $i$ on which communication occurs (\autoref{fig:reduction}).
In rule $\constr{comm}$, parallel processes reduce when they communicate over a common channel ${i}$.
As a result of that communication, the continuation of the input process $P$ gets all the references to its most immediate variable substituted with references to $\suc j$, the variable sent by the output process $\send{i}{j}{Q}$.
After substitution, $\subst{P}{j}{\constr{0}}$ is \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under parallel composition (rule $\constr{par}$), restriction (rule $\constr{res}$) and structural congruence (rule $\constr{struct}$) 
--- notably, not under input nor output, as doing so would not preserve the sequencing of actions \cite{Sangio01}.

We keep track of the channel over which communication occurs so that we can state subject reduction.
We use a $\func{dec}$ function to decrement the index of this channel every time we come out of a binder.
This function saturates at $\constr{internal}$: wrapping an internally reducing process with a binder will result in an internally reducing process.


\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Channel_n : \Set}
  \; \textsc{Channel}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  \datatype
  {c : \Channel_n \\ P \; Q : \Process_n}
  {P \reduce{c} Q : \Set}
  \; \textsc{Reduces}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce{\constr{external} \; i} \comp{\func{lower}_{\constr{0}} \; (\subst{P}{j}{\constr{0}})}{Q}}

  \inferrule
  {red : P \reduce{c} P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce{c} \comp{P'}{Q}}

  \inferrule
  {red : P \reduce{c} Q}
  {\constr{res} \; red : \new P \reduce{\func{dec}\; c} \new Q}

  \inferrule
  {eq : P \eq{r} P' \\ red : P' \reduce{c} Q}
  {\constr{struct} \; eq \; red : P \reduce{c} Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{fig:reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}
\label{type-system}

We characterise a usage algebra for our typing system in \autoref{multiplicities}.
This algebra defines the way in which resources are \emph{split} on parallel composition; the way in which resources are \emph{consumed} on input and output.
We then define typing and usage contexts in \autoref{contexts}.
We provide a typing system for a resource-aware \picalc{} in \autoref{leftover-typing}.

\subsection{Multiplicities and Capabilities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{multiplicities}

In the linear \picalc{} each channel has an input and an output \emph{capability}, and each capability has a given \emph{multiplicity} of 0 (exhausted) or 1 (available).
We generalise over this notion by defining an algebra that is satisfied by linear, gradual and shared types.

\begin{nidefinition}
  We define our usage algebra to be a ternary relation $\op{x}{y}{z}$ that is \emph{partial}, \emph{functional}, \emph{cancelative}, \emph{associative}, and \emph{commutative}.
  It has a \emph{neutral element} $\zero$ that is absorbed on either side, and that is also \emph{minimal}.
  It has an element $\one$ that is used to count inputs and outputs.
  For a formal definition, refer to \autoref{fig:multiplicities} in \autoref{app:usage-algebra}.
\end{nidefinition}

Linear, gradual and shared types are all defined as an instance of our usage algebra.
Their use in typing derivations is illustrated in \autoref{example-derivations}.

\begin{description}
  \item [Linear]
    The carrier is a type $\type{Two}$ with the trivial elements $\constr{zero}$ and $\constr{one}$.
    The monoidal operation has the element $\constr{zero}$ as neutral on both sides, and the element $\constr{one}$ splitting into $\constr{one}$ and $\constr{zero}$ (or $\constr{zero}$ and $\constr{one}$), and is uninhabited in every other case.
    All other properties are lifted element-wise.

    \item [Gradual]
    The carrier is the type of natural numbers $\N$.
    The element $\zero$ corresponds to 0, and $\one$ to 1.
    The partial monoid $\op{x}{y}{z}$ is defined exactly when $x \equiv y + z$.
    All other rules follow trivially from the algebraic rules for the addition of natural numbers.

    \item [Shared]
    The carrier is a type $\type{One}$ with a single trivial constructor $\constr{\omega}$.
    Both $\zero$ and $\one$ are instantiated to $\constr{\omega}$.
    The relation $\op{\constr{\omega}}{\constr{\omega}}{\constr{\omega}}$ is inhabited.
    All other rules follow trivially.
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection{Typing Contexts}
\label{contexts}

\begin{nidefinition}
  We use indexed sets of usage algebras to allow several usage algebras to coexist in our type system.
  An indexed set of usage algebras is a set of indices $\Idx$ together with an interpretation $\Usage_{idx}$ of indices into types, and an interpretation of indices into usage algebras on that type.
  $\Idx$ must be non-empty.
  Refer to \autoref{fig:indexed-multiplicities} in \autoref{app:usage-algebra} for a formal definition.
\end{nidefinition}

\begin{note}
  We will often work with pairs of input and output multiplicities.
  We use the notation $\Usage_{idx}^{\func{2}}$ to stand for a $\Usage_{idx} \times \Usage_{idx}$ tuple of input and output multiplicities, respectively.
  We use $\opsquared{x}{y}{z}$ to stand for a monoidal operation on pairs of multiplicities -- where the algebraic laws are lifted element-wise.
  Henceforth, we use $\lz$ to denote the pair $(0 \comma 0)$, $\li$ for the pair $(1 \comma 0)$, $\lo$ for $(0 \comma 1)$ and $\lio$ for $(1 \comma 1)$, borrowing from the linear \picalc{} notation \cite{KPT96,Sangio01}.
\end{note}

We keep typing contexts ($\PreCtx$) and usage contexts ($\Ctx$) separate.
The former are preserved throughout a typing derivation; the latter are transformed as a result of input, output, and context splits.

\begin{nidefinition}
  \autoref{fig:prectx} defines types as either unit types, base types or channel types.
  The unit type $\unit$ serves as a proof of inhabitance for types.
  The base type $\base{n}$ uses natural numbers as placeholders for types --- the host language can interpret the former into the latter.
  This is for convenience, so that there is less universe polymorphism polluting specifications.
  The type $\channel{t}{x}$ of a channel determines what type of data and what usage annotations are sent over that channel.
  We keep track of types in a length-indexed \emph{pre-context} $\PreCtx_n$.
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Type : \Set}
    \; \textsc{Type}
  
    \inferrule
    { }
    {\unit : \Type}

    \inferrule
    {n : \N}
    {\base{n} : \Type}
  
    \inferrule
    {t : \Type \\ \stacked{idx : \Idx \\\\ x : \Usage_{idx}^{\func{2}}}}
    {\channel{t}{x} : \Type}
  \end{mathpar}
  
  \begin{mathpar}
    \datatype
    {n : \N}
    {\PreCtx_n : \Set}
    \; \textsc{PreCtx}
  
    \inferrule
        { }
        {[] : \PreCtx_{\constr{0}}}
  
        \inferrule
            {\gamma : \PreCtx_n \\ t : \Type}
            {\gamma \comma t : \PreCtx_{\suc n}}
  \end{mathpar}
  \caption{Types and length-indexed typing contexts.}
  \label{fig:prectx}
  \end{figure}
\end{nidefinition}

\begin{nidefinition}
  We keep track of usages annotations in a context $\Ctx_{idxs}$ that is indexed by a length-indexed context of indices $\Idxs_n$, as shown in \autoref{fig:ctx}.

  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Idxs_n : \Set}
    \; \textsc{Idxs}
  
    \inferrule
        { }
        {[] : \Idxs_{\constr{0}}}
  
    \inferrule
        {idxs : \Idxs_n \\ idx : \Idx}
        {idxs \comma idx : \Idxs_{\suc n}}
  
    \datatype
    {idxs : \Idxs_n}
    {\Ctx_{idxs} : \Set}
    \; \textsc{Ctx}
  
    
    \inferrule
        { }
        {[] : \Ctx_{[]}}
        
    \inferrule
        {\Gamma : \Ctx_{idxs} \\ x : \Usage_{idx} ^{\func{2}}}
        {\Gamma \comma x : \Ctx_{idxs \comma idx}}
  \end{mathpar}
  \caption{Length-indexed context of carrier indices with a context of multiplicities on top.}
  \label{fig:ctx}
  \end{figure}
\end{nidefinition}

\begin{note}
  We lift the monoidal operation on usage annotations $\opsquared{x}{y}{z}$ to a monoidal operation $\opctx{\Gamma}{\Delta}{\Xi}$ on usage contexts that have a common underlying context of indices.
  All the properties of the partial monoid are trivially lifted.
\end{note}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection{Typing with Leftovers}
\label{leftover-typing}

We use \emph{leftover typing} \cite{Allais2018a} for our typing rules, an approach that, in addition to the usual typing context and usage context, adds an extra output usage context to the typing rules.
This output context contains the \emph{leftovers} (the unused multiplicities) of the process being typed.
These leftovers can then be used as an input to another typing derivation.
This technique presents three main advantages:
\begin{itemize}
  \item
    The transformations to the usage context (consequence of receiving and sending over a channel) are encapsulated into a variable reference judgment with both an input and an output usage context.
  \item
    The need for an extensional context splitting proof for parallel composition is eradicated.
    Such a proof would need to construct a witness $\opctx{\Gamma_m}{\Gamma_l}{\Gamma_r}$, where $\Gamma_l \vdash P$, $\Gamma_r \vdash Q$ and $\Gamma_m \vdash \comp{P}{Q}$.
    This could be obtained through automated search --- but it is better yet not to need it.
    Leftover typing uses the leftovers of $P$ to type $Q$.
  \item
    New theorems (\textbf{framing} (\autoref{framing}), \textbf{weakening} (\autoref{weakening}) and \textbf{strengthening} (\autoref{strengthening})) can suddenly be stated.
\end{itemize}
  
We introduce two judgments: one on variable references (\autoref{def:varref}), one on processes (\autoref{def:types}).
Both of these are indexed by a typing context, an input usage context, and an output usage context.

\begin{nidefinition}
  \label{def:varref}

  The \textsc{VarRef} relation presented in \autoref{fig:variable-references} keeps track of the index, type, and usage annotation of a variable within a particular typing and usage context.
  The leftover usage context is the result of subtracting the usage annotation from the input usage context.

  The base case $\constr{here}$ splits the usage annotation $x$ into $y$ and $z$, the leftovers.
  This splitting is as per the usage algebra defined on the index of the usage annotation.

  \begin{remark}
    We use the functionality of the monoidal relation to alleviate the user from the proof burden $\opsquared{x}{y}{z}$.
  \end{remark}

  \begin{figure}[h]
  \begin{mathpar}
    \mprset{sep=0.5em}
  
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      i : \Var_n \\
      t : \Type \\
      \stacked{
        idx : \Idx \\\\
        y : \Usage_{idx}^{\func{2}}} \\
      \Delta : \Ctx_{idxs}}
    {\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta} : \Set}
    \; \textsc{VarRef}
  
    \inferrule
    {\opsquared{x}{y}{z}}
    {\constr{here} : \contains{\gamma \comma t}{\Gamma \comma x}{\constr{0}}{t}{y}{\Gamma \comma z}}
    
    \inferrule
    {loc_i : \contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}}
    {\constr{there} \; loc_i : \contains{\gamma \comma t'}{\Gamma \comma x'}{\suc i}{t}{x}{\Delta \comma x'}}
  \end{mathpar}
  \caption{Variable reference judgments.}
  \label{fig:variable-references}
  \end{figure}
\end{nidefinition}

\begin{example}
  The following example asserts that the input $\channel{\unit}{\li}$ type at index $\constr{suc} \; \constr{0}$ is capable of $\li$, and that consuming such $\li$ results in $\lo$.
  \begin{lstlisting}[mathescape,caption=Here the underscore \_ introduces an anonymous declaration immediately followed by its definition.]
  _ : $\contains{\constr{[]} \comma \channel{\unit}{\li} \comma \unit} {\constr{[]} \comma \lio \comma \lio} {\constr{suc} \; \constr{0}} {\channel{\unit}{\li}} {\li} {\constr{[]} \comma \lo \comma \lio}$
  _ = $\constr{there} \; \constr{here}$
  \end{lstlisting}
\end{example}

\begin{nidefinition}
  \label{def:types}

  The typing relation \textsc{Types} presented in \autoref{fig:types} asserts that process $P$ is well-typed under typing context $\gamma$, usage input context $\Gamma$ and leftovers $\Delta$.

  \begin{figure}[h]
  \begin{mathpar}
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      P : \Process_n \\
      \Delta : \Ctx_{idxs}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : \Set}
    \; \textsc{Types}
    
    \inferrule
    { }
    {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}
  
    \inferrule
    {t : \Type \\ x : \Usage_{idx}^{\func{2}} \\ y : \Usage_{idx'} \\\\
     cont : \types{\gamma \comma \channel{t}{x}}{\Gamma \comma (y \comma y) }{P}{\Delta \comma \lz}}
    {\constr{chan} \; t \; x \; y \; cont : \types{\gamma}{\Gamma}{\new P}{\Delta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma \hspace{1.2em}}{\Gamma \hspace{1.3em}}{i}{\channel{t}{x}}{\li}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma \comma t}{\Xi \comma x}{P \hspace{5.6em}}{\Theta \comma \lz}}}
        {\constr{recv} \; chan_i \; cont : \types{\gamma}{\Gamma}{\recv{i}{P}}{\Theta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma}{\Gamma \hspace{0.2em}}{i}{\channel{t}{x}}{\lo}{\Delta} \\\\
            loc_j \hspace{0.8em} : \contains{\gamma}{\Delta}{j}{t \hspace{3.7em}}{x \hspace{0.3em}}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma}{\Xi \hspace{0.3em}}{P\hspace{5.8em}}{\Theta}}}
        {\constr{send} \; chan_i \; loc_j \; cont : \types{\gamma}{\Gamma}{\send{i}{j}P}{\Theta}}
  
    \inferrule
    {l \hspace{0.3em} : \types{\gamma}{\Gamma \hspace{0.2em}}{P}{\Delta} \\\\
     r : \types{\gamma}{\Delta}{Q}{\Xi}}
    {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
  \end{mathpar}
  \caption{Leftover typing for a resource-aware typing system.}
  \label{fig:types}
  \end{figure}

  Process termination threads usage annotations unchanged from input to output.

  Scope restriction expects three arguments: the type $t$ of data being transmitted; the usage annotation $x$ that is being transmitted; and the multiplicity $y$ given to the channel itself.
  This multiplicity $y$ is used for both input and output, so that these are balanced.
  The continuation process $P$ is provided with the new channel with usage annotation $(y \comma y)$, which it must completely exhaust.

  Receiving needs a channel $chan_i$ at index $i$ with usage $\li$ available, such that data with type $t$ and usage $x$ can be sent over it.
  Note that the index $i$ is used in the syntax of the typed process.
  We use the leftovers $\Xi$ to type the continuation process, which is also provided with the received element --- of type $t$ and multiplicity $x$ at index $\constr{0}$.
  The received element $x$ must be completely exhausted by the continuation process.

  Similar to input, sending needs a channel $chan_i$ at index $i$ with usage $\lo$ available, such that data with type $t$ and usage $x$ can be sent over it.
  We use the leftover context $\Delta$ to type the continuation process, which needs an element $loc_j$ at index $j$ with type $t$ and usage $x$, as specified by the channel $chan_i$.
  The leftovers $\Xi$ are used to type the continuation process.
  Note that both indices $i$ and $j$ are used in the syntax of the typed process.
  
  Parallel composition uses the leftovers of left-hand process to type the right-hand process.
\end{nidefinition}

\begin{example}
  \label{example-derivations}
  The example below uses linear and shared types to type the process $p$. 
  We define $\omega$ as a $(\one \comma \one)$ usage in an algebra for shared types.
  We define $\epsilon$ as the empty usage context where all usages are $(\zero \comma \zero)$.
  The typing derivation creates a new channel with usage $(\one \comma \one)$.
  This channel transmits $\li$ multiplicities of a type $\channel{\unit}{\omega}$.
  The right-hand subprocess creates a channel with usage $(\one \comma \one)$.
  This channel transmits $\omega$ multiplicities of a type $\unit$.
  Part of this channel ($(\one \comma \zero)$) is sent over the channel created by the parent process.
  
  \begin{lstlisting}[mathescape]
  $p$ : $\Process_1$
  $p$ = $\new{} (\comp{\recv{\constr{0}} (\recv{\constr{0}} \PO)}
                    {\new{} (\send{\constr{suc} \; \constr{0}} {\constr{0}} (\send{\constr{0}}{\constr{suc} \; \constr{suc} \; \constr{0}}) \; \PO)})$

  _ : $\types{\constr{[]} \comma \unit}{\constr{[]} \comma \omega}{p}{\epsilon}$
  _ = $\constr{chan} \; \channel{\unit}{\omega} \; \li \; \one$
      $(\constr{comp} \;
       (\constr{recv} \; \constr{here} \; (\constr{recv} \; \constr{here} \; \constr{end}))$
           $(\constr{chan} \; \unit \; \omega \; \one \; (\constr{send} \; (\constr{there} \; \constr{here}) \; \constr{here} \; (\constr{send} \; \constr{here} \; (\constr{there} \; \constr{here} \; \constr{there}) \; \constr{end})))
       )$
  \end{lstlisting}
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Type Safety}
\label{type-safety}

\todo{intro}

\subsection{Framing}
\label{framing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Framing captures the idea that the well-typedness of a process is independent of its leftover resources.

\begin{nitheorem}
  \label{thm:framing}
  Let $P$ be a well-typed process $\types{\gamma}{\Gamma_l}{P}{\Xi_l}$.
  Then, per \autoref{lm:types-op}, there exists some $\Delta$ such that $\opctx{\Gamma_l}{\Delta}{\Xi_l}$.
  Take arbitrary contexts $\Gamma_r$ and $\Xi_r$ such that $\opctx{\Gamma_r}{\Delta}{\Xi_r}$.
  Then $\types{\gamma}{\Gamma_r}{P}{\Xi_r}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Weakening}
\label{weakening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Inserting a new variable into the context preserves the well-typedness of a process as long as the usage annotation of the inserted variable is preserved as a leftover.

\begin{nitheorem}
  \label{thm:weakening}
  Let $\func{insert}_i$ insert an element into a context at position $i$ --- for simplicity, we use it both to insert types into typing contexts and usage annotations into usage contexts.
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then lifting every variable greater than or equal to $i$ in $P$ is well-typed under $\types{\func{insert}_i \; t \; \gamma}{\func{insert}_i \; x \; \Gamma}{\func{lift}_i \; P}{\func{insert}_i \; x \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Strengthening}
\label{strengthening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Removing an unused variable preserves the well-typedness of a process.
We say a variable is \emph{unused} within a process if neither inputs nor outputs refer to it.

\begin{remark}
  It is possible for the usage annotations of a variable $i$ within a process $P$ to be preserved as leftovers, yet for the variable $i$ to be mentioned within $P$ --- $P$ can choose to send $\lz$ usage annotations of $i$ over a channel.
\end{remark}

\begin{nitheorem}
  \label{thm:strengthening}
  Let $\func{delete}_i$ delete the element at position $i$ from a context --- for simplicity, we use it both to delete types from typing contexts and usage annotations from usage contexts.
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let $i$ be a variable index not mentioned by $P$, such that $\Unused_i \; P$.
  Then lowering every variable greater than or equal to $i$ in $P$ is well-typed under $\types{\func{delete}_i \; \gamma}{\func{delete}_i \; \Gamma}{\func{lower}_i \; P}{\func{delete}_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Swapping}
\label{swapping}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Swapping two variables preserves the well-typedness of a process.

\begin{remark}
  We limit ourselves to the swapping of adjacent variables $i$ and $\suc i$.
  Doing so is enough to prove subject reduction.
  More generally, any two variables can be swapped by performing a series of adjacent variable swappings.
\end{remark}

\begin{nitheorem}
  \label{thm:swapping}
  Let $\func{swap}_i$ be a function that swaps variables $i$ and $\suc i$.
  For simplicity, we overload $\func{swap}$ and use it to swap types in a typing context, multiplicities in a usage context, and variable references in a process.
  \todo{}
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then $\types{\func{swap}_i \; \gamma}{\func{swap}_i \; \Gamma}{\func{swap}_i \; P}{\func{swap}_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Subject Congruence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{subject-congruence}

\begin{nitheorem}
  \label{thm:subject-congruence}
  Applying structural congruence rules to a well-typed process preserves its well-typedness.
  That is, if $P \eq{r} Q$ and $\types{\gamma}{\Gamma}{P}{\Xi}$, then $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  By induction on \textsc{Equals}.
  The base cases under $\constr{struct}$ (and their symmetric variants under $\constr{sym}$) are the nontrivial ones.
  For those, we proceed by induction on \textsc{StructCong}:
  \begin{itemize}
    \item
      The case $\constr{comp-assoc}$ is trivial: leftover typing is naturally associative.
    \item
      In the $\constr{comp-sym}$ case for a process $\comp{P}{Q}$, we need framing (\autoref{thm:framing}) to shift the output context of $P$ to the one of $Q$; and the input context of of $Q$ to the one of $P$.
      The point at which $Q$ and $P$ join in $\comp{Q}{P}$ will no longer be the same.
    \item
      The case $\constr{comp-end}$ is trivial: the typing rule for a process $\PO$ has the same input and output contexts.
    \item
      In the $\constr{scope-end}$ case, we show that the usage annotation of the newly created channel must be $\lz$, making the proof trivial.
      In the opposite direction, we instantiate the newly created channel to a type $\unit$ and a usage annotation $\lz$..
    \item
      In the $\constr{scope-ext}$ case for a process $\new \comp{P}{Q}$, we use \autoref{lm:types-unused} to show that $P$ preserves the usage annotations of the unused variable.
      We then use strengthening (\autoref{thm:strengthening}) to delete the unused variable from $P$, and compose the result with typing derivation on $Q$ wrapped in $\constr{chan}$.
      In the reverse direction, we weaken (\autoref{thm:weakening}) $P$ so that it accepts the additional variable.
      We then use \autoref{lm:lower-lift} to show that lowering and then lifting $P$ results in $P$.
    \item
      In the $\constr{scope-comm}$ case, we use swapping (\autoref{thm:swapping}).
      In the reverse direction, we use swapping and then \autoref{lm:swap-swap} to show that swapping two elements in $P$ twice leaves $P$ unchanged.
  \end{itemize}
\end{proof}

\subsection{Substitution}
\label{substitution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\autoref{thm:subst-generalization} proves a generalized version of substitution, where the substitution $\subst{P}{j}{i}$ is on any variable $i$.
\autoref{thm:substitution} instantiates the generalized version to the concrete case where $i$ is $\constr{0}$, as required by subject reduction.

\begin{nitheorem}
  \label{thm:subst-generalization}
  Let process $P$ be well-typed such that $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$,
  Let $\ni_i m$ be a \textsc{VarRef} $\contains{\gamma}{\Gamma_i}{i}{t}{m}{\Gamma}$ for some $m$ and $\Gamma$.
  Let $\ni_i n$ be a \textsc{VarRef} $\contains{\gamma}{\Psi_i}{i}{t}{n}{\Psi}$ for some $m$ and $\Psi$.
  Let $\Gamma$ and $\Psi$ be related such that $\opctx{\Gamma}{\Delta}{\Psi}$ for some $\Delta$.
  Let $\Delta$ have a usage annotation $\lz$ at position $i$.
  Let $\ni_j m$ be a \textsc{VarRef} $\contains{\gamma}{\Gamma_j}{j}{t}{m}{\Gamma}$ for some $\Gamma_j$.
  Let $\ni_j n$ be a \textsc{VarRef} $\contains{\gamma}{\Psi_j}{j}{t}{n}{\Psi}$ for some $\Psi_j$.
  Then substituting $i$ with $j$ in $P$ will be well-typed such that $\types{\gamma}{\Gamma_j}{\subst{P}{j}{i}}{\Psi_j}$.
  Refer to \autoref{fig:subst} for a diagramatic representation.
\end{nitheorem}

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,6)   {$\Gamma_i$};
      \node (gamma-m)   at (0,3)   {$\Gamma$};
      \node (gamma-j) at (0,0)   {$\Gamma_j$};
      \node (xi-i)    at (3,5.5) {$\Xi_i$};
      \node (theta)   at (3,3.3) {$\Theta$};
      \node (delta-m) at (3,2.7) {};
      \node (xi-j)    at (3,0.5) {$\Xi_j$};
      \node (psi-i)   at (6,5)   {$\Psi_i$};
      \node (psi-m)   at (6,3)   {$\Psi$};
      \node (psi-j)   at (6,1)   {$\Psi_j$};

      \draw[-]  (gamma-m) -- (delta-m.center);
      \draw[->] (delta-m.center) -- node[align=center,below] {$\Delta$\\$\Delta_i = \lz$}(psi-m);

      \draw[->,densely dotted] (gamma-m) -- (theta);
      \draw[->,densely dotted] (theta) -- (psi-m);
      
      \draw[->] (gamma-i) -- node[left] {$\ni_i m$} (gamma-m);
      \draw[->] (gamma-j) -- node[left] {$\ni_j m$} (gamma-m);
      \draw[->] (psi-i) -- node[right] {$\ni_i n$} (psi-m);
      \draw[->] (psi-j) -- node[right] {$\ni_j n$} (psi-m);

      \draw[->] (gamma-i) -- node[above] {$\vdash P$} (xi-i);
      \draw[->] (xi-i) -- node[above] {$\vdash Q$} (psi-i);
      \draw[->,densely dotted] (gamma-j) -- node[below] {$\vdash \subst{P}{j}{i}$} (xi-j);
      \draw[->,densely dotted] (xi-j) -- node[below] {$\vdash \subst{Q}{j}{i}$} (psi-j);
      \draw[->,densely dotted] (xi-i) -- node[left] {$\ni_i l$} (theta);
      \draw[->,densely dotted] (xi-j) -- node[left] {$\ni_j l$} (theta);
    \end{tikzpicture}
    \caption{
      Diagrammatic representation of the inductive substitution lemma.
      Continuous lines represent known facts, dotted lines proof obligations.
    }
    \label{fig:subst}
  \end{subfigure}
  \hspace{\fill} % DO NOT LEAVE EMPTY LINE
  \begin{subfigure}{.4\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,4)   {};
      \node (gamma-m) at (0,2)   {};
      \node (gamma-j) at (0,0)   {};
      \node (xi-i)    at (2,5)   {};
      \node (xi-m)    at (2,3.5) {};
      \node (xi-j)    at (2,2)   {};
      \node (psi-m)   at (4,3.5) {};

      \draw[->] (gamma-i) -- (xi-j);
      \draw[->] (gamma-m) -- (xi-j);
      \draw[->,densely dotted] (gamma-j) -- (xi-j);
      \draw[->] (gamma-i) -- (gamma-m);
      \draw[->] (gamma-j) -- (gamma-m);
      \draw[->] (xi-i)    -- (xi-m);
      \draw[->] (xi-j)    -- (xi-m);
      \draw[->] (xi-i)    -- (psi-m);
      \draw[->] (xi-m)    -- (psi-m);
      \draw[->,densely dotted] (xi-j)    -- (psi-m);
    \end{tikzpicture}
    \caption{
      Alternative approach without arrows $\ni_i n$ and $\ni_j n$.
      This approach makes composing typing derivations before and after substitution more difficult.
    }
    \label{fig:subst-alternative}
  \end{subfigure}
  \caption{Substitution with and without the \emph{adjustment} arrows $\ni_i n$ and $\ni_j n$}
\end{figure}

\begin{nidefinition}
  For convenience, we use $\containsusage{\Gamma}{i}{x}{\Delta}$ to stand for $\contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}$ for some $\gamma$ and $t$.
\end{nidefinition}
  
\begin{proof}
  By induction on the derivation $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$.
  \begin{itemize}
    \item
      For constructor $\constr{end}$ we get $\Gamma_i \equiv \Psi_i$.
      From $\Delta_i \equiv \lz$ follows that $m \equiv n$.
      Therefore $\Gamma_j \equiv \Psi_j$ and $\constr{end}$ can be applied.

    \item
      For constructor $\constr{chan}$ we proceed inductively, wrapping arrows $\ni_i m$, $\ni_j m$, $\ni_i n$ and $\ni_j n$ with $\constr{there}$.
      
    \item
      For constructor $\constr{recv}$ we must split $\Delta$ to proceed inductively on the continuation.
      Observe that given the arrow from $\Gamma_i$ to $\Psi_i$ and given that $\Delta$ is $\lz$ at index $i$, there must exist some $\delta$ such that $\opsquared{m}{\delta}{n}$.
 l     \begin{itemize}
        \item
          If the input is on the variable being substituted, we split $m$ such that $\opsquared{m}{\li}{l}$ for some $l$, and construct an arrow $\containsusage{\Xi_i}{i}{l}{\Gamma}$ for the inductive call.
          Similarly, we construct for some $\Xi_j$ the arrows $\containsusage{\Gamma_j}{j}{\li}{\Xi_j}$ as the new input channel, and $\containsusage{\Xi_j}{j}{l}{\Gamma}$ for the inductive call.
        \item
          If the input is on a variable $x$ other than the one being substituted, we construct the arrows $\containsusage{\Xi_i}{i}{m}{\Theta}$ (for the inductive call) and $\containsusage{\Gamma}{x}{\li}{\Theta}$ for some $\Theta$.
          We then construct for some $\Xi_j$ the arrows $\containsusage{\Gamma_j}{x}{\li}{\Xi_j}$ (the new output channel) and $\containsusage{Xi_j}{j}{m}{\Theta}$ (for the inductive call).
          Given there exists a composition of arrows from $\Xi_i$ to $\Psi$, we conclude that $\Theta$ splits $\Delta$ such that $\opctx{\Gamma}{\Delta_1}{\Theta}$ and $\opctx{\Theta}{\Delta_2}{\Psi}$.
          As $\lz$ is a minimal element, then $\Delta_1$ must be $\lz$ at index $i$, and so must $\Delta_2$.
      \end{itemize}

    \item
      $\constr{send}$ applies the ideas outlined for the $\constr{recv}$ constructor to both the \textsc{VarRef} doing the output, and the \textsc{VarRef} for the sent data.

    \item
      For $\constr{comp}$ we first find a $\delta$, $\Theta$, $\Delta_1$ and $\Delta_2$ such that $\containsusage{\Xi_i}{i}{\delta}{\Theta}$ and $\opctx{\Gamma}{\Delta_1}{\Theta}$ and $\opctx{\Theta}{\Delta_2}{\Psi}$.
      Given $\Delta$ is $\lz$ at index $i$, we conclude that $\Delta_1$ and $\Delta_2$ are too.
      Observe that $\opsquared{m}{\delta}{\psi}$, where $\psi$ is the usage annotation at index $i$ consumed by the subprocess $P$.
      We construct an arrow $\containsusage{\Xi_j}{j}{\delta}{\Theta}$, for some $\Xi_j$.
      We can now make two inductive calls (on the derivation of $P$ and $Q$) and compose their results.
  \end{itemize}  
\end{proof}


\begin{nitheorem}
  \label{thm:substitution}
  Let $P$ be a process typed under $\types{\gamma \comma t}{\Gamma \comma m}{P}{\Psi \comma \lz}$.
  Let $\ni_j m$ be a \textsc{VarRef} $\contains{\gamma}{\Psi}{j}{t}{m}{\Xi}$.
  Then, we can substitute the variable references to $\constr{0}$ in $P$ with $\suc j$ so that the result is well-typed under $\types{\gamma \comma t}{\Gamma \comma m}{\subst{P}{\suc j}{\constr{0}}}{\Xi \comma m}$.
\end{nitheorem}
\begin{proof}
  Use framing to derive $\contains{\gamma}{\Gamma}{j}{m}{\Theta}$ and $\types{\gamma \comma t}{\Theta \comma m}{P}{\Xi \comma \lz}$ for some $\Theta$.
  Supply these to the generalised \autoref{thm:subst-generalization}.
\end{proof}

\subsection{Subject Reduction}
\label{subject-reduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

In the linear \picalc{} reduction affects the usage context: communicating over a channel takes away $\one$ input and $\one$ output multiplicity.

\begin{nitheorem}
  Let $P \reduce{c} Q$.
  If $c$ is $\constr{internal}$, then $\Gamma' \equiv \Gamma$.
  If however $c$ is $\constr{external}\; i$, then $\containsusage{\Gamma'}{i}{\lio}{\Gamma}$.
  Given $\types{\gamma}{\Gamma'}{P}{\Xi}$ then after reduction $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  \hfill{}\\
  \begin{itemize}
    \item
    In the $\constr{comm}$ case we apply framing (\autoref{thm:framing}) to rearrange the assumptions in \autoref{fig:subject-reduction:a} into the proofs in \autoref{fig:subject-reduction:b}.
    We then apply substitution (\autoref{thm:substitution}) and strengthening (\autoref{thm:strengthening}).

    \begin{figure}[h]
      \begin{subfigure}{.5\textwidth}
        \begin{alignat*}{2}
          \containsusage{&\Gamma'}{i}{\lio &&}{\Gamma} \\
          \contains{\gamma}{&\Gamma'}{i}{\channel{t}{m}}{\li &&}{\Psi} \\
          \types{\gamma \comma t}{&\Psi \comma m}{P &&}{\Delta \comma \lz} \\
          \contains{\gamma}{&\Delta }{i}{\channel{t}{m}}{\lo &&}{\Theta} \\
          \contains{\gamma}{&\Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Initial assumptions.}
        \label{fig:subject-reduction:a}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{alignat*}{2}
          \types{\gamma \comma t}{& \Gamma \comma m}{P &&}{\Theta \comma \lz} \\
          \contains{\gamma}{& \Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Shift witness for $\lo$ and merge with the one for $\li$ into $\lio$.}
        \label{fig:subject-reduction:b}
      \end{subfigure}
    \end{figure}
  
    \item
    Reduction under $\constr{par}$ proceeds by induction on the process that is being reduced.

    \item
    Reduction under scope restriction case splits on the channel $c$ on which communication occurs.
    If $c$ is $\constr{internal}$ subject reduction proceeds inductively.
    If $c$ is $\constr{external}\; \constr{0}$ -- i.e. the channel that is being introduced by the scope restriction -- we use \autoref{lm:comm-capable} to subtract $\lio$ from the channel's usage annotation and then apply the induction hypothesis.
    If $c$ is $\constr{external}\; (\suc i)$ subject reduction proceeds inductively.

    \item
    In the $\constr{struct}$ case, we apply subject congruence (\autoref{thm:subject-congruence}) and the induction hypothesis.
  \end{itemize}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

This work is heavily based on the work by Allais \cite{Allais2018a}.
Allais uses leftover typing to build a bidirectional type system for the linear \lambdacalc{}.
He proves type preservation and provides a procedure that decides type checking and type inference.
He then goes on showing the soundness and completeness with respect to the sequent calculus for intuitionistic linear logic.

\cite{Thiemann2019}
\cite{Rouvoet2020}
\cite{Veltri2020}

\cite{previous-work} polymorphic tokens, HOAS

\cite{LTS-semantics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permitting:

\begin{description}

\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

  Bidirectional typing rules needed.

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}

\newpage
\bibliography{paper}

%%
\newpage
\appendix
\input{appendix.tex}
\end{document}
