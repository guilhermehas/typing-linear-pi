\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage{mathtools}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Example code
\usepackage{listings}

% Diagrams
\usepackage{tikz}

% Mathbb doesn't support digits
\usepackage{bbm}

% Less margins around figures
\usepackage{changepage}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

% Do not use italics in definitions and theorems
\theoremstyle{definition}
\newtheorem{nidefinition}[theorem]{Definition}
\newtheorem{nitheorem}[theorem]{Theorem}
\newtheorem{nilemma}[theorem]{Lemma}

% No line numbers
\nolinenumbers

% Abbreviations
\newcommand{\lambdacalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}

% Typing rules
\newcommand{\stacked}[1]{\mprset{flushleft} \inferrule*{}{#1}}
\newcommand{\datatype}[2]{{\mprset{fraction={===}} \inferrule{#1}{#2}}}

\newcommand{\type}[1]{\textcolor{blue}{\operatorname{#1}}}
\newcommand{\constr}[1]{\textcolor{olive}{\operatorname{#1}}}
\newcommand{\field}[1]{\textcolor{red}{\operatorname{#1}}}

% Constructors
\newcommand{\PO}{\constr{\mathbf{0}}}
\newcommand{\comp}[2]{#1 \; \constr{\parallel} \; #2}
\newcommand{\new}{\constr{\boldsymbol{\nu}} \;}
\newcommand{\send}[2]{#1 \; \constr{\langle} \; #2 \;\constr{\rangle} \;}
\newcommand{\recv}[1]{#1 \; \constr{\mathbb{()}} \;}
\newcommand{\suc}{\constr{\scriptstyle 1+}}
\newcommand{\unit}{\constr{\mathbbm{1}}}
\newcommand{\base}[1]{\constr{B[} \; #1 \; \constr{]}}
\newcommand{\channel}[2]{\constr{C[} \; #1 \; \constr{\propto} \; #2 \; \constr{]}}
\newcommand{\comma}{\; \constr{,} \;}

% Functions
\newcommand{\subst}[3]{#1 \; [ \; #2 \; / \;#3 \;]}
\newcommand{\opsquared}[3]{#1 \, \coloneqq \, #2 \, \cdot^2 \, #3}
\newcommand{\opctx}[3]{#1 \, \coloneqq \, #2 \, \otimes \, #3}

% Fields
\newcommand{\op}[3]{#1 \; \field{\coloneqq} \; #2 \; \field{\cdot} \; #3}
\newcommand{\zero}{\field{0\cdot}}
\newcommand{\one}{\field{1\cdot}}
\newcommand{\li}{\ell_i}
\newcommand{\lo}{\ell_o}
\newcommand{\lz}{\ell_{\o}}
\newcommand{\lio}{\ell_{\#}}

% Types
\newcommand{\Set}{\type{SET}}
\newcommand{\reduce}[1]{\; \type{\longrightarrow}_{#1} \;}
\newcommand{\types}[4]{#1 \; \type{\propto} \; #2 \; \type{\vdash} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\contains}[6]{#1 \; \type{\propto} \; #2 \; \type{\ni}_{#3} \; #4 \; \type{\propto} \; #5 \; \type{\boxtimes} \; #6}
\newcommand{\containsusage}[4]{#1 \; \type{\ni}_{#2} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\Var}{\type{VAR}}
\newcommand{\Process}{\type{PROCESS}}
\newcommand{\Unused}{\type{UNUSED}}
\newcommand{\PreCtx}{\type{PRECTX}}
\newcommand{\Ctx}{\type{CTX}}
\newcommand{\Type}{\type{TYPE}\;}
\newcommand{\Idx}{\type{IDX}\;}
\newcommand{\Idxs}{\type{IDXS}}
\newcommand{\Carrier}{\type{CARRIER}}
\newcommand{\N}{\type{\mathbb{N}}}
\newcommand{\Channel}{\type{CHANNEL}}
\newcommand{\Rec}{\type{REC}}
\newcommand{\Quantifier}{\type{QUANTIFIER}}
\newcommand{\eq}[1]{\; \type{=}_{#1} \;}
\newcommand{\eqeq}{\; \type{\equiv} \;}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{$\pi$ with leftovers: \\ a mechanisation in Agda \thanks{Supported by the UK EPSRC grant EP/K034413/1, ``From Data Types to Session Types: A Basis for Concurrency and Distribution'' (ABCD), and by the EU HORIZON 2020 MSCA RISE project 778233
``Behavioural Application Program Interfaces'' (BehAPI).}
}
\titlerunning{$\pi$ with leftovers: all mechanisation in Agda}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi-calculus, linear types, leftover typing, concurrency, mechanization, Agda}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{We want to thank Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
  The \picalc{} is a computational model for communication and concurrency.
  The \emph{linear} \picalc{} is a typed version of the \picalc{} where channel resources must be used exactly once.
  With the rise of session types as a formalism to model real-world distributed systems, the linear \picalc{} has re-emerged as the underlying theoretical and practical framework for session types and communication-based distributed programming \cite{DardhaGS12,Padovani17,ScalasY16,ScalasDHY17}.
  While there have been several extensions to the session typed \picalc{}, the linear \picalc{} remains essentially unchanged and stable as a foundational calculus.

  We present the \emph{first} fully mechanised \picalc{} featuring linear types, as well as gradual and shared types.
  We present its syntax, operational semantics, and typing rules and the corresponding type safety properties.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalise the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  Our formalisation is fully mechanised in Agda. \cite{Zalakain2020Agda}
\end{abstract}

\todo{rename Scoped to Process in code}
\todo{make sure all citations are there}
\todo{change colors, color functions}
\todo{do not distinguish fields from functions, it is not worth it}
\todo{go over guillaume's paper again}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
% The way I want to write the intro:
% -- describe what is the picalc and why it is IMPORTATNT
% -- describe what are linear types and why programming with them is IMPORTATNT
% -- join together by saying that is why we focus on linear pi calculus but we do more than just that: we have linear, gradual and shared types
% -- put emphasis on mechanisation in Agda

We live in a concurrent world where any given state is often computed interactively by a myriad of parties --- people, machines, processors, services, networks.
As humans, we aim to model, predict, and build such interactive systems; as mathematicians, abstraction is our tool of choice to do so.

The \picalc{} \cite{MilnerPW92,Milner99} is the most successful computational model for communication and concurrency.
It abstracts over the details of concurrent processing and boils the interactions down to the sending and receiving of data through communication channels.
Notably, it features \emph{channel mobility}: the channels themselves are first order constructs, and can therefore be transmitted.
The \picalc{} is at the basis of design and implementation of programming languages for concurrency, such as Pict \cite{Pierce} and more recently Go \cite{Golang}.
Moreover, at the state-of-the-art, the \picalc{} features a wide plethora of types, ranging from basic types, linear types, types for liveness properties, such as deadlock freedom, livelock freedom or termination, and most notably, session types \cite{K07}, making the \picalc{} a fully-fledged tool for modelling and verification of concurrent and distributed systems.

In a parallel track, the discovery of linear logic by J.-Y. Girard \cite{Girard87} opened new avenues in computing science in the early '90s and introduced \emph{linear types} for (functional) programming languages \cite{Curry-Howard,Wadler90,Bernardy2018}.
Linear type systems restrict the usage of resources to \emph{exactly ones}.
Enforcing ``no duplicating'' and ``no discarding'' of resources via linearity, allows for resource-aware programming and efficient implementation \cite{Wadler90}.
Later on, linearity inspired unique types, as in Clean \cite{BarendsenS96} or ownership types, as in Rust \cite{MatsakisK14}.

The \picalc{} also benefited from this linearity wave in early '90s.
Kobayashi et al. \cite{KPT96} defined the {linear} \picalc{}, which is a typed version of the \picalc{} where the linear type system restricts the usage of channels to {exactly ones}.

In the meantime, the rise of session types \cite{H93,THK94,HVK98} gave linearity in the \picalc{} a different flavour.
Session types are a type formalism used in communication-centric programming and the \picalc{} is the original and still
the most successful framework where session types are defined.
Linearity in session types means that a channel can be owned only by one communicating participant, but the channel itself can be used multiple times, as specified by the structure of a session type.
Linearity in session types is a key ingredient in order to guarantee type safety.

Recent work \cite{DardhaGS12,Dardha14,DardhaGS17} turned again the spotlight on the linear \picalc{} \cite{KPT96}, via an encoding of session types into linear types.
This encoding not only has theoretical benefits in terms expressivity of session types and reusability of theoretical results from the linear \picalc{}, but most importantly it is useful at a practical level.
The encoding has been used as a technique to implement session types in mainstream programming languages such as OCaml \cite{Padovani17} or Scala \cite{ScalasY16,ScalasDHY17}.
This means we can use the linear \picalc{} as an underlying theoretical and practical framework on top of which we can build session types.

Considering the importance of the \picalc{} and linearity in modelling concurrent and distributed systems, in this paper we focus our investigation on both and go beyond.
We present for the first time a full mechanisation in Agda of a \picalc{} with linear, gradual and shared types all under the same unified framework.

In order to obtain this unification of type systems, we use leftover typing for the first time in the \picalc{}, following Allais \cite{Allais2018a}.
The user can choose among the possible type systems by instantiating our $\pi$ with leftovers, which gives as a result one of the three typed $\pi$s.
Ultimately, we can use $\pi$ with leftovers as a unified framework for type safe distributed modelling and programming with a range of type systems, on top of which we can build more advanced types, theories and languages.
While linearity is needed for type safety, gradual types and shared types are needed to build real-world systems.

\subsection{Contributions}
Our contributions are given in the following together with the corresponding sections.
\begin{itemize}
  \item \textbf{Machine verified formalisation of the syntax and semantics of the \picalc{}}: The syntax for the \picalc{} is given in \S \ref{syntax}.
  We use de Bruijn indices \cite{} as variable references, and dependent types to make the syntax well-scoped by construction: every free variable is accounted for in the type of the process that uses it.
  We define the operational semantics of the \picalc{} by a reduction relation in \S \ref{operational-semantics}.
  The base case of every such reduction is communication over a channel; we take care to track this information at the type level so that we can then use it for subject reduction (aka type preservation) theorem.

  \item \textbf{Machine verified typing with leftovers for the \picalc{} with linear, gradual and shared types}:
  Linear type systems need of context splits.
  These are tricky to handle constructively without explicitly asking the user to supply them.
  Leftover typing \cite{} is a type theoretical technique that addresses this.
  It does so by carrying both an input and an output context (the leftovers).
  The output context can then be used as the input context of the continuations.
  We apply this technique to the \picalc{} in \S \ref{leftover-typing}.
  We generalize our algebra on usage multiplicities in \S \ref{multiplicities}.
  As a result, we are able to model a mix of shared, linear, and gradual types.
  \todo{reformulate paragraph}
  Another property of particular interest in concurrent and distributed systems is the avoidance of race conditions.
  A type system that excludes multiple usages of a resource excludes race conditions. Linear \picalc{} not only avoids races, but ensures \emph{communication privacy}: if both endpoints of a channel are acquired no other process can eavesdrop.
  It also ensures that every declared communication channel must be used.
  We provide a typing system for the linear \picalc{} in \S \ref{type-system} as extensional rules on sitting on top of the unruly well-scoped syntax.
  
  \item \textbf{Machine verified proofs of subject reduction and auxiliary lemmas for all $\pi$ with leftovers}:
  
  \item \textbf{Full formalisation in Agda available at \cite{Zalakain2020Agda}}:
\end{itemize}

%\paragraph*{Syntax}
%In the \lambdacalc{} all computations are local and happen on syntactically contiguous terms; in the \picalc{} however communicating subprocesses can be non-contiguous and even have different parent processes.
%One way to define a reduction relation modulo these syntactic minutiae is to define a structural congruence \cite{} relation that acts as a quotient type.
%A term $A$ can then be freely rewritten into a term $B$ as long as $A$ is structurally congruent to $B$.


%\paragraph*{Semantics}
% In the \lambdacalc{} function application is the main computational engine; in the \picalc{} it is inter-process communication what drives computation.
% Two subprocesses can communicate anywhere in a process but under input and output, which must be respected to ensure the sequential behavior.
% We type a reduction relation that acts as an operational semantics modulo subject congruence in \S \ref{operational-semantics}.
% The base case of every such reduction is communication over a channel; we take care to track this information at the type level so that we can then use it to state the theorem for subject reduction (aka type preservation).

% As with the untyped \lambdacalc{}, the untyped \picalc{} can be used to construct a wide variety of ill-behaved terms --- for some characterization of ill-behaved.
% One can use type systems to constructively obtain a subset of terms for which certain properties hold.
% As an example, the simply typed \lambdacalc{} ensures that the argument supplied to a function is of the expected type.
% Correspondingly, the simply typed \picalc{} \cite{} ensures that the data sent over a channel is of the expected type.
% This property is often referred to as \emph{communication safety}.

% \todo{Mention that our semantics is prior to our typing (Curry-style)}

% Another property of particular interest to concurrent systems is the avoidance of race conditions.
% A type system that excludes multiple usages of a resource excludes race conditions.
% In the linear \picalc{} \cite{} channels must be used exactly once.
% This not only avoids races, but ensures \emph{communication privacy}: if both endpoints of a channel are acquired no other process can eavesdrop.
% It also ensures that every declared communication channel must be used.
% The linear \picalc{} is also interesting because together with product types it is isomorphic to session types \cite{} -- which are used to encode communication protocols.
% We provide a typing system for the linear \picalc{} in \S \ref{type-system} as extensional rules on sitting on top of the unruly well-scoped syntax.

% \paragraph*{Typing with leftovers}
% Linear type systems need of context splits.
% These are tricky to handle constructively without explicitly asking the user to supply them.
% Leftover typing \cite{} is a type theoretical technique that addresses this.
% It does so by carrying both an input and an output context (the leftovers).
% The output context can then be used as the input context of the continuations.
% We apply this technique to the \picalc{} in \S \ref{leftover-typing}.
% We generalize our algebra on usage multiplicities in \S \ref{multiplicities}.
% As a result, we are able to model a mix of shared, linear, and gradual types.
% \todo{reformulate paragraph}


\subsection{Notation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\type{\N} : \Set}
    \; \textsc{Nat}

    \inferrule
    { }
    {\constr{0} : \type{\N}}

    \inferrule
    {n : \type{\N}}
    {\suc n : \type{\N}}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Data type definitions have double lines and index-free synonyms as rule names (for ease of reference).
We otherwise use the constructor name as the name of a typing rule.
Universe levels and universe polymorphism are omitted for brevity --- all our types are of type $\Set$.
Implicit arguments are mentioned by type definitions but omitted in constructors.
$\type{TYPES}$ are in blue and uppercased (with indices as subscripts), $\constr{constructors}$ are in olive, $\field{fields}$ in red, and variables and functions in black.
Some constructor names are overloaded --- they and disambiguated by context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}
\label{syntax}

In the \picalc{} both scope restriction and input introduce abstractions.
The bodies of these constructs need a way of referring to their argument.
Using names as variable references is a popular option amongst humans.
However, names are cumbersome to mechanize: inserting a new variable into a context means proving that the name of such variable is different to all other variable names in context.
Moreover, names are of no significance to machines whatsoever.

The idea de Bruijn had \cite{} was to use a natural number $n$ (aka \emph{index}) to refer to the variable introduced $n$ binders ago --- and to have binders no longer introduce names.
\begin{example}
\hfill{}\\
The \picalc{} term \hfill{} $(\textbf{new} \; x) (x ( y ) . y \langle \texttt{"Hello world!"} \rangle . \mathbf{0} \parallel (\textbf{new} \; y) (x \langle y \rangle . y ( z ) .\mathbf{0}))$ \\ is represented as \hfill{} $(\textbf{new}) (0 () . 0 \langle \texttt{"Hello world!"} \rangle . \mathbf{0} \parallel (\textbf{new}) (1 \langle 0 \rangle . 0 () . \mathbf{0}))$.
\end{example}
That is, terms at different \emph{depths} use different indices to refer to the same binding.
Humans may find this confusing.
There is however no reason not to annotate these indices with the original names bestowed upon them by humans.
Machines can then manipulate references mechanically whilst using names to present terms to humans.

A variable occurring under $n$ abstractions has $n$ possible variables to refer to.
References outside of that range are meaningless.
It is useful to rule out these nonsensical terms syntactically.
In Figure \ref{fig:var} we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Var_n : \Set}
  \; \textsc{Var}

  \inferrule
  {n : \N}
  {\constr{0} : \Var_{\suc n}}

  \inferrule
  {x : \Var_n}
  {\suc x : \Var_{\suc n}}
\end{mathpar}
\caption{Types of size $n$}
\label{fig:var}
\end{figure}

Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
As shown in Figure \ref{fig:syntax}, we increase the \emph{depth} counter every time we create a new channel or receive some input.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Process_n : \Set}
  \; \textsc{Process}
\end{mathpar}
  
\begin{equation*}
\begin{split}
  \Process_n ::=& \; \PO_n                    \\
              |& \; \new{} \Process_{\suc n}          \\
              |& \; \comp{\Process_n}{\Process_n}          \\
              |& \; \recv{\Var_n}{}\Process_{\suc n} \\
              |& \; \send{\Var_n}{\Var_n}\Process_n
\end{split}
\end{equation*}
\caption{Well-scoped grammar using de Bruijn indices}
\label{fig:syntax}
\end{figure}

Using type-level de Bruijn indices makes our syntax well-scoped by construction --- the semantics of our language can now be defined on the totality of the syntax.
User-friendliness can still be recovered through a function that converts processes with named variables into (possibly) processes with indexed variables.
This function recursively traverses processes, keeping track of what name is associated with each index.
If the process is ill-scoped, the function returns nothing.
To present things to the user, we substitute indices by their related names.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
\label{semantics}

In the \lambdacalc{} $\beta$-reduction operates on syntactically adjacent terms.
In the \picalc{} however, the syntax introduces unnecessary distinctions
(e.g. semantically, parallel composition is defined modulo associativity and commutativity).
There are several ways around this, a structural congruence relation being one of the historical ones \cite{}.
(Others include labeled transition systems \cite{} and higher inductive types \cite{}.)

\subsection{Structural Congruence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{structural-congruence}

Structural congruence is a congruent equivalence relation on processes.
Any two structurally congruent processes are strongly bisimilar: they are can follow each other's reduction steps \cite{}.
Figure \ref{fig:struct-cong-base} lists the base cases of structural congruence.
The type $\Unused_i \; Q$ is an inductive proof that witnesses that the variable index $i$ does not appear nor in the inputs nor in the outputs of $Q$.
The function $lower_i \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $i$.
Finally, $swap_i \; P$ traverses $P$ (of type $\Process_{\suc \suc n}$) and swaps variable references $i$ and $\suc i$.
In all three, $i$ is incremented every time we go under a binder.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {P \eqeq Q : \Set}
  \; \textsc{StructCong}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{\comp{Q}{R}} \eqeq \comp{\comp{P}{Q}}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \eqeq \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \eqeq P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \eqeq \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \, Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \eqeq \comp{(\new P)}{lower_0 \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \eqeq \new \new swap_0 \; P}
\end{mathpar}
\caption{Base cases of structural congruence.}
\label{fig:struct-cong-base}
\end{figure}

\begin{nilemma}
  \label{lm:lower-lift}
  The function $lower_i \; P \; uP$ has an inverse $lift_i \; P$ that increments every $\textsc{Var}$ greater than or equal to $i$, such that $lift_i \; (lower_i \; P \; uP) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}
  
\begin{nilemma}
  \label{lm:swap-swap}
  The function $swap_i \; P$ is its own inverse: $swap_i \; (swap_i \; P) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}

Structural congruence is a congruent equivalence relation.
As such, rewrites can happen anywhere inside a process, and are closed under reflexivity, symmetry and transitivity as shown in Figure \ref{fig:struct-cong}.
In \S \ref{subject-congruence} we prove that if two processes $P$ and $Q$ are structurally congruent and $P$ is well-typed, then so is $Q$.
In the transitivity case, we must show that if $P$ is structurally congruent to $Q$ and $Q$ is to $R$, and $P$ is well-typed, then so is $R$.
To do so, we need to proceed by induction and first get a proof of the well-typedness of $Q$, then use that to reach $R$.
To show the typechecker that the doubly recursive call terminates we index the equivalence relation $=$ by a type $\Rec$ that models the structure of the recursion.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {\Rec : \Set}
  \; \textsc{Rec}

  \inferrule
  { }
  {\constr{zero} : \Rec}
  
  \inferrule
  {r : \Rec}
  {\constr{one} \; r : \Rec}

  \inferrule
  {r \; s : \Rec}
  {\constr{two} \; r \; s : \Rec}
  
  \datatype
  {P \, Q : \Process_n \\ r : \Rec}
  {P \eq{r} Q : \Set}
  \; \textsc{Equals}

  \inferrule
  {eq : P \eqeq Q}
  {\constr{struct} \; eq : P \eq{\constr{zero}} Q}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-scope} \; eq : \new P \eq{\constr{one} \; r} \new P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-comp} \; eq : \comp{P}{Q} \eq{\constr{one} \; r} \comp{P'}{Q}}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-recv} \; eq : \recv{x}P \eq{\constr{one} \; r} \recv{x}P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-send} \; eq : \send{x}{y}P \eq{\constr{one} \; r} \send{x}{y}P'}

  \inferrule
  { }
  {\constr{refl} : P \eq{\constr{zero}} P}

  \inferrule
  {eq : P \eq{r} Q}
  {\constr{sym} \; eq : Q \eq{\constr{one} \; r} P}

  \inferrule
  {eq_1 : P \eq{r} Q \\ \; eq_2 : Q \eq{s} R}
  {\constr{trans} \; eq_1 \; eq_2 : P \eq{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.}
\label{fig:struct-cong}
\end{figure}
  
\subsection{Operational Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{operational-semantics}

Figure \ref{fig:reduction} models the operational semantics of the \picalc{}.
Processes put in parallel reduce when they communicate over a common channel.
The receiving process substitutes references to its most immediate variable with references to the variable that is being sent by the process doing the output.
The process is then \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under structural congruence and goes under parallel composition and scope restriction
--- notably, not under input nor output, or otherwise the sequencing of actions would not be preserved.
In \S \ref{subject-reduction} we prove that if $P$ reduces to $Q$ and $P$ is well-typed, so is $Q$.
However, this reduction operation is effectful: it consumes the channel over which communication occurs.
If this channel is external to $P$ (it resides in its context) then the context in which $Q$ is typed must change.
To keep track of this information, we lift the index of the channel to the type level.
We use a $dec$ function to decrement the index of the channel every time we come out of a binder.
This function saturates at $\constr{internal}$ --- meaning communication happens internally to the process.


\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Channel_n : \Set}
  \; \textsc{Channel}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  \datatype
  {i : \Channel_n \\ P \; Q : \Process_n}
  {P \reduce{i} Q : \Set}
  \; \textsc{Reduces}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce{\constr{external} \; i} \comp{lower_0 \; (\subst{P}{j}{0})}{Q}}

  \inferrule
  {red : P \reduce{i} P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce{i} \comp{P'}{Q}}

  \inferrule
  {red : P \reduce{i} Q}
  {\constr{res} \; red : \new P \reduce{dec\; i} \new Q}

  \inferrule
  {eq : P = P' \\ red : P' \reduce{i} Q}
  {\constr{struct} \; eq \; red : P \reduce{i} Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{fig:reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}
\label{type-system}

Typing systems for the \picalc{} ensure that processes make a correct use of their channels.
Typing judgments are of the form $\Gamma \vdash P$ (for some typing context $\Gamma$ and some process $P$) --- types only appear in the contexts of typing judgments.
A resource-aware typing system for the \picalc{} must take resource usages into account, and needs an algebra on these --- a way of \emph{splitting} resources on parallel composition, of \emph{ticking off} resources on input and output.
We characterise such an algebra in \S \ref{multiplicities}.
We define independent typing contexts and usage contexts in \S \ref{contexts}.
We provide a typing judgment for a resource-aware \picalc{} in \S \ref{leftover-typing}.

\subsection{Multiplicities and Capabilities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{multiplicities}

In the linear \picalc{} each channel has an input and an output \emph{capability}, and each capability has a given \emph{multiplicity} of 0 (exhausted) or 1 (available).
In this paper we generalize the type of multiplicities by defining an algebra any such type must comply with.
Shared, gradual and linear usage types all satisfy these algebraic laws.

\todo{we haven't introduced the forall and implicit syntax}
\begin{nidefinition}
  The algebra on multiplicities must be \emph{partial}, \emph{functional}, \emph{cancelative}, \emph{associtive}, and \emph{commutative}, and needs a \emph{minimal neutral element}.
  It also requires a special element that is to be used to count inputs and outputs.
  We define the laws of such a \emph{partial commutative monoid} as a type $\Quantifier_C$ on a carrier set $C$ in Figure \ref{fig:multiplicities} --- we use a terniary relation to model the monoidal operation.
  
  \begin{figure}[h]
  \begin{equation}
  \begin{aligned}
    &\zero                  &:{} &                      &        & C \\
    &\one                   &:{} &                      &        & C \\
    &\op{\_}{\_}{\_}        &:{} &                      &        & C \to C \to C \to \Set \\
    &\field{\cdot-compute}  &:{} &\forall y z           & \to \; & \type{DEC} \; (\type{\exists} x . \; (\op{x}{y}{z})) \\
    &\field{\cdot-unique}   &:{} &\forall \{x x' y z\}  & \to \; & \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
    &\field{\cdot-unique^l} &:{} &\forall \{x y y' z\}  & \to \; & \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
    &\field{0\cdot-min^l}   &:{} &\forall \{y z\}       & \to \; & \op{\zero}{y}{z} \to y \equiv \zero \\
    &\field{\cdot-id^l}     &:{} &\forall \{x\}         & \to \; & \op{x}{\zero}{x} \\
    &\field{\cdot-comm}     &:{} &\forall \{x y z\}     & \to \; & \op{x}{y}{z} \to \op{x}{z}{y} \\
    &\field{\cdot-assoc}    &:{} &\forall \{x y z u v\} & \to \; & \op{x}{y}{z} \to \op{y}{u}{v} \to \type{\exists} w . \; (\op{x}{u}{w} \times \op{w}{v}{z})
  \end{aligned}
  \end{equation}
  \caption{Quantifier algebra $\Quantifier_C$ algebra on a partial commutative monoid.}
  \label{fig:multiplicities}
  \end{figure}
\end{nidefinition}

\begin{note}
  We will often work with input and output multiplicities as pairs.
  We use the notation $\Carrier^2$ to stand for a $\Carrier \times \Carrier$ tuple, and $\opsquared{x}{y}{z}$ to stand for a monoidal operation on pairs of multiplicities -- where all properties are trivially lifted.
  Henceworth, we use $\lz$ to denote the pair $(0 \comma 0)$, $\li$ for the pair $(1 \comma 0)$, $\lo$ for $(0 \comma 1)$ and $\lio$ for $(1 \comma 1)$.
\end{note}

Shared, gradual and linear multiplicity types can all be defined as an instance of the properties in Figure \ref{fig:multiplicities}.
For examples of how these multiplicity types are used in typing derivations, refer to Example \ref{example-derivations}.

\begin{description}
  \item [Shared]
    The carrier $C$ is a type $\type{One}$ with a single trivial constructor $\constr{\omega}$.
    Both $\zero$ and $\one$ are instantiated to $\constr{\omega}$.
    The relation $\op{\constr{\omega}}{\constr{\omega}}{\constr{\omega}}$ is inhabited.
    All other laws are trivially satisfied.
  \item [Gradual]
    The carrier $C$ is implemented as the type of natural numbers $\N$.
    The element $\zero$ corresponds to 0, and $\one$ to 1.
    The partial monoid $\op{x}{y}{z}$ is defined exactly when $x \equiv y + z$.
    All other rules follow trivially from the algebraic rules for the addition of naturals.
  \item [Linear]
    The carrier $C$ is implemented as a type $\type{Two}$ with the trivial elements $\constr{zero}$ and $\constr{one}$.
    The monoidal operation has the element $\constr{zero}$ as neutral on both sides, and the element $\constr{one}$ splitting into $\constr{one}$ and $\constr{zero}$ (or $\constr{zero}$ and $\constr{\one}$), and is uninhabited in every other case.
    All other rules follow trivially.
\end{description}

\subsection{Contexts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{contexts}

In a resource-aware \picalc{}, usage annotations are transformed as a result of input and output; types howeverr are preserved.
In our case, usage annotations do not depend on types, and keeping types and usages in separate contexts allows for a more modular approach in our proofs.

\subsubsection{Typing Contexts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{nidefinition}
  Figure \ref{fig:prectx} defines types as either unit types, base types or channel types.
  The unit type $\unit$ serves as a proof of inhabitance for types (we can trivially obtain it), and is used to such end in subject congruence --- for the $\new \PO_{\suc n} \eqeq \PO_n$ rule.
  The base type $\base{n}$ uses a natural number $n$ to represent types.
  This natural number can then be interpreted as a type in the host language.
  Using natural numbers instead of type universes is convenient: less universe polymorphism poluting specifications.
  
  The channel type $\channel{t}{x}$ uses $t$ to stand for the type of data that is being transmitted over the channel, and $x$ to stand for what usages of that data are transmitted. 
  
  We keep track of types in a length-indexed \emph{pre-context} $\PreCtx_n$.
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Type : \Set}
    \; \textsc{Type}
  
    \inferrule
    { }
    {\unit : \Type}

    \inferrule
    {n : \N}
    {\base{n} : \Type}
  
    \inferrule
    {t : \Type \\ \stacked{idx : \Idx \\\\ x : \Carrier_{idx}}}
    {\channel{t}{x} : \Type}
  \end{mathpar}
  
  \begin{mathpar}
    \datatype
    {n : \N}
    {\PreCtx_n : \Set}
    \; \textsc{PreCtx}
  
    \inferrule
        { }
        {[] : \PreCtx_0}
  
        \inferrule
            {\gamma : \PreCtx_n \\ t : \Type}
            {\gamma \comma t : \PreCtx_{\suc n}}
  \end{mathpar}
  \caption{Types and length-indexed typing contexts.}
  \label{fig:prectx}
  \end{figure}
\end{nidefinition}

\subsubsection{Usage Contexts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

We choose to allow multiple multiplicity algebras to coexist in our typing system.
We do so by defining an indexed set of usage algebras.

\begin{nidefinition}
  An indexed set of usage algebras is a set of indices such that for every index there exists a carrier $C$ with a $\Quantifier_C$ algebra defined on it, as captured by Figure \ref{fig:indexed-multiplicities}.
  We require the index type to be inhabited -- proving subject congruence on $\new \PO_{\suc n} \eqeq \PO_n$ requires an inhabited carrier set.
  
  \begin{figure}[h]
  \begin{equation}
  \begin{split}
    &\field{IDX}          &:{} &\Set \\
    &\field{\exists IDX}  &:{} &\field{IDX} \\
    &\field{CARRIER}      &:{} &\field{IDX} \to \Set \\
    &\field{QUANTIFIERS}  &:{} &(i : \field{IDX}) \to \Quantifier_{\field{CARRIER}_i}
  \end{split}
  \end{equation}
  \caption{Indexed set of partial commutative monoids.}
  \label{fig:indexed-multiplicities}
  \end{figure}
\end{nidefinition}

\begin{nidefinition}
  A context of usages $\Ctx_{idxs}$ is indexed by a length-indexed context of indices $\Idxs_n$, as shown in Figure \ref{fig:ctx}.
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Idxs_n : \Set}
    \; \textsc{Idxs}
  
    \inferrule
        { }
        {[] : \Idxs_0}
  
    \inferrule
        {idxs : \Idxs_n \\ idx : \Idx}
        {idxs \comma idx : \Idxs_{\suc n}}
  
        \\
        
    \datatype
    {idxs : \Idxs_n}
    {\Ctx_{idxs} : \Set}
    \; \textsc{Ctx}
  
    
    \inferrule
        { }
        {[] : Ctx_{[]}}
        
    \inferrule
        {\Gamma : \Ctx_{idxs} \\ x : \Carrier_{idx} ^2}
        {\Gamma \comma x : \Ctx_{idxs \comma idx}}
  \end{mathpar}
  \caption{Length-indexed context of carrier indices with a context of multiplicities on top.}
  \label{fig:ctx}
  \end{figure}
\end{nidefinition}

\begin{note}
  We lift the monoidal operation on multiplicity pairs $\opsquared{x}{y}{z}$ to a monoidal operation $\opctx{\Gamma}{\Delta}{\Xi}$ on contexts of usages with the same underlying context of indices.
  All the properties of the partial monoid are trivially lifted.
\end{note}

\subsection{Typing with Leftovers}
\label{leftover-typing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

We make use \emph{leftover typing} \cite{}, an approach that, in addition to the usual typing context and input usage context, adds an extra output usage context to the typing rules.
This output context contains the \emph{leftovers} of the process being typed --- its unused multiplicities.
Crucially, the leftovers can then be used as an input to some othew typing derivation.
Adopting this techinque has two main advantages:
\begin{itemize}
  \item
    The input and output actions do no longer need to transform the usage context through functions, but can use a variable reference type with both an input and an output usage context to encapsulate these transformations.
  \item
    Parallel composition no longer needs an explicit context splitting proof --- a proof $\opctx{\Gamma_m}{\Gamma_l}{\Gamma_r}$ where $\Gamma_l \vdash P$, $\Gamma_r \vdash Q$ and $\Gamma_m \vdash \comp{P}{Q}$.
    Such a proof could be obtained through automated search --- but it is better yet to avoid needing it.
    With leftover typing, we use the leftovers of $P$ to type $Q$.
\end{itemize}
  
We introduce two judgments: one for variable references (Definition \ref{def:varref}), one for processes (Definition \ref{def:types}).
Both of them combine a judgment on types and a judgment on usages.
These could be kept separate, but doing so would risk incoherence: if typing derivations had any choice to make, the judgment on types could choose to do one thing while the judgment on usages chooses to do another.
The constructions instroduced in this paper make the typing derivations completely syntax directed and render this problem inexistent, but we nevertheless choose to keep both judgments as one, for simplicity.

\begin{nidefinition}
  \label{def:varref}

  The \textsc{VarRef} relation presented in Figure \ref{fig:variable-references} is indexed by a typing context and an input and output usage context.
  In addition to these, it also keeps track of its position in the contexts, its type, and its usage annotation.
  
  The base case $\constr{here}$ asserts that $t$ is the most immediate type in typing context, and splits the most immediate usage annotation $x$ in the input context into the usage annotation $y$ the usage annotation $z$ in the output context.
  This is the only place in the typing system where the algebra on multiplicities is used.

  \begin{remark}
    We use $\field{\cdot-compute}$ to aliviate the user from the proof burden $\opsquared{x}{y}{z}$.
  \end{remark}

  The inductive case $\constr{there}$ appends an extra type to the typing context, and an extra usage annotation to both the input and output usage context.

  \begin{figure}[h]
  \begin{mathpar}
    \mprset{sep=0.5em}
  
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      i : \Var_n \\
      t : \Type \\
      \stacked{
        idx : \Idx \\\\
        y : \Carrier_{idx}^2} \\
      \Delta : \Ctx_{idxs}}
    {\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta} : \Set}
    \; \textsc{VarRef}
  
    \inferrule
    {\opsquared{x}{y}{z}}
    {\constr{here} : \contains{\gamma \comma t}{\Gamma \comma x}{\constr{zero}}{t}{y}{\Gamma \comma z}}
    
    \inferrule
    {loc_i : \contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}}
    {\constr{there} \; loc_i : \contains{\gamma \comma t'}{\Gamma \comma x'}{\suc i}{t}{x}{\Delta \comma x'}}
  \end{mathpar}
  \caption{Variable reference judgments.}
  \label{fig:variable-references}
  \end{figure}
\end{nidefinition}

\begin{example}
  The following is an example that asserts that the input usage context is capable of $\li$ on a $\channel{\unit}{\li}$ type at index $\constr{suc} \; \constr{zero}$, and that consuming such $\li$ results in the stated leftovers.
  \begin{lstlisting}[mathescape,caption=Here \_ introduces an anonymous declaration that must be immediately followed by its definition.]
  _ : $\contains{\constr{[]} \comma \channel{\unit}{\li} \comma \unit} {\constr{[]} \comma \lio \comma \lio} {\constr{suc} \; \constr{zero}} {\channel{\unit}{\li}} {\li} {\constr{[]} \comma \lo \comma \lio}$
  _ = $\constr{there} \; \constr{here}$
  \end{lstlisting}
\end{example}

\begin{nidefinition}
  \label{def:types}

  The typing relation \textsc{Types} presented in Figure \ref{fig:types} is indexed by a typing context, an input and an output usage context, and the process $P$ being typed.

  \begin{figure}[h]
  \begin{mathpar}
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      P : \Process_n \\
      \Delta : \Ctx_{idxs}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : \Set}
    \; \textsc{Types}
    
    \inferrule
    { }
    {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}
  
    \inferrule
    {t : \Type \\ x : \Carrier_{idx}^2 \\ y : \Carrier_{idx'} \\\\
     cont : \types{\gamma \comma \channel{t}{x}}{\Gamma \comma (y \comma y) }{P}{\Delta \comma \lz}}
    {\constr{chan} \; t \; x \; y \; cont : \types{\gamma}{\Gamma}{\new P}{\Delta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma \hspace{1.2em}}{\Gamma \hspace{1.3em}}{i}{\channel{t}{x}}{\li}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma \comma t}{\Xi \comma x}{P \hspace{5.6em}}{\Theta \comma \lz}}}
        {\constr{recv} \; chan_i \; cont : \types{\gamma}{\Gamma}{\recv{i}{P}}{\Theta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma}{\Gamma \hspace{0.2em}}{i}{\channel{t}{x}}{\lo}{\Delta} \\\\
            loc_j \hspace{0.8em} : \contains{\gamma}{\Delta}{j}{t \hspace{3.7em}}{x \hspace{0.3em}}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma}{\Xi \hspace{0.3em}}{P\hspace{5.8em}}{\Theta}}}
        {\constr{send} \; chan_i \; loc_j \; cont : \types{\gamma}{\Gamma}{\send{i}{j}P}{\Theta}}
  
    \inferrule
    {l \hspace{0.3em} : \types{\gamma}{\Gamma \hspace{0.2em}}{P}{\Delta} \\\\
     r : \types{\gamma}{\Delta}{Q}{\Xi}}
    {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
  \end{mathpar}
  \caption{Leftover typing for a resource-aware typing system.}
  \label{fig:types}
  \end{figure}

  The process termination case is only concerned with usage contexts.
  Its input usage context is returned as leftovers.

  Scope restriction expects three arguments: the type $t$ of data being transmitted; the input and output multiplicities $x$ of the data being transmitted; and the multiplicity $y$ assigned to the channel itself.
  The same multiplicity $y$ is used as the input multiplicity and as the output multiplicity of the channel, so these are balanced.
  The typing derivation of the continuation process $P$ is provided with this channel with multiplicity $(y \comma y)$.
  Process $P$ must then completely exhaust this channel, and to that end we substitute $(y , y)$ in the input context with $\lz$ in the output context.

  Receiving requires a proof $chan_i$ that selects a channel at index $i$ with multiplicity $\li$ available, over which data with type $t$ and multiplicity $x$ is going to be sent.
  Note that this index $i$ is then used in the syntax of the typed process.
  After consuming $\li$ from this channel, we use the leftover context $\Xi$ to type the continuation.
  The continuation is also provided with the received element --- of type $t$ and multiplicity $x$ at index $\constr{zero}$.
  This multiplicity $x$ must be completely exhausted by the continuation process.

  Similar to input, output requires a proof $chan_i$ that selects a channel at index $i$ with multiplicity $\lo$ available, over which data with type $t$ and multiplicity $x$ is going to be sent.
  Note that this index $i$ is then used in the syntax of the typed process.
  After consuming $\lo$ from this channel, we use the leftover context $\Delta$ to type the continuation.
  The continuation must select the element at index $j$ that is being sent.
  This element must have type $t$ and at least multiplicity $x$ --- as per the channel's type.
  The result of consuming these multiplicity $x$ is the leftover context $\Xi$, which is then used to type the continuation process.
  Note that both indices $i$ and $j$ are used in the syntax of the typed process.
  
  Parallel composition is only concerned with usage contexts.
  It uses the leftovers of the left-hand process to type the right-hand process.
\end{nidefinition}

\begin{example}
  \label{example-derivations}
  The following example uses both linear and shared types to type the process $p$. 
  We use $\omega$ as a synonym for a $(\one \comma \one)$ multiplicity in an algebra for shared types.
  The usage context $\epsilon$ signifies the empty context where all multiplicities are $(\zero \comma \zero)$.
  The typing derivation creates a new channel over which $\li$ multiplicities of a type $\channel{\unit}{\omega}$ are sent.
  This channel is initialized with a linear multiplicity of $(\one \comma \one)$, and therefore must be used exactly once for sending and once for receiving.
  The right-hand parallel subprocess then creates a new channel as per the specification $\channel{\unit}{\omega}$.
  
  \begin{lstlisting}[mathescape]
  $p$ : $\Process_1$
  $p$ = $\new{} (\comp{\recv{\constr{zero}} (\recv{\constr{zero}} \PO)}
                    {\new{} (\send{\constr{suc} \; \constr{zero}} {\constr{zero}} (\send{\constr{zero}}{\constr{suc} \; \constr{suc} \; \constr{zero}}) \; \PO)})$

  _ : $\types{\constr{[]} \comma \unit}{\constr{[]} \comma \omega}{p}{\epsilon}$
  _ = $\constr{chan} \; \channel{\unit}{\omega} \; \li \; \one$
      $(\constr{comp} \;
       (\constr{recv} \; \constr{here} \; (\constr{recv} \; \constr{here} \; \constr{end}))$
           $(\constr{chan} \; \unit \; \omega \; \one \; (\constr{send} \; (\constr{there} \; \constr{here}) \; \constr{here} \; (\constr{send} \; \constr{here} \; (\constr{there} \; \constr{here} \; \constr{there}) \; \constr{end})))
       )$
  \end{lstlisting}
\end{example}

\begin{nilemma}
  \label{lm:types-unused}
  For all well-typed processes $\types{\gamma}{\Gamma}{P}{\Xi}$, if the variable $i$ is unused within $P$, then $\Gamma$ at $i$ is equivalent to $\Xi$ at $i$.
\end{nilemma}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\begin{nilemma}
  \label{lm:types-op}
  For all well-typed processes $\types{\gamma}{\Gamma}{P}{\Xi}$, there exists some $\Delta$ such that $\opctx{\Gamma}{\Delta}{\Xi}$.
\end{nilemma}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Type Safety}
\label{type-safety}

\todo{intro}

\subsection{Framing}
\label{framing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Framing captures the idea that the well-typedness of a process does not depend on its unused resources.
These unused resources are not introduced as new variables -- the typing context remains unaltered -- but rather as extra multiplicities that are carried from the input context to the output context.

\begin{nitheorem}
  \label{thm:framing}
  Let $P$ be a well-typed process from context $\Gamma_l$ to $\Xi_l$.
  Then, per Lemma \ref{lm:types-op}, there exists some $\Delta$ such that $\opctx{\Gamma_l}{\Delta}{\Xi_l}$.
  Take arbitrary contexts $\Gamma_r$ and $\Xi_r$ such that $\opctx{\Gamma_r}{\Delta}{\Xi_r}$.
  Then $\types{\gamma}{\Gamma_r}{P}{\Xi_r}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Weakening}
\label{weakening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Weakening states that adding new variables to the typing and usage contexts preserves the well-typedness of a process.
The multiplicities of these new variables will be carried from the input context to the output context.
Usually, weakening is presented through order preserving embeddings.
Order preserving embeddings model a series of insertions into a context.
In this paper, we use weakening to prove subject congruence.
To do so, we need of a single insertion into a context, and thus we will limit our theorem statement to that, but there is no loss of generality.

\begin{nitheorem}
  \label{thm:weakening}
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let us insert an arbitrary type $t$ at position $i$ in the typing context and an arbitrary multiplicity $x$ at position $i$ into both the input and output contexts.
  Let us reflect this on the process $P$ by incrementing every index greater than or equal to $i$.
  The resulting process will be well-typed so that $\types{insert_i \; t \; \gamma}{insert_i \; x \; \Gamma}{lift_i \; P}{insert_i \; x \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Strengthening}
\label{strengthening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Strengthening states that removing unused variables from the typing and usage contexts preserves the well-typedness of a process.
The proof that a variable is unused within a process must be syntactical and cannot rely on the preservation of its usage annotations between the input and output contexts: a process can refer to a variable and still make no use of it -- e.g. by sending none of its multiplicities over a channel.

\begin{nitheorem}
  \label{thm:strengthening}
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let $i$ be a variable index that is not mentioned by $P$, such that $\Unused_i \; P$.
  Then removing index $i$ from the typing context and both of the usage contexts and decrementing every variable in $P$ greater than $i$ preserves its well typedness, so that $\types{delete_i \; \gamma}{delete_i \; \Gamma}{lower_i \; P}{delete_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Swapping}
\label{swapping}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Swapping two variables (in the typing context, input and output usage contexts and process) preserves the well-typedness of a process.

\begin{remark}
  We limit ourselves to the swapping of contiguous variables $i$ and $\suc i$.
  Doing so is enough to prove subject reduction.
  The swapping of any two variables can be modeled as a sequence of contiguous variable swappings.
\end{remark}


\begin{nitheorem}
  \label{thm:swapping}
  Let $swap_i$ be a function that swaps variables $i$ and $\suc i$.
  For simplicity, we overload $swap$ and use it to swap types in a typing context, multiplicities in a usage context, and variable references in a process.
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then $\types{swap_i \; \gamma}{swap_i \; \Gamma}{swap_i \; P}{swap_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Subject Congruence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{subject-congruence}

Structural congruence is an equivalence relation that aims to overcome the semantically meaningless difference introduced by the syntax of the \picalc{}.

\begin{nitheorem}
  \label{thm:subject-congruence}
  Applying structural congruence rules to a well-typed process should preserve its well-typedness under the same typing and usage contexts.
  If $P \eq{r} Q$ and $\types{\gamma}{\Gamma}{P}{\Xi}$ then $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  By induction on \textsc{Equals}.
  The case $\constr{struct}$ and its symmetric one under $\constr{sym}$ are the nontrivial ones.
  For those, we proceed by induction on \textsc{StructCong}:
  \begin{itemize}
    \item
      The case $\constr{comp-assoc}$ is trivial because the encoding with leftover typing of the typing rules naturally preserves associativity.
    \item
      The $\constr{comp-sym}$ case for a process $\comp{P}{Q}$ is however more complicated: $P$ must use framing (Theorem \ref{thm:framing}) to shift its output context to $Q$'s; $Q$ must use framing to shift its input context to $P$'s.
      The usage context on which $Q$ and $P$ coincide in $\comp{Q}{P}$ will no longer be the same.
    \item
      The case $\constr{comp-end}$ is trivial because in the typing rule for process $\PO$ the input and output contexts are one and the same.
    \item
      In the $\constr{scope-end}$ case, the typing rules $\constr{chan}$ and $\constr{end}$ work together to constraint the multiplicity of the newly create channel to $\lz$, making the proof trivial.
      In the opposite direction, we will need to instantiate the newly created channel to a concrete type and multiplicities.
      For this, we will use type $\unit$ and multiplicities $\lz$.
    \item
      In the $\constr{scope-ext}$ case for a process $\new \comp{P}{Q}$, we will make use of Lemma $\ref{lm:types-unused}$ to show that as the typing derivation on $P$ will preserved the multiplicity of the recently introduced variable unchanged.
      We then use strengthening (Theorem \ref{thm:strengthening}) to delete the recently introduced variable from $P$, and then compose with the typing derivation of $Q$ under $\constr{chan}$.
      In the reverse direction, we will weaken $P$ so that it can accept an additional variable.
      We will then use Lemma \ref{lm:lower-lift} to show that lifting a lowered $P$ leaves $P$ unchanged.
    \item
      Finally, for the $\constr{scope-comm}$ rule, we will use swapping as shown in Theorem \ref{thm:swapping}.
      In the reverse direction, we will use swapping and then use Lemma \ref{lm:swap-swap} to show that swapping indices twice leaves $P$ unchanged.
  \end{itemize}
\end{proof}
\todo{make sure constructor names in code coincide}

\begin{remark}
  We encode the recursive structure of \textsc{Equals} in its inductive definition -- by indexing its type with \textsc{Rec}.
  This acts as a justification of the well-formedness of the recursion scheme, which Agda cannot immediately see as terminating due to the interaction between the transitive and symmetric cases.
\end{remark}

\subsection{Substitution}
\label{substitution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When function abstraction and application come together in the \lambdacalc{} with de Bruijn indices, every reference to the most recent variable in the body of the abstraction gets replaced with the argument of the application.
In the \picalc{} however substitution takes another form: every reference to the most recent variable in the receiving process gets replaced with the reference to the data that is being sent over the channel.
In a resource-aware \picalc{}, that means that instead of exhausting all $m$ multiplicities of the most recent variable, we leave those unaltered and exhaust them from the variable that is being received.

\begin{nitheorem}
  \label{thm:substitution}
  Let $P$ be a process where the most recent variable has all its $m$ multiplities exhausted, such that $\types{\gamma \comma t}{\Gamma \comma m}{P}{\Psi \comma \lz}$.
  Let $j$ be the index of the data with $m$ multiplicities that is being received after $P$ is done, so that $\contains{\gamma}{\Psi}{j}{t}{m}{\Xi}$.
  Then, we can substitute variable $\constr{zero}$ in $P$ with $\suc j$.
  As a result, the multiplicities at $\constr{zero}$ will be preserved and those at $j$ will be consumed instead, resulting in $\types{\gamma \comma t}{\Gamma \comma m}{\subst{P}{\suc j}{\constr{zero}}}{\Xi \comma m}$.
\end{nitheorem}
\begin{proof}
  We need to proceed by induction on $P$, and to do so means going under scope restriction.
  We use the generalised version in Theorem \ref{thm:subst-generalization} so that the variable that is being substituted is not $\constr{zero}$ but any variable $i$.
  \todo{explain arguments}
\end{proof}

\begin{nitheorem}
  \label{thm:subst-generalization}

  Let the variable that is being substituted be $\contains{\gamma}{\Gamma_i}{i}{t}{m}{\Gamma}$ and the variable that it is being substituted with $\contains{\gamma}{\Gamma_j}{j}{t}{m}{\Gamma}$.
  As shown in Figure \ref{fig:subst}, the process that is being substituted will pivot from the input usage context $\Gamma_i$ to the input usage context $\Gamma_j$.
  Let there be two \emph{adjustment} variables $\contains{\gamma}{\Psi_i}{i}{t}{n}{\Psi}$ and $\contains{\gamma}{\Psi_j}{j}{t}{n}{\Psi}$.
  The process that is being substituted will pivot from the output usage context $\Psi_i$ to the output usage context $\Psi_j$.
  As shown in Figure \ref{fig:subst-alternative}, without this \emph{adjustment} composing the substitution of subprocesses is not at all trivial.
  Assume that $P$ uses all $m$ multiplicities at index $i$.
  To model this, require $\opctx{\Gamma}{\Delta}{\Psi}$ for some $\Delta$ where index $i$ is $\lz$.
  The process that is typed such that $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$ will be typed $\types{\gamma}{\Gamma_j}{\subst{P}{j}{i}}{\Psi_j}$ after substitution.
\end{nitheorem}

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,6)   {$\Gamma_i$};
      \node (gamma-m)   at (0,3)   {$\Gamma$};
      \node (gamma-j) at (0,0)   {$\Gamma_j$};
      \node (xi-i)    at (3,5.5) {$\Xi_i$};
      \node (theta)   at (3,3.3) {$\Theta$};
      \node (delta-m) at (3,2.7) {};
      \node (xi-j)    at (3,0.5) {$\Xi_j$};
      \node (psi-i)   at (6,5)   {$\Psi_i$};
      \node (psi-m)   at (6,3)   {$\Psi$};
      \node (psi-j)   at (6,1)   {$\Psi_j$};

      \draw[-]  (gamma-m) -- (delta-m.center);
      \draw[->] (delta-m.center) -- node[align=center,below] {$\Delta$\\$\Delta_i = \lz$}(psi-m);

      \draw[->,densely dotted] (gamma-m) -- (theta);
      \draw[->,densely dotted] (theta) -- (psi-m);
      
      \draw[->] (gamma-i) -- node[left] {$\ni_i m$} (gamma-m);
      \draw[->] (gamma-j) -- node[left] {$\ni_j m$} (gamma-m);
      \draw[->] (psi-i) -- node[right] {$\ni_i n$} (psi-m);
      \draw[->] (psi-j) -- node[right] {$\ni_j n$} (psi-m);

      \draw[->] (gamma-i) -- node[above] {$\vdash P$} (xi-i);
      \draw[->] (xi-i) -- node[above] {$\vdash Q$} (psi-i);
      \draw[->,densely dotted] (gamma-j) -- node[below] {$\vdash \subst{P}{j}{i}$} (xi-j);
      \draw[->,densely dotted] (xi-j) -- node[below] {$\vdash \subst{Q}{j}{i}$} (psi-j);
      \draw[->,densely dotted] (xi-i) -- node[left] {$\ni_i l$} (theta);
      \draw[->,densely dotted] (xi-j) -- node[left] {$\ni_j l$} (theta);
    \end{tikzpicture}
    \caption{
      Diagrammatic representation of the inductive substitution lemma.
      Continuous lines represent known facts, dotted lines proof obligations.
    }
    \label{fig:subst}
  \end{subfigure}
  \hspace{\fill} % DO NOT LEAVE EMPTY LINE
  \begin{subfigure}{.4\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,4)   {};
      \node (gamma-m) at (0,2)   {};
      \node (gamma-j) at (0,0)   {};
      \node (xi-i)    at (2,5)   {};
      \node (xi-m)    at (2,3.5) {};
      \node (xi-j)    at (2,2)   {};
      \node (psi-m)   at (4,3.5) {};

      \draw[->] (gamma-i) -- (xi-j);
      \draw[->] (gamma-m) -- (xi-j);
      \draw[->,densely dotted] (gamma-j) -- (xi-j);
      \draw[->] (gamma-i) -- (gamma-m);
      \draw[->] (gamma-j) -- (gamma-m);
      \draw[->] (xi-i)    -- (xi-m);
      \draw[->] (xi-j)    -- (xi-m);
      \draw[->] (xi-i)    -- (psi-m);
      \draw[->] (xi-m)    -- (psi-m);
      \draw[->,densely dotted] (xi-j)    -- (psi-m);
    \end{tikzpicture}
    \caption{
      Alternative approach without arrows $\ni_i n$ and $\ni_j n$.
      Composition is non-trivial.
    }
    \label{fig:subst-alternative}
  \end{subfigure}
  \caption{Substitution with and without the \emph{adjustment} arrows $\ni_i n$ and $\ni_j n$}
\end{figure}

\begin{proof}
  By induction on the derivation $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$.
  \begin{itemize}
    \item
      From constructor $\constr{end}$ we derive $\Gamma_i \equiv \Psi_i$.
      From $\Delta_i \equiv \lz$ follows that $m \equiv n$.
      Therefore $\Gamma_j \equiv \Psi_j$ and $\constr{end}$ can be applied.

    \item
      For constructor $\constr{chan}$ we proceed inductively, applying the constructor $\suc$ to all arrows $\ni_i m$, $\ni_j m$, $\ni_i n$ and $\ni_j n$.
      
    \item
      For constructor $\constr{recv}$ we split $\Delta$ so that we can proceed inductively on the continuation.
      We first observe that given that there exists an arrow from $\Gamma_i$ to $\Psi_i$ and $\Delta$ at index $i$ is $\lz$, for any $m$ and $n$, there is some $\delta$ such that $\opsquared{m}{\delta}{n}$.
 l     \begin{itemize}
        \item
          If the input occurs on the variable that is being substituted, we derive $\opsquared{m}{\li}{l}$ for some $l$ and construct an arrow $\containsusage{\Xi_i}{i}{l}{\Gamma}$ (used for the inductive call).
          Similarly, we construct the arrows $\containsusage{\Gamma_j}{j}{\li}{\Xi_j}$ (used as the new channel on which input occurs) and $\containsusage{\Xi_j}{j}{l}{\Gamma}$ (used for the inductive call) for some $\Xi_j$.
        \item
          If the input occurs on some variable $x$ other than the one that is being substituted, we construct the arrows $\containsusage{\Xi_i}{i}{m}{\Theta}$ (used for the inductive call) and $containsusage{\Gamma}{x}{\li}{\Theta}$ for some $\Theta$.
          We can then find $\Xi_j$ and construct the two arrows $\containsusage{\Gamma_j}{x}{\li}{\Xi_j}$ (used as the new channel on which input occurs) and $\containsusage{Xi_j}{j}{m}{\Theta}$ (used for the inductive call).
          From the fact that there exists a composition of arrows from $\Xi_i$ to $\Psi$, we can conclude that $\Theta$ is splitting $\Delta$ such that $\opctx{\Gamma}{\Delta_1}{\Theta}$ and $\opctx{\Theta}{\Delta_2}{\Psi}$.
          As $\lz$ is a minimal element, if $\Delta$ is $\lz$ at index $i$, then it must be $\lz$ at index $i$ for $\Delta_1$ and $\Delta_2$ as well.
      \end{itemize}

    \item
      $\constr{send}$ applies the ideas outlined for the $\constr{recv}$ constructor to both the channel doing the output and the transmitted data.

    \item
      For $\constr{comp}$ we first find a $\delta$, $\Theta$, $\Delta_1$ and $\Delta_2$ such that $\containsusage{\Xi_i}{i}{\delta}{\Theta}$ and $\opctx{\Gamma}{\Delta_1}{\Theta}$ and $\opctx{\Theta}{\Delta_2}{\Psi}$.
      Given that $\Delta$ is $\lz$ at index $i$, we know that $\Delta_1$ and $\Delta_2$ are so too.
      We observe that $\opsquared{m}{\delta}{\omega}$ where $\omega$ is what subprocess $P$ consumes at index $i$.
      We use this to construct an arrow $\containsusage{\Xi_j}{j}{\delta}{\Theta}$, for some $\Xi_j$.
      We use these constructions to make two inductive calls (on the derivation of $P$ and $Q$) and compose their result.
  \end{itemize}  
\end{proof}


\subsection{Subject Reduction}
\label{subject-reduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Subject reduction (aka type preservation) relates the operational semantics and the typing system of a language.
In its usual form, it states that if $P$ reduces to $Q$ and $P$ is well-typed under context $\Gamma$, then $Q$ is well-typed under $\Gamma$ too.
In the linear \picalc{} however, reduction \emph{is} meant to transform the context: each time communication occurs over a channel, that channel is exhausted.
In our case, and because we generalize linearity to a partial monoid, the channel over which the communication occurs will loose a multiplicity $\one$ on both its input and output capabilities.
In \S \ref{semantics}, we made sure to lift the index of the communicating channel to the type level, now we use it to state subject reduction.

\begin{nitheorem}
  Let $P \reduce{c} Q$.
  If $c$ is $\constr{internal}$ to the process, the context must not be modified and thus $\Gamma' \equiv \Gamma$.
  If $c$ is $\constr{external}\; i$, the input usage context at index $i$ must be decremented, and therefore $\containsusage{\Gamma'}{i}{\lio}{\Gamma}$.
  Then the typing derivation $\types{\gamma}{\Gamma'}{P}{\Xi}$ can be transformed into $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  \hfill{}\\
  \begin{itemize}
    \item
    In the base case $\constr{comm}$ we need to construct a typing derivation $\types{\gamma}{\Gamma}{lower_0 \allowbreak \; (\subst{P}{\suc j}{\constr{zero}})}{\Xi}$ starting from the assumptions in Figure \ref{fig:subject-reduction:a}.
    We start by using framing (Theorem \ref{thm:framing}) to rearrange the consumption of the input and output multiplicities of the communicating channel and then apply substitution (Theorem \ref{thm:substitution}) and strengthening (Theorem \ref{thm:strengthening}).

    \begin{figure}[h]
      \setlength{\mathindent}{0pt}
      \begin{subfigure}{.3\textwidth}
        \begin{alignat*}{2}
          \containsusage{&\Gamma'}{i}{\lio &&}{\Gamma} \\
          \contains{\gamma}{&\Gamma'}{i}{\channel{t}{m}}{\li &&}{\Psi} \\
          \types{\gamma \comma t}{&\Psi \comma m}{P &&}{\Delta \comma \lz} \\
          \contains{\gamma}{&\Delta }{i}{\channel{t}{m}}{\lo &&}{\Theta} \\
          \contains{\gamma}{&\Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Initial assumptions.}
        \label{fig:subject-reduction:a}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{alignat*}{2}
          \types{\gamma \comma t}{& \Gamma \comma m}{P &&}{\Theta \comma \lz} \\
          \contains{\gamma}{& \Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Rearrange $\lo$ witness, and merge with $\li$ witness into $\lio$.}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{align*}
          \types{\gamma \comma t}{\Gamma \comma m}{\subst{P}{\suc j}{\constr{zero}}}{\Xi \comma m}
        \end{align*}
        \caption{Substitution.}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{align*}
          \types{\gamma \comma t}{\Gamma \comma m}{lower_0 \; (\subst{P}{\suc j}{\constr{zero}})}{\Xi \comma m}
        \end{align*}
        \caption{Strengthening.}
      \end{subfigure}
      \caption{Proof steps for the $\constr{comm}$ case in subject reduction.}
    \end{figure}
  
    \item
    Reduction under composition with $\constr{par}$ proceeds by induction on the process that is being reduced.

    \item
    Reduction under scope restriction case splits on the channel $c$ on which communication occurs.
    If the channel is $\constr{internal}$ to the process subject reduction proceeds inductively.
    If the channel is $\constr{external}\; \constr{zero}$ -- i.e. the channel that is being introduced by the scope restriction -- we use the Lemma \ref{lm:comm-capable} to subtract $\lio$ from the channel's multiplicity first, then apply the induction hypothesis.
    If the channel is $\constr{external}\; (\suc i)$ subject reduction proceeds inductively.

    \item
    Finally, in the $\constr{struct}$ case, we apply subject congruence (Theorem \ref{thm:subject-congruence}) and then the induction hypothesis.
  \end{itemize}
\end{proof}

\begin{nilemma}
  \label{lm:comm-capable}
  Every input usage context $\Gamma$ on a well-typed process $\types{\gamma}{\Gamma}{P}{\Delta}$ that reduces such that $P \reduce{\constr{external} \; i} Q$ has a multiplicity of at least $\lio$ at index $i$.
\end{nilemma}
\begin{proof}
  By induction on the reduction derivation $P \reduce{\constr{external \; i}}Q$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\cite{previous-work} polymorphic tokens, HOAS

\cite{typing-with-leftovers}

\cite{Higher-inductive-types-for-congruence}

\cite{LTS-semantics}

\cite{work-on-session-types}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permiting:

\begin{description}

\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

  Bidirectional typing rules needed.

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}


\bibliography{paper}
\end{document}
