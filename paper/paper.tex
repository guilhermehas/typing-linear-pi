\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage{mathtools}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Mathbb doesn't support digits
\usepackage{bbm}

% Less margins around figures
\usepackage{changepage}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

% Do not use italics for definitions
\theoremstyle{definition}
\newtheorem{nidefinition}[theorem]{Definition}

% No line numbers
\nolinenumbers

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Typing a linear \picalc}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi calculus, linear, types, concurrency}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{We want to thank Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\stacked}[1]{\mprset{flushleft} \inferrule*{}{#1}}
\newcommand{\datatype}[2]{{\mprset{fraction={===}} \inferrule{#1}{#2}}}

\newcommand{\lamdacalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}

\newcommand{\type}[1]{\textcolor{blue}{\mathtt{\operatorname{#1}}}}
\newcommand{\constr}[1]{\textcolor{olive}{\mathtt{\operatorname{#1}}}}
\newcommand{\field}[1]{\textcolor{red}{\mathtt{\operatorname{#1}}}}

% Constructors
\newcommand{\PO}{\constr{\mathbf{0}}}
\newcommand{\comp}[2]{#1 \; \constr{\parallel} \; #2}
\newcommand{\new}{\constr{\boldsymbol{\nu}} \;}
\newcommand{\send}[2]{#1 \; \constr{\langle} \; #2 \;\constr{\rangle} \;}
\newcommand{\recv}[1]{#1 \; \constr{\mathbb{()}} \;}
\newcommand{\suc}{\constr{\scriptstyle 1+}}
\newcommand{\unit}{\constr{\mathbbm{1}}}
\newcommand{\base}[1]{\constr{B[} \; #1 \; \constr{]}}
\newcommand{\channel}[2]{\constr{C[} \; #1 \; \constr{\propto} \; #2 \; \constr{]}}
\newcommand{\comma}{\; \constr{,} \;}

% Functions
\newcommand{\subst}[3]{#1[#2/#3]}

% Fields
\newcommand{\op}[3]{#1 \; \field{\coloneqq} \; #2 \; \field{\cdot} \; #3}
\newcommand{\zero}{\field{0\cdot}}
\newcommand{\one}{\field{1\cdot}}
\newcommand{\li}{\field{\ell_i}}
\newcommand{\lo}{\field{\ell_o}}
\newcommand{\lz}{\field{\ell_{\o}}}
\newcommand{\lio}{\field{\ell_{\#}}}

% Types
\newcommand{\Set}{\type{SET}}
\newcommand{\reduce}[1]{\; \type{\longrightarrow}_{#1} \;}
\newcommand{\types}[4]{#1 \; \type{\propto} \; #2 \; \type{\vdash} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\contains}[6]{#1 \; \type{\propto} \; #2 \; \type{_[} _{#3} \type{_]=} \; #4 \; \type{\propto} \; #5 \; \type{\boxtimes} \; #6}
\newcommand{\Var}{\type{VAR}}
\newcommand{\Process}{\type{PROCESS}}
\newcommand{\Unused}{\type{UNUSED}}
\newcommand{\PreCtx}{\type{PRECTX}}
\newcommand{\Ctx}{\type{CTX}}
\newcommand{\Type}{\type{TYPE}\;}
\newcommand{\Idx}{\type{IDX}\;}
\newcommand{\Idxs}{\type{IDXS}}
\newcommand{\Carrier}{\type{CARRIER}}
\newcommand{\N}{\type{\mathbb{N}}}
\newcommand{\Channel}{\type{CHANNEL}}
\newcommand{\Rec}{\type{REC}}
\newcommand{\Quantifier}{\type{QUANTIFIER}}
\newcommand{\eq}[1]{\; \type{=}_{#1} \;}
\newcommand{\eqeq}{\; \type{\equiv} \;}


\begin{document}

\maketitle
\todo{remove todo notes}

\begin{abstract}
  We present the syntax, operational semantics, and typing rules of a \picalc{} with linear and shared types.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalize the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  This formalization has been fully mechanized with Agda and is available at \url{https://github.com/umazalakain/typing-linear-pi}.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

We live in a concurrent world where any given state is often decided by the interaction between a myriad of parties --- people, machines, processors, services, networks.
As humans, we aim to model, predict, and even construct such interactive systems.
As mathematicians, abstraction is our tool of choice to do so.

The \picalc models communication.

The properties guaranteed by the picalc

why resource-aware typing

extensional typing rules for a given syntax and operational semantics

leftover typing

\subsection{Contribution}

\begin{description}
  \item [Machine verified formalisation of the linear pi calculus]

  \item [Typing with leftovers applied to the pi calculus]

  \item [Abstraction over multiplicities]

  \item [Full formalisation available in Agda]
\end{description}

\subsection{Notation}

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\type{\N} : \Set}
    \; \textsc{Nat}

    \inferrule
    { }
    {\constr{0} : \type{\N}}

    \inferrule
    {n : \type{\N}}
    {\suc n : \type{\N}}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Type constructors as the names for the typing rules.
Datatype constructor rules might have additional index-free synonyms for ease of reference.
Double rule for type-level definitions.
We omit universe levels for brevity.
$\type{TYPES}$ are in blue and uppercased (and their indices are subscripts), $\constr{constructors}$ are in olive, $\field{fields}$ in red and variables and functions in black.
Some constructors are shared across types. They can however always be disambiguated through the type of the goal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}

Abstraction is one of the key reasoning tools in a language: it allows for features to be defined over a range of inputs.
Such is the case of the \picalc{} too, where both scope restriction and input introduce abstractions.
The bodies of these constructs must have a way of referring to their argument.
Using names as variable references is a popular option amongst humans.
However, names are cumbersome to mechanize: inserting a new variable into an environment means proving that the name of such variable is different to all other variable names in the environment.
Moreover, to a machine names are of no significance whatsoever.

Machines prefer things they can algorithmically act upon. Like natural numbers!
What does it mean to use a number as a variable reference?
The idea de Bruijn had \cite{} was to use the index $n$ to refer to the variable introduced $n$ binders ago.
The binders themselves introduce no names anymore.
The expression $\lambda g . (\lambda f . f g) g$ in the \lamdacalc{} would translate as $\lambda (\lambda 0 1) 0$.
That is, terms at different \emph{depths} must use different indices to refer to the same binding.
Humans find this often confusing.
There is however no reason not to keep the original names bestowed by the humans together with the indices.
Machines can then manipulate references mechanically and still use names to present them to humans.

A variable occurring under $n$ abstractions has $n$ things to refer to.
References outside of that range have no associated meaning.
It is useful to rule out these nonsensical terms syntactically.
In Figure \ref{var} we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Var_n : \Set}
  \; \textsc{Var}

  \inferrule
  {n : \N}
  {\constr{0} : \Var_{\suc n}}

  \inferrule
  {x : \Var_n}
  {\suc x : \Var_{\suc n}}
\end{mathpar}
\caption{Types of size $n$}
\label{var}
\end{figure}

Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
As shown in Figure \ref{process}, we increase the \emph{depth} counter every time we create a new channel or receive some input.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Process_n : \Set}
  \; \textsc{Process}
\end{mathpar}
  
\begin{equation*} \label{pi-calc-syntax}
\begin{split}
  \Process_n ::=& \; \PO_n                    \\
              |& \; \new{} \Process_{\suc n}          \\
              |& \; \comp{\Process_n}{\Process_n}          \\
              |& \; \recv{\Var_n}{}\Process_{\suc n} \\
              |& \; \send{\Var_n}{\Var_n}\Process_n
\end{split}
\end{equation*}
\caption{Well-scoped grammar using de Bruijn indices}
\label{process}
\end{figure}

Unlike with names, using type-level de Bruijn indices makes our syntax well-scoped by construction.
As a consequence, the semantics of our language can be defined on the totality of the syntax.
User-friendliness can still be recovered through a function that converts processes with names into (possibly) processes with indices.
This function would keep track of what index is associated with what name, and would traverse the process recursively, taking note of new binders and substituting variable references.
If the process is ill-scoped, the function would return nothing.
To print things back to the user names can be substituted with an index together with the name.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}

In the \lamdacalc{} $\beta$-reduction operates on syntactically adjacent terms.
In the \picalc{} however, the syntax introduces unnecessary distinctions
(e.g. semantically parallel composition is defined modulo associativity and commutativity).
There are several ways around this, a structural congruence relation being one of the historical ones.
(Others include labeled transition systems and higher inductive types.)

\subsection{Structural Congruence}

Structural congruence is a congruent equivalence relation on processes.
Any two structurally congruent processes are strongly bisimilar: they are can follow each other's reduction steps \cite{}.
Figure \ref{struct-cong-base} lists the base cases of structural congruence.
The type $\Unused_0 \; Q$ witnesses that index $0$ does not appear nor in the inputs nor in the outputs of process $Q$ --- it does so by traversing $Q$.
The function $lower \; 0 \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $0$.
Finally, $swap \; 0 \; P$ traverses $P$ (scoped under $\suc \suc n$) and swaps variable references $0$ and $\suc 0$.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {P \eqeq Q : \Set}
  \; \textsc{StructCong}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{\comp{Q}{R}} \eqeq \comp{\comp{P}{Q}}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \eqeq \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \eqeq P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \eqeq \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \, Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \eqeq \comp{(\new P)}{lower \; 0 \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \eqeq \new \new swap \; 0 \; P}
\end{mathpar}
\caption{Structural rewriting rules. Premises $P$, $Q$ and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong-base}
\end{figure}

Structural congruence is a congruent equivalence relation.
As such, rewrites can happen at any point in a process' recursive definition, and they are closed under reflexivity, symmetry and transitivity as shown in Figure \ref{struct-cong}.
In \S \ref{subject-congruence} we will prove that if two processes $P$ and $Q$ are structurally congruent and $P$ is well-typed, then $Q$ is well-typed.
Specifically, in the case of transitivity we must prove that if $P$ is structurally congruent with $Q$ and $Q$ with $R$, and $P$ is well-typed, then so is $R$.
To do so, we will have to proceed by induction and first get a proof of the well-typedness of $Q$, then use that to reach $R$.
To show that the doubly recursive call terminates we index the equivalence relation $=$ by the type $\Rec$, which models the structure of the recursion.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {\Rec : \Set}
  \; \textsc{Rec}

  \inferrule
  { }
  {\constr{zero} : \Rec}
  
  \inferrule
  {r : \Rec}
  {\constr{one} \; r : \Rec}

  \inferrule
  {r \; s : \Rec}
  {\constr{two} \; r \; s : \Rec}
  
  \datatype
  {P \, Q : \Process_n \\ r : \Rec}
  {P \eq{r} Q : \Set}
  \; \textsc{Equals}

  \inferrule
  {eq : P \eqeq Q}
  {\constr{struct} \; eq : P \eq{\constr{zero}} Q}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-scope} \; eq : \new P \eq{\constr{one} \; r} \new P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-comp} \; eq : \comp{P}{Q} \eq{\constr{one} \; r} \comp{P'}{Q}}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-recv} \; eq : \recv{x}P \eq{\constr{one} \; r} \recv{x}P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-send} \; eq : \send{x}{y}P \eq{\constr{one} \; r} \send{x}{y}P'}

  \inferrule
  { }
  {\constr{refl} : P \eq{\constr{zero}} P}

  \inferrule
  {eq : P \eq{r} Q}
  {\constr{sym} \; eq : Q \eq{\constr{one} \; r} P}

  \inferrule
  {eq_1 : P \eq{r} Q \\ \; eq_2 : Q \eq{s} R}
  {\constr{trans} \; eq_1 \; eq_2 : P \eq{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.
  Premises $P$, $P'$, $Q$, and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong}
\end{figure}
  
\subsection{Operational Semantics}

Figure \ref{reduction} models the operational semantics of the \picalc{}.
Processes put in parallel reduce when they communicate over a common variable.
The receiving process substitutes references to its most immediate variable with references to the variable sent by the process doing the output, and is then \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under structural congruence and goes under parallel composition and scope restriction
--- but notably not under input nor output, otherwise the sequencing of actions would not be preserved.
In \S \ref{subject-reduction} we prove that if $P$ reduces to $Q$ and $P$ is well-typed, so is $Q$.
However, this reduction operation is effectful: it consumes the variable over which communication happens.
If this variable is external to $P$ (it resides in its context) then the context in which $Q$ is typed must change.
To keep track of this information, we lift the variable index over which communication occurs to the type level.
Every time we come out of a binder we decrement this variable.
To do so, we make use of a $dec$ function that saturates at $\constr{internal}$ --- as opposed to an $inc$ function that would not.


\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Channel_n : \Set}
  \; \textsc{Channel}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  \datatype
  {i : \Channel_n \\ P \; Q : \Process_n}
  {P \reduce{i} Q : \Set}
  \; \textsc{Reduces}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n \\ uP : \Unused_0 \, P}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce{\constr{external} \; i} \comp{lower \; 0 \; \subst{P}{j}{0} \; uP}{Q}}

  \inferrule
  {red : P \reduce{i} P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce{i} \comp{P'}{Q}}

  \inferrule
  {red : P \reduce{i} Q}
  {\constr{res} \; red : \new P \reduce{dec\; i} \new Q}

  \inferrule
  {eq : P = P' \\ red : P' \reduce{i} Q}
  {\constr{struct} \; eq \; red : P \reduce{i} Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}

A type system is in the business of further constraining a language, filtering out terms that (although well-formed) are meaningless.
In the simply typed \lamdacalc{}, a term has a meaning iff it has a type.
This typing judgment is a proof of the form $\Gamma \vdash t : T$, where the term $t$ has type $T$ under the typing context $\Gamma$ -- the typing context associates variables (possibly occurring within $t$) to types.
In the simply typed \picalc{} however, it is the channels that are typed, and a process has a meaning iff it \emph{uses} its channels according to their types.
The typing judgment is therefore of the form $\Gamma \vdash p$, where the process $p$ (which has no type of its own) uses the channels in $\Gamma$ according to their types.

A resource-aware type system uses both types and usage counting to constraint a language.
It uses typing contexts to keep track of both types and usage counts.
In the case of a linear type system, resources must be used exactly once, and usages transition from available to consumed as soon as they are used.
In the linear \picalc{} however, every channel must be used exactly once to receive and exactly once to send.
In \S \ref{multiplicities}, we generalize this usage counting algebra so that the same type system can be used for a combination of linear, shared, and gradual types.


Syntax directed
Continuations.
\ref{leftover-typing}

\subsection{Multiplicities and Capabilities}\label{multiplicities}

In the linear \picalc{} each channel has an input and an output \emph{capability}, and each capability has a given \emph{multiplicity} of 0 or 1.
In this paper we generalize over linearity and provide an algebra on multiplicities that is capable of encoding shared and gradual types as well.
The algebra has a single binary operator $(\cdot)$ that crushes multiplicities together.
It must satisfy the following constraints:
\begin{description}

\item [Partiality]
  Not all multiplicities are necessarily compatible: in the linear \picalc{} $1$ cannot be split into $1$ and $1$.
\item [Functionality]
  Given two multiplicities $y$ and $z$, it must be computable whether a third multiplicity $x$ exists such that $\op{x}{y}{z}$.
  If such an $x$ exists, it must be unique.
    
\item [Injectivity]
  To prove framing (\S \ref{framing}) we need to be able to \emph{subtract} multiplicities.
  For that end, we rely on $x - z \equiv y$ iff $\op{x}{y}{z}$.
  As a consequence, we must constraint $y$ to be uniquely determined as well.

\item [Associativity]
  As a direct consequence of the structural congruence rule $\comp{P}{\comp{Q}{R}} \equiv \comp{\comp{P}{Q}}{R}$.

\item [Commutativity]
  As a direct consequence of the structural congruence rule $\comp{P}{Q} \equiv \comp{Q}{P}$.

\item [Distinguished elements]
  There must be a neutral element $0$ absorbed on both sides.
  There must be a special element $1$ to record usage.
\end{description}

\begin{nidefinition}
  Together, the aforementioned constraints give raise to a \emph{partial commutative monoid}.
  We deal with partiality by modeling the monoidal operation as a terniary relation.
  An algebra on the carrier set $C$ forms a $\Quantifier_C$ iff it satisfies the fields in Figure \ref{fig:multiplicities}.
  
  \begin{figure}[h]
  \begin{equation}
  \begin{aligned}
    &\zero                  &:{} &                      &        & C \\
    &\one                   &:{} &                      &        & C \\
    &\op{\_}{\_}{\_}        &:{} &                      &        & C \to C \to C \to \Set \\
    &\field{\cdot-compute}  &:{} &\forall y z           & \to \; & \type{DEC} \; (\type{\exists} x . \; (\op{x}{y}{z})) \\
    &\field{\cdot-unique}   &:{} &\forall \{x x' y z\}  & \to \; & \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
    &\field{\cdot-unique^l} &:{} &\forall \{x y y' z\}  & \to \; & \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
    &\field{\cdot-id^l}     &:{} &\forall x             & \to \; & \op{x}{\zero}{x} \\
    &\field{\cdot-comm}     &:{} &\forall \{x y z\}     & \to \; & \op{x}{y}{z} \to \op{x}{z}{y} \\
    &\field{\cdot-assoc}    &:{} &\forall \{x y z u v\} & \to \; & \op{x}{y}{z} \to \op{y}{u}{v} \to \type{\exists} w . \; (\op{x}{u}{w} \times \op{w}{v}{z})
  \end{aligned}
  \end{equation}
  \caption{Quantifier algebra $\Quantifier_C$ algebra on a partial commutative monoid.}
  \label{fig:multiplicities}
  \end{figure}
\end{nidefinition}

\begin{nidefinition}
  An indexed set of partial commutative monoids is a set of indices such that for every index there exists a carrier $C$ with a $\Quantifier_C$ algebra defined on it.
  This allows for several algebras to coexist in the same type system.
  Figure \ref{fig:indexed-multiplicities} captures these requirements: each index $i$ has a corresponding carrier type $\field{CARRIER}_i$ such that $\field{CARRIER}_i$ satisfies the algebra $\Quantifier_{\field{CARRIER}_i}$.
  We require the index type to be inhabited -- necessary to prove type preservation on $\new \PO_{\suc n} \eqeq \PO_n$.
  \todo{lift op to $^2$}
  
  \begin{figure}[h]
  \begin{equation}
  \begin{split}
    &\field{IDX}          &:{} &\Set \\
    &\field{\exists IDX}  &:{} &\field{IDX} \\
    &\field{CARRIER}      &:{} &\field{IDX} \to \Set \\
    &\field{QUANTIFIERS}  &:{} &(i : \field{IDX}) \to \Quantifier_{\field{CARRIER}_i}
  \end{split}
  \end{equation}
  \caption{Indexed set of partial commutative monoids.}
  \label{fig:indexed-multiplicities}
  \end{figure}
\end{nidefinition}

\subsubsection{Example Type Systems}

\todo{Add typing derivations for example processes}

\begin{description}

\item [Shared]

The carrier $C$ is implemented as a type $\type{One}$ with a single trivial constructor $\constr{\omega}$.
Both $\zero$ and $\one$ are instantiated to $\constr{\omega}$.
The relation $\op{\constr{\omega}}{\constr{\omega}}{\constr{\omega}}$ is inhabited.
All other laws are trivially satisfied.

\item [Linear]

The carrier $C$ is implemented as a type $\type{Two}$ with the trivial elements $\constr{zero}$ and $\constr{one}$.
The monoidal operation has the element $\constr{zero}$ as neutral on both sides, and the element $\constr{one}$ splitting into $\constr{one}$ and $\constr{zero}$ (or $\constr{zero}$ and $\constr{\one}$), and is uninhabited in every other case.
All other rules follow trivially.

\item [Gradual]

The carrier $C$ is implemented as the type of natural numbers $\N$.
The element $\zero$ corresponds 0, and $\one$ to 1.
The partial monoid $\op{x}{y}{z}$ is defined exactly when $x \equiv y + z$.
All other rules follow trivially from the algebraic rules for the addition of naturals.

\end{description}

\subsection{Contexts}

In a resource-aware \picalc{} type multiplicities change every time input and output occurs; however, the types themselves remain constant.
If multiplicities need not to depend on types, keeping types and multiplicities in independent contexts allows for a more modular approach to the algebra on contexts of multiplicities.
In this paper we choose that approach, which entails accepting that base non-channel types have dedicated input and output multiplicities too -- we will take care of impeding that any actual input or output can occur through them in the typing rules.

\begin{nidefinition}
  Figure \ref{fig:prectx} defines types as either unit types, base types or channel types.
  Unit types $\unit$ provide a proof of inhabitance for types, needed for the $\new \PO_{\suc n} \eqeq \PO_n$ rule in subject congruence.

  Base types $\base{n}$ use a natural number $n$ that can be reified into a type by the host language.
  Using natural numbers instead of type universes is convenient: there is no need to litter type types with universe polymorphism.
  
  Channel types $\channel{t}{x}$ use $t$ as the type of data sent over the channel and $x$ as the capability of the data sent over the channel.
  When data is received on a channel of type $\channel{t}{x}$, the type $t$ will be appended to the context of types $\PreCtx_n$ and the capability $x$ to the context of capabilities $\Ctx_{idxs}$.
  
  Types form length-indexed \emph{pre-contexts} $\PreCtx_n$.
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Type : \Set}
    \; \textsc{Type}
  
    \inferrule
    { }
    {\unit : \Type}

    \inferrule
    {n : \N}
    {\base{n} : \Type}
  
    \inferrule
    {t : \Type \\ \stacked{idx : \Idx \\\\ x : \Carrier_{idx}}}
    {\channel{t}{x} : \Type}
  \end{mathpar}
  
  \begin{mathpar}
    \datatype
    {n : \N}
    {\PreCtx_n : \Set}
    \; \textsc{PreCtx}
  
    \inferrule
        { }
        {[] : \PreCtx_0}
  
        \inferrule
            {\gamma : \PreCtx_n \\ t : \Type}
            {\gamma \comma t : \PreCtx_{\suc n}}
  \end{mathpar}
  \caption{Types and length-indexed typing contexts.}
  \label{fig:prectx}
  \end{figure}
\end{nidefinition}

\begin{nidefinition}
  To allow different multiplicity algebras to coexist we first define a length-indexed context of carrier indices $\Idxs_n$ (see \ref{fig:ctx}).
  On top of it, we define a context of multiplicities $\Ctx_{idxs}$.
  We lift the algebra on multiplicities to multiplicity contexts by constraining the algebra on multiplicity contexts to act on  contexts defined on the same underlying context of carrier indices.
  We use two multiplicities over a common index to represent multiplicities for both the input and the output capabilities ($\Carrier_{idx}^2$).
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Idxs_n : \Set}
    \; \textsc{Idxs}
  
    \inferrule
        { }
        {[] : \Idxs_0}
  
    \inferrule
        {idxs : \Idxs_n \\ idx : \Idx}
        {idxs \comma idx : \Idxs_{\suc n}}
  
        \\
        
    \datatype
    {idxs : \Idxs_n}
    {\Ctx_{idxs} : \Set}
    \; \textsc{Ctx}
  
    
    \inferrule
        { }
        {[] : Ctx_{[]}}
        
    \inferrule
        {\Gamma : \Ctx_{idxs} \\ x : \Carrier_{idx} ^2}
        {\Gamma \comma x : \Ctx_{idxs \comma idx}}
  \end{mathpar}
  \caption{Length-indexed context of carrier indices with a context of multiplicities on top.}
  \label{fig:ctx}
  \end{figure}
\end{nidefinition}


\subsection{Typing with Leftovers}\label{leftover typing}

\todo{syntax directed typing rules}

In a resource-aware calculi, typing rules modify the context of multiplicities under which their premises are typed -- e.g. in $\send{x}{y}P$ the multiplicity context under which $P$ is typed needs to be modified at at $x$ and $y$.
This context transformations can be modeled as functions on contexts, however threading these transformations through the proofs on typing rules is cumbersome, and these transformations necessitate of a myriad of additional lemmas.
Additionally, if the typing rules do not record the result of their actions on contexts, managing parallel composition entails a context split for which the user is required to provide an existential proof at the cutting point \todo{rephrase}.

An alternative is to keep track in the typing judgment of the way in which the context has been transformed.
One way of doing so is by mentioning both the \emph{input contexts} and the \emph{output contexts} over which the processes are typed.
Parallel composition then uses the output context of the left hand process as the input context of the right hand.
As an additional benefit, the associativity of parallel composition becomes trivial to prove.

In the \picalc{} both input and output contain variable references.
Both these actions need to modify their context, and thus using variable references that mention both their input and output contexts seems relevant.

Both the typing judgment and the variable references are of an inductive form.
As a consequence, all proofs on them will need to perform a double induction: once on the typing derivation, once for each variable reference.

Both the typing rules and the rules for variable references mention both contexts of types and contexts of multiplicities.
The contexts of types are threaded through the premises unchanged; the contexts of multiplicities are threaded through the premises using one premise's output as the next premise's input.
Both the context of types and the context of multiplicities are of a common length.

\begin{nidefinition}
  Akin to the typing rules for processes, the rules for variable references presented in Figure \ref{fig:variable-references} are indexed over the typing context, the input multiplicity context, and the output multiplicity context.
  The base case $\constr{zero}$ splits the last multiplicity in the input context into $x$ and the last multiplicity in the output context, while also ensuring that $t$ is the last type in the typing context.
  The inductive case $\constr{suc}$ appends the same multiplicity to both the input context and the output context, while also appending an extra type to the typing context.
  
  \todo{example}
  \todo{lift op to $^2$}
  
  \begin{figure}[h]
  \begin{mathpar}
    \mprset{sep=0.5em}
  
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      i : \Var_n \\
      t : \Type \\
      \stacked{
        idx : \Idx \\\\
        x : \Carrier_{idx}^2} \\
      \Delta : \Ctx_{idxs}}
    {\contains{\gamma}{\Gamma}{i}{t}{x}{\Delta} : \Set}
    \; \textsc{VarRef}
  
    \inferrule
        {t : \Type \\
          x \; y \; z : \Carrier_{idx}^2\\
          \op{x}{y}{z}}
    {\constr{zero} : \contains{\gamma \comma t}{\Gamma \comma x}{zero}{t}{y}{\Gamma \comma z}}
    
    \inferrule
        {t \; t' \; : \Type \\
          x : \Carrier_{idx}^2 \\
          x' : \Carrier_{idx'}^2 \\\\
      loc_i : \contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}}
    {\constr{suc} \; loc_i : \contains{\gamma \comma t'}{\Gamma \comma x'}{\suc i}{t}{x}{\Delta \comma x'}}
  \end{mathpar}
  \caption{Variable references as proofs on the typing context and input and output multiplicity contexts.}
  \label{fig:variable-references}
  \end{figure}
\end{nidefinition}

\lemma{The typing context $\gamma$ at index $i$ is type $t$.}
\lemma{The input multiplicity context $\Gamma$ at index $i$ is the result of performing the monoidal operation on $x$ and the output multiplicity context $\Delta$ at index $i$.}
\lemma{For every index $j$ other than $i$, the input multiplicity context $\Gamma$ at index $i$ is the output multiplicity $\Delta$ at index $i$.}
\corollary{Given the witness $\contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}$, $\Gamma \equiv \Delta$ iff $x \equiv \zero$.}
\proof{By structural induction on the variable reference}

\subsection{Typing judgments}\label{typing-judgments}

The indices in the variable reference rules are then used as the variable references of the underlying process.

\todo{comment on balancing in chan rule}

\begin{nidefinition}
  \begin{figure}[h]
  \begin{mathpar}
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      P : \Process_n \\
      \Delta : \Ctx_{idxs}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : \Set}
    \; \textsc{Types}
    
    \inferrule
    { }
    {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}
  
    \inferrule
    {t : \Type \\ x : \Carrier_{idx}^2 \\ y : \Carrier_{idx'} \\\\
     cont : \types{\gamma \comma \channel{t}{x}}{\Gamma \comma (y \comma y) }{P}{\Delta \comma \lz}}
    {\constr{chan} \; t \; x \; y \; cont : \types{\gamma}{\Gamma}{\new P}{\Delta}}
  
    \inferrule
    {chan_i : \contains{\gamma}{\Gamma}{i}{\channel{t}{x}}{\li}{\Xi} \\\\
     cont : \types{\gamma \comma t}{\Xi \comma x}{P}{\Theta \comma \lz}}
    {\constr{recv} \; chan_i \; cont : \types{\gamma}{\Gamma}{\recv{i}{P}}{\Theta}}
  
    \inferrule
    {chan_i : \contains{\gamma}{\Gamma}{i}{\channel{t}{x}}{\lo}{\Delta} \\\\
     loc_j : \contains{\gamma}{\Delta}{j}{t}{x}{\Xi} \\\\
     cont : \types{\gamma}{\Xi}{P}{\Theta}}
    {\constr{send} \; chan_i \; loc_j \; cont : \types{\gamma}{\Gamma}{\send{i}{j}P}{\Theta}}
  
    \inferrule
    {l : \types{\gamma}{\Gamma}{P}{\Delta} \\\\
     r : \types{\gamma}{\Delta}{Q}{\Xi}}
    {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
  \end{mathpar}
  \caption{This is...}
  \end{figure}
\end{nidefinition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Subject Reduction}\label{subject-reduction}

\subsection{Framing}


\subsection{Weakening}

Order preserving embeddings model a series of insertions. We only ever need one insertion to prove subject congruence, but there is no loss of generality.

\subsection{Strengthening}

\subsection{Swapping}

\subsection{Subject Congruence}\label{subject-congruence}

\subsection{Substitution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\cite{previous-work} polymorphic tokens, HOAS

\cite{typing-with-leftovers}

\cite{Higher-inductive-types-for-congruence}

\cite{LTS-semantics}

\cite{work-on-session-types}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permiting:

\begin{description}

\item [Affine types]
  
\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}


\bibliography{paper}
\end{document}
