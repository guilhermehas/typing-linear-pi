\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage{mathtools}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Diagrams
\usepackage{tikz}

% Mathbb doesn't support digits
\usepackage{bbm}

% Less margins around figures
\usepackage{changepage}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

% Do not use italics in definitions and theorems
\theoremstyle{definition}
\newtheorem{nidefinition}[theorem]{Definition}
\newtheorem{nitheorem}[theorem]{Theorem}
\newtheorem{nilemma}[theorem]{Lemma}

% No line numbers
\nolinenumbers

% Abbreviations
\newcommand{\lambdacalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}

% Typing rules
\newcommand{\stacked}[1]{\mprset{flushleft} \inferrule*{}{#1}}
\newcommand{\datatype}[2]{{\mprset{fraction={===}} \inferrule{#1}{#2}}}

\newcommand{\type}[1]{\textcolor{blue}{\operatorname{#1}}}
\newcommand{\constr}[1]{\textcolor{olive}{\operatorname{#1}}}
\newcommand{\field}[1]{\textcolor{red}{\operatorname{#1}}}

% Constructors
\newcommand{\PO}{\constr{\mathbf{0}}}
\newcommand{\comp}[2]{#1 \; \constr{\parallel} \; #2}
\newcommand{\new}{\constr{\boldsymbol{\nu}} \;}
\newcommand{\send}[2]{#1 \; \constr{\langle} \; #2 \;\constr{\rangle} \;}
\newcommand{\recv}[1]{#1 \; \constr{\mathbb{()}} \;}
\newcommand{\suc}{\constr{\scriptstyle 1+}}
\newcommand{\unit}{\constr{\mathbbm{1}}}
\newcommand{\base}[1]{\constr{B[} \; #1 \; \constr{]}}
\newcommand{\channel}[2]{\constr{C[} \; #1 \; \constr{\propto} \; #2 \; \constr{]}}
\newcommand{\comma}{\; \constr{,} \;}

% Functions
\newcommand{\subst}[3]{#1 \; [ \; #2 \; / \;#3 \;]}
\newcommand{\opsquared}[3]{#1 \, \coloneqq \, #2 \, \cdot^2 \, #3}
\newcommand{\opctx}[3]{#1 \, \coloneqq \, #2 \, \otimes \, #3}

% Fields
\newcommand{\op}[3]{#1 \; \field{\coloneqq} \; #2 \; \field{\cdot} \; #3}
\newcommand{\zero}{\field{0\cdot}}
\newcommand{\one}{\field{1\cdot}}
\newcommand{\li}{\field{\ell_i}}
\newcommand{\lo}{\field{\ell_o}}
\newcommand{\lz}{\field{\ell_{\o}}}
\newcommand{\lio}{\field{\ell_{\#}}}

% Types
\newcommand{\Set}{\type{SET}}
\newcommand{\reduce}[1]{\; \type{\longrightarrow}_{#1} \;}
\newcommand{\types}[4]{#1 \; \type{\propto} \; #2 \; \type{\vdash} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\contains}[6]{#1 \; \type{\propto} \; #2 \; \type{\ni}_{#3} \; #4 \; \type{\propto} \; #5 \; \type{\boxtimes} \; #6}
\newcommand{\containsusage}[4]{#1 \; \type{\ni}_{#2} \; #3 \; \type{\boxtimes} \; #4}
\newcommand{\Var}{\type{VAR}}
\newcommand{\Process}{\type{PROCESS}}
\newcommand{\Unused}{\type{UNUSED}}
\newcommand{\PreCtx}{\type{PRECTX}}
\newcommand{\Ctx}{\type{CTX}}
\newcommand{\Type}{\type{TYPE}\;}
\newcommand{\Idx}{\type{IDX}\;}
\newcommand{\Idxs}{\type{IDXS}}
\newcommand{\Carrier}{\type{CARRIER}}
\newcommand{\N}{\type{\mathbb{N}}}
\newcommand{\Channel}{\type{CHANNEL}}
\newcommand{\Rec}{\type{REC}}
\newcommand{\Quantifier}{\type{QUANTIFIER}}
\newcommand{\eq}[1]{\; \type{=}_{#1} \;}
\newcommand{\eqeq}{\; \type{\equiv} \;}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{$\pi$ with leftovers: \\ a mechanisation in Agda}
\titlerunning{$\pi$ with leftovers: a mechanisation in Agda}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi-calculus, linear types, leftover typing, concurrency, mechanization, Agda}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{We want to thank Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
  The \picalc{} is a computational model for communication and concurrency.
  The \emph{linear} \picalc{} is a typed version of the \picalc{} where channel resources must be used exactly once.
  With the rise of session types as a formalism to model real-world distributed systems, the linear \picalc{} has re-emerged as the underlying theoretical and practical framework for session types and communication-based distributed programming \cite{DardhaGS12,Padovani17,ScalasY16,ScalasDHY17}.
  While there have been several extensions to the session typed \picalc{}, the linear \picalc{} remains essentially unchanged and stable as a foundational calculus.

  We present the \emph{first} fully mechanised \picalc{} featuring linear types, as well as gradual and shared types.
  We present its syntax, operational semantics, and typing rules and the corresponding type safety properties.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalise the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  Our formalisation is fully mechanised in Agda. \cite{Zalakain2020Agda}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
We live in a concurrent world where any given state is often computed interactively by a myriad of parties --- people, machines, processors, services, networks.
As humans, we aim to model, predict, and even construct such interactive systems; as mathematicians, abstraction is our tool of choice to do so.
The \picalc{} \cite{MilnerPW92,Milner99,Sangio01} is the most successful computational model for communication and concurrency.
It abstracts over the details of concurrent processing and boils the interactions down to the sending and receiving of data through communication channels.
\todo{OD: The key point here is that the pi-calculus, especically the linear one, is a sufficcient core calculus where all research on concurrent and ditrubuted systems can be achieved. That is why we are inspecting it. The goal is to bring all distributed systems features (in the future) into the formalised world.}
Notably, it features \emph{channel mobility}: the channels themselves are first order constructs, and can therefore be transmitted.

The discovery of linear logic by J.-Y. Girard \cite{Girard87} opened new avenues in computing science and introduced linear types and type systems for (functional) programming languages \cite{Wadler90,Bernardy2018} \todo{fill the gaps with more PLs}.

The \emph{linear} \picalc{} \cite{KPT96,Sangio01} is a typed version of the \picalc{} where the linear type system restricts the usage of channel resources to exactly ones.
Session types \cite{H93,THK94,HVK98}...
Linearity is key in session types and the linear \picalc{} is the theoretica and practical framework and session types can be expressed in terms of linear \picalc{} \cite{DardhaGS12,DardhaGS17}.

We type the syntax for the \picalc{} in \S \ref{syntax}.
We use de Bruijn indices \cite{} as variable references, and dependent types to make the syntax well-scoped by construction: every unbound variable is accounted for in the type of the process that uses it.
\todo{OD: don't put references to section just yet. This first part should describe the what and why of the problem.
In the contributions section below, we can use references to sections to show where those contributions can be found.}
In the \lambdacalc{} all computations are local and happen on syntactically contiguous terms; in the \picalc{} however communicating subprocesses can be non-contiguous and even have different parent processes.
One way to define a reduction relation modulo these syntactic minutiae is to define a structural congruence \cite{} relation that acts as a quotient type.
A term $A$ can then be freely rewritten into a term $B$ as long as $A$ is structurally congruent to $B$.
We type this equivalence relation in \S \ref{structural-congruence}.

In the \lambdacalc{} function application is the main computational engine; in the \picalc{} it is inter-process communication what drives computation.
Two subprocesses can communicate anywhere in a process but under input and output, which must be respected to ensure the sequential behavior.
We type a reduction relation that acts as an operational semantics modulo subject congruence in \S \ref{operational-semantics}.
The base case of every such reduction is communication over a channel; we take care to track this information at the type level so that we can then use it to state the theorem for subject reduction (aka type preservation).

As with the untyped \lambdacalc{}, the untyped \picalc{} can be used to construct a wide variety of ill-behaved terms --- for some characterization of ill-behaved.
One can use type systems to constructively obtain a subset of terms for which certain properties hold.
As an example, the simply typed \lambdacalc{} ensures that the argument supplied to a function is of the expected type.
Correspondingly, the simply typed \picalc{} \cite{} ensures that the data sent over a channel is of the expected type.
This property is often referred to as \emph{communication safety}.

Another property of particular interest to concurrent systems is the avoidance of race conditions.
A type system that excludes multiple usages of a resource excludes race conditions.
In the linear \picalc{} \cite{} channels must be used exactly once.
This not only avoids races, but ensures \emph{communication privacy}: if both endpoints of a channel are acquired no other process can eavesdrop.
It also ensures that every declared communication channel must be used.
The linear \picalc{} is also interesting because together with product types it is isomorphic to session types \cite{} -- which are used to encode communication protocols.
We provide a typing system for the linear \picalc{} in \S \ref{type-system} as extensional rules on sitting on top of the unruly well-scoped syntax.

Linear type systems need of context splits.
These are tricky to handle constructively without explicitly asking the user to supply them.
Leftover typing \cite{} is a type theoretical technique that addresses this.
It does so by carrying both an input and an output context (the leftovers).
The output context can then be used as the input context of the continuations.
We apply this technique to the \picalc{} in \S \ref{leftover-typing}.
We generalize our algebra on usage multiplicities in \S \ref{multiplicities}.
As a result, we are able to model a mix of shared, linear, and gradual types.
\todo{reformulate paragraph}

\todo{subject reduction}

\subsection{Contribution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{description}
  \item [Machine verified formalisation of the linear pi calculus]

  \item [Typing with leftovers applied to the pi calculus]

  \item [Abstraction over multiplicities]

  \item [Full formalisation available in Agda]
\end{description}

\subsection{Notation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\type{\N} : \Set}
    \; \textsc{Nat}

    \inferrule
    { }
    {\constr{0} : \type{\N}}

    \inferrule
    {n : \type{\N}}
    {\suc n : \type{\N}}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Data type definitions have double lines and index-free synonyms as rule names, for ease of reference.
Otherwise, we use the constructor name as the name of a typing rule.
We omit universe levels for brevity.
Implicit arguments are mentioned by type definitions but omitted in constructors.
$\type{TYPES}$ are in blue and uppercased (with indices as subscripts), $\constr{constructors}$ are in olive, $\field{fields}$ in red, and variables and functions in black.
Some constructors can be shared across types and disambiguated by context.
\todo{OD: the next part to be filled should be the notation, so that when I go through the paper, I can use this as a manual.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}
\label{syntax}

In the \picalc{} both scope restriction and input introduce abstractions.
The bodies of these constructs need a way of referring to their argument.
Using names as variable references is a popular option amongst humans.
However, names are cumbersome to mechanize: inserting a new variable into a context means proving that the name of such variable is different from all other variable names in context.
Moreover, names are of no significance to machines.

Machines need constructs they can algorithmically act upon.
The idea de Bruijn had \cite{} was to use a natural number $n$ (aka \emph{index}) to refer to the variable introduced $n$ binders ago.
Binders no longer introduce any names.
\todo{OD: IMPORTATNT!
There is too much on lambda-calculus; I suggest you give examples and illustrate your points on the pi-calculus only from now on. It can get too broad and lack focus otherwise... It is fine in the Introduction as you are giving an overview.}
\begin{example}
The expression $\lambda g . (\lambda f . f g) g$ in the \lambdacalc{} would translate to $\lambda (\lambda 0 1) 0$.
\end{example}
That is, terms at different \emph{depths} use different indices to refer to the same binding.
Humans often find this confusing.
There is however no reason not to annotate these indices with the original names bestowed by humans.
Machines can then manipulate references mechanically while still using names to present terms to humans.

A variable occurring under $n$ abstractions has $n$ things to refer to.
References outside of that range have no associated meaning.
It is useful to rule out these nonsensical terms syntactically.
In Figure \ref{fig:var} we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Var_n : \Set}
  \; \textsc{Var}

  \inferrule
  {n : \N}
  {\constr{0} : \Var_{\suc n}}

  \inferrule
  {x : \Var_n}
  {\suc x : \Var_{\suc n}}
\end{mathpar}
\caption{Types of size $n$}
\label{fig:var}
\end{figure}

Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
As shown in Figure \ref{fig:syntax}, we increase the \emph{depth} counter every time we create a new channel or receive some input.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Process_n : \Set}
  \; \textsc{Process}
\end{mathpar}
  
\begin{equation*}
\begin{split}
  \Process_n ::=& \; \PO_n                    \\
              |& \; \new{} \Process_{\suc n}          \\
              |& \; \comp{\Process_n}{\Process_n}          \\
              |& \; \recv{\Var_n}{}\Process_{\suc n} \\
              |& \; \send{\Var_n}{\Var_n}\Process_n
\end{split}
\end{equation*}
\caption{Well-scoped grammar using de Bruijn indices}
\label{fig:syntax}
\end{figure}

Using type-level de Bruijn indices makes our syntax well-scoped by construction, and the semantics of our language can now be defined on the totality of the syntax.
User-friendliness can still be recovered through a function that converts processes with names into (possibly) processes with indices.
This function keeps track of what index is associated with what name, and traverses the process recursively, taking note of new binders and substituting variable references.
If the process is ill-scoped, the function returns nothing.
To present things back to the user, we print indices as their named annotations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}
\label{semantics}

In the \lambdacalc{} $\beta$-reduction operates on syntactically adjacent terms.
In the \picalc{} however, the syntax introduces unnecessary distinctions
(e.g. semantically, parallel composition is defined modulo associativity and commutativity).
There are several ways around this, a structural congruence relation being one of the historical ones.
(Others include labeled transition systems and higher inductive types.)

\subsection{Structural Congruence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{structural-congruence}

Structural congruence is a congruent equivalence relation on processes.
Any two structurally congruent processes are strongly bisimilar: they are can follow each other's reduction steps \cite{}.
Figure \ref{fig:struct-cong-base} lists the base cases of structural congruence.
The type $\Unused_i \; Q$ is an inductive proof on $Q$ that witnesses that the index $i$ does not appear nor in the inputs nor in the outputs of the process.
The function $lower \; i \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $i$.
Finally, $swap \; i \; P$ traverses $P$ (scoped under $\suc \suc n$) and swaps variable references $i$ and $\suc i$.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {P \eqeq Q : \Set}
  \; \textsc{StructCong}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{\comp{Q}{R}} \eqeq \comp{\comp{P}{Q}}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \eqeq \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \eqeq P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \eqeq \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \, Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \eqeq \comp{(\new P)}{lower \; 0 \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \eqeq \new \new swap \; 0 \; P}
\end{mathpar}
\caption{Structural rewriting rules. Premises $P$, $Q$ and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{fig:struct-cong-base}
\end{figure}

\begin{nilemma}
  \label{lm:lower-lift}
  The function $lower \; i \; P \; uP$ has an inverse $lift \; i \; P$ that increments every $\textsc{Var}$ greater than or equal to $i$, such that $lift \; i \; (lower \; i \; P \; uP) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}
  
\begin{nilemma}
  \label{lm:swap-swap}
  The function $swap \; i \; P$ is its own inverse: $swap \; i \; (swap \; i \; P) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}

Structural congruence is a congruent equivalence relation.
As such, rewrites can happen at any point in a process' recursive definition, and they are closed under reflexivity, symmetry and transitivity as shown in Figure \ref{fig:struct-cong}.
In \S \ref{subject-congruence} we will prove that if two processes $P$ and $Q$ are structurally congruent and $P$ is well-typed, then $Q$ is well-typed.
Specifically, in the case of transitivity, we must prove that if $P$ is structurally congruent with $Q$ and $Q$ with $R$, and $P$ is well-typed, then so is $R$.
To do so, we will have to proceed by induction and first get a proof of the well-typedness of $Q$, then use that to reach $R$.
To show that the doubly recursive call terminates we index the equivalence relation $=$ by the type $\Rec$, which models the structure of the recursion.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {\Rec : \Set}
  \; \textsc{Rec}

  \inferrule
  { }
  {\constr{zero} : \Rec}
  
  \inferrule
  {r : \Rec}
  {\constr{one} \; r : \Rec}

  \inferrule
  {r \; s : \Rec}
  {\constr{two} \; r \; s : \Rec}
  
  \datatype
  {P \, Q : \Process_n \\ r : \Rec}
  {P \eq{r} Q : \Set}
  \; \textsc{Equals}

  \inferrule
  {eq : P \eqeq Q}
  {\constr{struct} \; eq : P \eq{\constr{zero}} Q}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-scope} \; eq : \new P \eq{\constr{one} \; r} \new P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-comp} \; eq : \comp{P}{Q} \eq{\constr{one} \; r} \comp{P'}{Q}}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-recv} \; eq : \recv{x}P \eq{\constr{one} \; r} \recv{x}P'}

  \inferrule
  {eq : P \eq{r} P'}
  {\constr{cong-send} \; eq : \send{x}{y}P \eq{\constr{one} \; r} \send{x}{y}P'}

  \inferrule
  { }
  {\constr{refl} : P \eq{\constr{zero}} P}

  \inferrule
  {eq : P \eq{r} Q}
  {\constr{sym} \; eq : Q \eq{\constr{one} \; r} P}

  \inferrule
  {eq_1 : P \eq{r} Q \\ \; eq_2 : Q \eq{s} R}
  {\constr{trans} \; eq_1 \; eq_2 : P \eq{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.
  Premises $P$, $P'$, $Q$, and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{fig:struct-cong}
\end{figure}
  
\subsection{Operational Semantics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{operational-semantics}

Figure \ref{fig:reduction} models the operational semantics of the \picalc{}.
Processes put in parallel reduce when they communicate over a common variable.
The receiving process substitutes references to its most immediate variable with references to the variable sent by the process doing the output.
The process is then \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under structural congruence and goes under parallel composition and scope restriction
--- but notably not under input nor output, otherwise the sequencing of actions would not be preserved.
In \S \ref{subject-reduction} we prove that if $P$ reduces to $Q$ and $P$ is well-typed, so is $Q$.
However, this reduction operation is effectful: it consumes the variable over which communication happens.
If this variable is external to $P$ (it resides in its context) then the context in which $Q$ is typed must change.
To keep track of this information, we lift the variable index over which communication occurs to the type level.
Every time we come out of a binder we decrement this variable.
To do so, we make use of a $dec$ function that saturates at $\constr{internal}$ --- as opposed to an $inc$ function that would not.


\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Channel_n : \Set}
  \; \textsc{Channel}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  \datatype
  {i : \Channel_n \\ P \; Q : \Process_n}
  {P \reduce{i} Q : \Set}
  \; \textsc{Reduces}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce{\constr{external} \; i} \comp{lower \; 0 \; (\subst{P}{j}{0})}{Q}}

  \inferrule
  {red : P \reduce{i} P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce{i} \comp{P'}{Q}}

  \inferrule
  {red : P \reduce{i} Q}
  {\constr{res} \; red : \new P \reduce{dec\; i} \new Q}

  \inferrule
  {eq : P = P' \\ red : P' \reduce{i} Q}
  {\constr{struct} \; eq \; red : P \reduce{i} Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{fig:reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}
\label{type-system}


A \emph{resource-aware} typing system for the \emph{\picalc{}} is distinctive in several ways.

\begin{description}
  \item [As a resource-aware typing system,] the language is constrained not just by types, but also by their usage annotations.
    We must be able to add up and split usage contexts, to do so we introduce a generalized algebra in \S \ref{multiplicities}.
    We provide an independent inductive definition of typing contexts and usage contexts in \S \ref{contexts}.
    \todo{why independent}

  \item [As a typing system for the \picalc{},] the terms (processes) in the typing judgment do not come accompanied by a type -- processes have no type.
    It is the communication channels that are annotated with types and usages.
    Typing judgments assert that the process correctly uses the channels in the context under which it is typed.
\end{description}

In this paper, we combine typing and annotation judgments into a single judgment.
Although the typing rules are for now completely syntax-directed, adding support for branching would introduce choice in the typing derivations.
If we were to keep typing judgments and annotation judgments separate, we would need a coherence relation making sure that the same choice is taken by both.
We avoid doing so by combining them into a single judgment.

We make use \emph{leftover typing}, a technique consisting of adding an \emph{output context of usages} to the usual \emph{input context of usages}.
This output context contains the leftovers: the multiplicities unused by the processes.
Crucially, this output context can then be used as the input context of the continuation process.
The typing rules are introduced in \S \ref{leftover-typing}.

\subsection{Multiplicities and Capabilities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{multiplicities}

In the linear \picalc{} each channel has an input and an output \emph{capability}, and each capability has a given \emph{multiplicity} of 0 or 1.
In this paper we generalize over linearity and provide an algebra on multiplicities that is capable of encoding shared and gradual types as well.
The algebra has a single binary operator $(\cdot)$ that crushes multiplicities together.
It must satisfy the following constraints:
\begin{description}

\item [Partiality]
  Not all multiplicities are necessarily compatible: in the linear \picalc{} $1$ cannot be split into $1$ and $1$.
\item [Functionality]
  Given two multiplicities $y$ and $z$, it must be computable whether a third multiplicity $x$ exists such that $\op{x}{y}{z}$.
  If such an $x$ exists, it must be unique.
    
\item [Injectivity]
  To prove framing (\S \ref{framing}) we need to be able to \emph{subtract} multiplicities.
  For that end, we rely on $x - z \equiv y$ iff $\op{x}{y}{z}$.
  As a consequence, we must constraint $y$ to be uniquely determined as well.

\item [Associativity]
  As a direct consequence of the structural congruence rule $\comp{P}{\comp{Q}{R}} \equiv \comp{\comp{P}{Q}}{R}$.

\item [Commutativity]
  As a direct consequence of the structural congruence rule $\comp{P}{Q} \equiv \comp{Q}{P}$.

\item [Distinguished elements]
  There must be a neutral element $0$ absorbed on both sides.
  The neutral element $0$ must also be the minimal element.
  There must be a special element $1$ to record usage.
\end{description}

\begin{nidefinition}
  Together, the aforementioned constraints give raise to a \emph{partial commutative monoid}.
  We deal with partiality by modeling the monoidal operation as a terniary relation.
  An algebra on the carrier set $C$ forms a $\Quantifier_C$ iff it satisfies the fields in Figure \ref{fig:multiplicities}.
  
  \begin{figure}[h]
  \begin{equation}
  \begin{aligned}
    &\zero                  &:{} &                      &        & C \\
    &\one                   &:{} &                      &        & C \\
    &\op{\_}{\_}{\_}        &:{} &                      &        & C \to C \to C \to \Set \\
    &\field{\cdot-compute}  &:{} &\forall y z           & \to \; & \type{DEC} \; (\type{\exists} x . \; (\op{x}{y}{z})) \\
    &\field{\cdot-unique}   &:{} &\forall \{x x' y z\}  & \to \; & \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
    &\field{\cdot-unique^l} &:{} &\forall \{x y y' z\}  & \to \; & \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
    &\field{0\cdot-min^l}   &:{} &\forall \{y z\}       & \to \; & \op{\zero}{y}{z} \to y \equiv \zero \\
    &\field{\cdot-id^l}     &:{} &\forall \{x\}         & \to \; & \op{x}{\zero}{x} \\
    &\field{\cdot-comm}     &:{} &\forall \{x y z\}     & \to \; & \op{x}{y}{z} \to \op{x}{z}{y} \\
    &\field{\cdot-assoc}    &:{} &\forall \{x y z u v\} & \to \; & \op{x}{y}{z} \to \op{y}{u}{v} \to \type{\exists} w . \; (\op{x}{u}{w} \times \op{w}{v}{z})
  \end{aligned}
  \end{equation}
  \caption{Quantifier algebra $\Quantifier_C$ algebra on a partial commutative monoid.}
  \label{fig:multiplicities}
  \end{figure}
\end{nidefinition}

\begin{note}
  We will often work with input and output multiplicities pairs, and thus we use the notation $\Carrier^2$ to stand for the type $\Carrier \times \Carrier$, and $\opsquared{x}{y}{z}$ to stand for a monoidal operation on pairs of multiplicities -- where all of its properties are trivially lifted.
\end{note}

\begin{nidefinition}
  An indexed set of partial commutative monoids is a set of indices such that for every index there exists a carrier $C$ with a $\Quantifier_C$ algebra defined on it.
  This allows for several algebras to coexist in the same type system.
  Figure \ref{fig:indexed-multiplicities} captures these requirements: each index $i$ has a corresponding carrier type $\field{CARRIER}_i$ such that $\field{CARRIER}_i$ satisfies the algebra $\Quantifier_{\field{CARRIER}_i}$.
  We require the index type to be inhabited -- necessary to prove type preservation on $\new \PO_{\suc n} \eqeq \PO_n$.
  
  \begin{figure}[h]
  \begin{equation}
  \begin{split}
    &\field{IDX}          &:{} &\Set \\
    &\field{\exists IDX}  &:{} &\field{IDX} \\
    &\field{CARRIER}      &:{} &\field{IDX} \to \Set \\
    &\field{QUANTIFIERS}  &:{} &(i : \field{IDX}) \to \Quantifier_{\field{CARRIER}_i}
  \end{split}
  \end{equation}
  \caption{Indexed set of partial commutative monoids.}
  \label{fig:indexed-multiplicities}
  \end{figure}
\end{nidefinition}

\subsubsection{Example Type Systems}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo{Add typing derivations for example processes}

\begin{description}

\item [Shared]

The carrier $C$ is implemented as a type $\type{One}$ with a single trivial constructor $\constr{\omega}$.
Both $\zero$ and $\one$ are instantiated to $\constr{\omega}$.
The relation $\op{\constr{\omega}}{\constr{\omega}}{\constr{\omega}}$ is inhabited.
All other laws are trivially satisfied.

\item [Linear]

The carrier $C$ is implemented as a type $\type{Two}$ with the trivial elements $\constr{zero}$ and $\constr{one}$.
The monoidal operation has the element $\constr{zero}$ as neutral on both sides, and the element $\constr{one}$ splitting into $\constr{one}$ and $\constr{zero}$ (or $\constr{zero}$ and $\constr{\one}$), and is uninhabited in every other case.
All other rules follow trivially.

\item [Gradual]

The carrier $C$ is implemented as the type of natural numbers $\N$.
The element $\zero$ corresponds 0, and $\one$ to 1.
The partial monoid $\op{x}{y}{z}$ is defined exactly when $x \equiv y + z$.
All other rules follow trivially from the algebraic rules for the addition of naturals.
\todo{OD: in addition to the above, could we have examples of typing a process in each of the above type systems? It can be the same process everywhere and we can show how the typing changes...}
\end{description}

\subsection{Contexts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{contexts}

In a resource-aware \picalc{} type multiplicities change every time input and output occurs; however, the types themselves remain constant.
If multiplicities need not to depend on types, keeping types and multiplicities in independent contexts allows for a more modular approach to the algebra on contexts of multiplicities.
In this paper we choose that approach, which entails accepting that base non-channel types have dedicated input and output multiplicities too -- we will take care of impeding that any actual input or output can occur through them in the typing rules.

\begin{nidefinition}
  Figure \ref{fig:prectx} defines types as either unit types, base types or channel types.
  Unit types $\unit$ provide a proof of inhabitance for types, needed for the $\new \PO_{\suc n} \eqeq \PO_n$ rule in subject congruence.

  Base types $\base{n}$ use a natural number $n$ that can be reified into a type by the host language.
  Using natural numbers instead of type universes is convenient: there is no need to litter type types with universe polymorphism.
  
  Channel types $\channel{t}{x}$ use $t$ as the type of data sent over the channel and $x$ as the capability of the data sent over the channel.
  When data is received on a channel of type $\channel{t}{x}$, the type $t$ will be appended to the context of types $\PreCtx_n$ and the capability $x$ to the context of capabilities $\Ctx_{idxs}$.
  
  Types form length-indexed \emph{pre-contexts} $\PreCtx_n$.
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Type : \Set}
    \; \textsc{Type}
  
    \inferrule
    { }
    {\unit : \Type}

    \inferrule
    {n : \N}
    {\base{n} : \Type}
  
    \inferrule
    {t : \Type \\ \stacked{idx : \Idx \\\\ x : \Carrier_{idx}}}
    {\channel{t}{x} : \Type}
  \end{mathpar}
  
  \begin{mathpar}
    \datatype
    {n : \N}
    {\PreCtx_n : \Set}
    \; \textsc{PreCtx}
  
    \inferrule
        { }
        {[] : \PreCtx_0}
  
        \inferrule
            {\gamma : \PreCtx_n \\ t : \Type}
            {\gamma \comma t : \PreCtx_{\suc n}}
  \end{mathpar}
  \caption{Types and length-indexed typing contexts.}
  \label{fig:prectx}
  \end{figure}
\end{nidefinition}

\begin{nidefinition}
  To allow different multiplicity algebras to coexist we first define a length-indexed context of carrier indices $\Idxs_n$ (see \ref{fig:ctx}).
  On top of it, we define a context of multiplicities $\Ctx_{idxs}$.
  We lift the algebra on multiplicities to multiplicity contexts by constraining the algebra on multiplicity contexts to act on  contexts defined on the same underlying context of carrier indices.
  We use two multiplicities over a common index to represent multiplicities for both the input and the output capabilities ($\Carrier_{idx}^2$).
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Idxs_n : \Set}
    \; \textsc{Idxs}
  
    \inferrule
        { }
        {[] : \Idxs_0}
  
    \inferrule
        {idxs : \Idxs_n \\ idx : \Idx}
        {idxs \comma idx : \Idxs_{\suc n}}
  
        \\
        
    \datatype
    {idxs : \Idxs_n}
    {\Ctx_{idxs} : \Set}
    \; \textsc{Ctx}
  
    
    \inferrule
        { }
        {[] : Ctx_{[]}}
        
    \inferrule
        {\Gamma : \Ctx_{idxs} \\ x : \Carrier_{idx} ^2}
        {\Gamma \comma x : \Ctx_{idxs \comma idx}}
  \end{mathpar}
  \caption{Length-indexed context of carrier indices with a context of multiplicities on top.}
  \label{fig:ctx}
  \end{figure}
\end{nidefinition}

\begin{note}
  We lift the monoidal operation on pairs of multiplicities $\opsquared{x}{y}{z}$ to a monoidal operation on contexts with the same underlying vector of indices $\opctx{\Gamma}{\Delta}{\Xi}$, where all the properties of the partial monoid are trivially lifted to contexts.
\end{note}

\subsection{Typing with Leftovers}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{leftover-typing}

We use leftover typing \cite{} to encode our typing rules.
The insight of this approach is to use input and output contexts in the typing judgment.
Our typing judgment on processes are of the form $\types{\gamma}{\Gamma}{P}{\Delta}$ (introduced in Figure \ref{fig:types}).
This assertion is in fact both a typing judgment on $\gamma$ and a usage judgment on $\Gamma$ and $\Delta$.
These two judgments could, in fact, happen separately: our typing rules are completely syntax directed.
However, if we were to introduce branching, typing derivations would have to make choices, and the two separate judgments would need of a third relation to make sure that their choices agree.
To avoid this, we merge both judgments into a single one.
The typing context $\gamma$ needs to be explicit because the usage context $\Gamma$ and $\Delta$ do not in any way depend on it -- in fact, they are only related by their common length.

While the typing contexts are preserved through the typing derivation, the usage contexts change.
We use input and output usage contexts to capture this transformation.
This has two main advantages: for one, the usage modifications effected by both input and output can be enclosed in a self-containing typing and usage judgment for variable references (also with an output context); but more crucially, we avoid requesting an explicit constructive proof of context splitting for parallel composition -- if $P$ is typed under $\Gamma_l$ and $Q$ under $\Gamma_r$, then to type $\comp{P}{Q}$ under $\Gamma_m$ a proof $\opctx{\Gamma_m}{\Gamma_l}{\Gamma_r}$ would be needed.
The search for such a proof can be automated, but its existence is still required.
Moreover, providing a typing derivation for $P$ gets the user no usage annotations to type $Q$.
By using output usage contexts, we get the leftovers from the derivation on $P$ and use them to type $Q$.
This is the recurring theme in leftover typing: usage contexts are threaded through the premises.

The typing and usage judgments on both processes and variable references are of an inductive form.
As a result, the proofs on typing derivations will perform a double induction: once on the derivation of the process, once on the derivation of the variable reference.

\begin{nidefinition}
  Akin to the typing and usage judgment on processes, in Figure \ref{fig:variable-references} we present a typing and usage judgment on variable references -- also indexed over a typing context and an input an output usage context.
  However, in addition to this, variable references also record the index, the type, and the usage annotation of the variable reference.
  The base case $\constr{zero}$ ensures that $t$ is the most immediate type in typing context, and splits the most immediate annotation in the input context $x$ into the usage annotation for the variable $y$ and the annotation in the output context $z$.
  The inductive case $\constr{suc}$ appends an extra type to the typing context, and an extra usage annotation to both the input and output usage context.

  \begin{figure}[h]
  \begin{mathpar}
    \mprset{sep=0.5em}
  
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      i : \Var_n \\
      t : \Type \\
      \stacked{
        idx : \Idx \\\\
        y : \Carrier_{idx}^2} \\
      \Delta : \Ctx_{idxs}}
    {\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta} : \Set}
    \; \textsc{VarRef}
  
    \inferrule
    {\opsquared{x}{y}{z}}
    {\constr{zero} : \contains{\gamma \comma t}{\Gamma \comma x}{zero}{t}{y}{\Gamma \comma z}}
    
    \inferrule
    {loc_i : \contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}}
    {\constr{suc} \; loc_i : \contains{\gamma \comma t'}{\Gamma \comma x'}{\suc i}{t}{x}{\Delta \comma x'}}
  \end{mathpar}
  \caption{Variable references as proofs on the typing context and input and output multiplicity contexts.}
  \label{fig:variable-references}
  \end{figure}
\end{nidefinition}

\begin{remark}
  We use $\field{\cdot-unique}$ to relieve the user from the proof burden $\opsquared{x}{y}{z}$ in the base case $\constr{zero}$.
  This is the only place in the typing system that uses the algebra on multiplicities.
\end{remark}

\begin{example}
\todo{example}
\end{example}

\begin{nilemma}
  The typing context $\gamma$ at index $i$ is type $t$.
\end{nilemma}
\begin{nilemma}
  The input annotation in context $\Gamma$ at index $i$ is the result of aggregating (as per the algebra) $y$ and the output annotation in context $\Delta$ at index $i$.
\end{nilemma}
\begin{nilemma}
  For every index $j$ other than $i$, the input annotation in context $\Gamma$ at index $i$ is the output annotation in $\Delta$ at index $i$.
\end{nilemma}
\begin{nilemma}
  \todo{Add feedback and feedfront}
\end{nilemma}
\begin{corollary}
  Given the witness $\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta}$, $\Gamma \equiv \Delta$ iff $y \equiv \zero$.
\end{corollary}
\proof{All proofs are by structural induction on \textsc{VarRef}.}

\begin{nidefinition}
  The typing relation \textsc{Types} presented in Figure \ref{fig:types} is indexed over a context of types $\gamma$, a context of input multiplicities $\Gamma$, the process $P$ that is being typed, and the context of output capabilities $\Delta$, and notated as $\types{\gamma}{\Gamma}{P}{\Delta}$.
  \todo{empty output context}
  The typing rules are in one-to-one correspondence with the underlying syntax for processes, and thus we say they are syntax-directed.

  Process termination is typed under any typing context, and preserves the multiplicity context unchanged.

  Scope restriction accepts three parameters: the type $t$ of data sent over the channel; the input and output multiplicities $x$ of the data sent over the channel; and the multiplicity $y$ of the channel itself, which is used both as input and as output.
  The typing derivation of the continuation process $P$ has a channel of data type $t$ and data multiplicity $x$ added to the typing context, and the multiplicities $(y , y)$ added to the input multiplicity context.
  The continuation must completely exhaust this channel, to that end we substitute $(y , y)$ by $(\zero , zero)$ in the output context.
  \todo{comment on balancing in chan rule}

  Input requires a proof $chan_i$ locating a channel with data type $t$, data multiplicities $x$ and multiplicity $\ell_i$ \todo{} at index $i$ in the typing and multiplicity contexts $\gamma$ and $\Gamma$.
  The result of exhausting $\ell_i$ is the output multiplicity $\Xi$.
  The data type $t$ is then used to expand the typing context of the continuation $cont$, while the data multiplicities $x$ are appended to the output context $\Xi$ to form the input context over which $P$ is typed.
  These multiplicities $x$ must be exhausted by typing derivation of the continuation process.
  Note that the index $i$ is then used as part of the syntax.

  \todo{note that every new multiplicity introduced in an input context must be exhausted in the output context}

  Similar to input, output requires a proof $chan_i$ locating a channel with data type $t$ and data multiplicities $x$ in $\gamma$ at index $i$, however this time the channel must have multiplicity $\ell_o$.
  The result of exhausting $\ell_o$ is the output multiplicity $\Delta$.
  That output context $\Delta$ must have a variable of type $t$ and multiplicities $x$ at position $j$.
  This second proof represents the data that is sent over the channel.
  The result of exhausting the multiplicities $x$ of that variable is the context $\Xi$.
  The continuation process must be typed under this context $\Xi$.

  Finally, parallel composition requires its two subprocesses to be typed such that the output context of the first is the input context of the second.

  \begin{figure}[h]
  \begin{mathpar}
    \datatype{
      \gamma : \PreCtx_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma : \Ctx_{idxs}} \\
      P : \Process_n \\
      \Delta : \Ctx_{idxs}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : \Set}
    \; \textsc{Types}
    
    \inferrule
    { }
    {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}
  
    \inferrule
    {t : \Type \\ x : \Carrier_{idx}^2 \\ y : \Carrier_{idx'} \\\\
     cont : \types{\gamma \comma \channel{t}{x}}{\Gamma \comma (y \comma y) }{P}{\Delta \comma \lz}}
    {\constr{chan} \; t \; x \; y \; cont : \types{\gamma}{\Gamma}{\new P}{\Delta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma}{\Gamma}{i}{\channel{t}{x}}{\li}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma \comma t}{\Xi \comma x}{P}{\Theta \comma \lz}}}
        {\constr{recv} \; chan_i \; cont : \types{\gamma}{\Gamma}{\recv{i}{P}}{\Theta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma}{\Gamma}{i}{\channel{t}{x}}{\lo}{\Delta} \\\\
            loc_j \hspace{0.8em} : \contains{\gamma}{\Delta}{j}{t}{x\hspace{4em}}{\Xi} \\\\
            cont \hspace{0.6em} : \types{\gamma}{\Xi}{P\hspace{6em}}{\Theta}}}
        {\constr{send} \; chan_i \; loc_j \; cont : \types{\gamma}{\Gamma}{\send{i}{j}P}{\Theta}}
  
    \inferrule
    {l : \types{\gamma}{\Gamma}{P}{\Delta} \\\\
     r : \types{\gamma}{\Delta}{Q}{\Xi}}
    {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
  \end{mathpar}
  \caption{Leftover typing for a resource-aware typing system.}
  \label{fig:types}
  \end{figure}
  \todo{align typing rules to make them more readable}
\end{nidefinition}

\begin{nilemma}
  \label{lm:types-unused}
  If $P$ is well-typed under input context $\Gamma$ and output context $\Xi$, and variable $i$ is unused within $P$, then $\Gamma_i \equiv \Xi_i$.
\end{nilemma}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\begin{nilemma}
  \label{lm:types-op}
  For any well typed-process $P$ with input context $\Gamma$ and output context $\Xi$, there exists some $\Delta$ such that $\opctx{\Gamma}{\Delta}{\Xi}$.
\end{nilemma}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Type Safety}
\label{type-safety}

\todo{intro}

\subsection{Framing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Framing captures the idea that the well-typedness of a process does not depend on its unused resources.
These unused resources are not introduced as new variables -- the typing context remains unaltered -- but rather as extra multiplicities that are carried from the input context to the output context.

\begin{nitheorem}
  \label{thm:framing}
  Let $P$ be a well-typed process from context $\Gamma_l$ to $\Xi_l$.
  Then, per Lemma \ref{lm:types-op}, there exists some $\Delta$ such that $\opctx{\Gamma_l}{\Delta}{\Xi_l}$.
  Take arbitrary contexts $\Gamma_r$ and $\Xi_r$ such that $\opctx{\Gamma_r}{\Delta}{\Xi_r}$.
  Then $\types{\gamma}{\Gamma_r}{P}{\Xi_r}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Weakening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Weakening states that adding new variables to the typing and usage contexts preserves the well-typedness of a process.
The multiplicities of these new variables will be carried from the input context to the output context.
Usually, weakening is presented through order preserving embeddings.
Order preserving embeddings model a series of insertions into a context.
In this paper, we use weakening to prove subject congruence.
To do so, we need of a single insertion into a context, and thus we will limit our theorem statement to that, but there is no loss of generality.

\begin{nitheorem}
  \label{thm:weakening}
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let us insert an arbitrary type $t$ at position $i$ in the typing context and an arbitrary multiplicity $x$ at position $i$ into both the input and output contexts.
  Let us reflect this on the process $P$ by incrementing every index greater than or equal to $i$.
  The resulting process will be well-typed so that $\types{insert_i \; t \; \gamma}{insert_i \; x \; \Gamma}{lift_i \; P}{insert_i \; x \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Strengthening}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Strengthening states that removing unused variables from the typing and usage contexts preserves the well-typedness of a process.
The proof that a variable is unused within a process must be syntactical and cannot rely on the preservation of its usage annotations between the input and output contexts: a process can refer to a variable and still make no use of it -- e.g. by sending none of its multiplicities over a channel.

\begin{nitheorem}
  \label{thm:strengthening}
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let $i$ be a variable index that is not mentioned by $P$, such that $\Unused \; i \; P$.
  Then removing index $i$ from the typing context and both of the usage contexts and decrementing every variable in $P$ greater than $i$ preserves its well typedness, so that $\types{delete_i \; \gamma}{delete_i \; \Gamma}{lower_i \; P}{delete_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Swapping}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Swapping two variables (in the typing context, input and output usage contexts and process) preserves the well-typedness of a process.

\begin{remark}
  We limit ourselves to the swapping of contiguous variables $i$ and $\suc i$.
  Doing so is enough to prove subject reduction.
  The swapping of any two variables can be modeled as a sequence of contiguous variable swappings.
\end{remark}


\begin{nitheorem}
  \label{thm:swapping}
  Let $swap_i$ be a function that swaps variables $i$ and $\suc i$.
  For simplicity, we overload $swap$ and use it to swap types in a typing context, multiplicities in a usage context, and variable references in a process.
  Let $P$ be a well-typed process such that $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then $\types{swap_i \; \gamma}{swap_i \; \Gamma}{swap_i \; P}{swap_i \; \Xi}$.
\end{nitheorem}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\subsection{Subject Congruence}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{subject-congruence}

Structural congruence is an equivalence relation that aims to overcome the semantically meaningless difference introduced by the syntax of the \picalc{}.

\begin{nitheorem}
  \label{thm:subject-congruence}
  Applying structural congruence rules to a well-typed process should preserve its well-typedness under the same typing and usage contexts.
  If $P \eq{r} Q$ and $\types{\gamma}{\Gamma}{P}{\Xi}$ then $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  By induction on \textsc{Equals}.
  The case $\constr{struct}$ and its symmetric one under $\constr{sym}$ are the nontrivial ones.
  For those, we proceed by induction on \textsc{StructCong}:
  \begin{itemize}
    \item
      The case $\constr{comp-assoc}$ is trivial because the encoding with leftover typing of the typing rules naturally preserves associativity.
    \item
      The $\constr{comp-sym}$ case for a process $\comp{P}{Q}$ is however more complicated: $P$ must use framing (Theorem \ref{thm:framing}) to shift its output context to $Q$'s; $Q$ must use framing to shift its input context to $P$'s.
      The usage context on which $Q$ and $P$ coincide in $\comp{Q}{P}$ will no longer be the same.
    \item
      The case $\constr{comp-end}$ is trivial because in the typing rule for process $\PO$ the input and output contexts are one and the same.
    \item
      In the $\constr{scope-end}$ case, the typing rules $\constr{chan}$ and $\constr{end}$ work together to constraint the multiplicity of the newly create channel to $\ell_{\o}$, making the proof trivial.
      In the opposite direction, we will need to instantiate the newly created channel to a concrete type and multiplicities.
      For this, we will use type $\unit$ and multiplicities $\ell_{\o}$.
    \item
      In the $\constr{scope-ext}$ case for a process $\new \comp{P}{Q}$, we will make use of Lemma $\ref{lm:types-unused}$ to show that as the typing derivation on $P$ will preserved the multiplicity of the recently introduced variable unchanged.
      We then use strengthening (Theorem \ref{thm:strengthening}) to delete the recently introduced variable from $P$, and then compose with the typing derivation of $Q$ under $\constr{chan}$.
      In the reverse direction, we will weaken $P$ so that it can accept an additional variable.
      We will then use Lemma \ref{lm:lower-lift} to show that lifting a lowered $P$ leaves $P$ unchanged.
    \item
      Finally, for the $\constr{scope-comm}$ rule, we will use swapping as shown in Theorem \ref{thm:swapping}.
      In the reverse direction, we will use swapping and then use Lemma \ref{lm:swap-swap} to show that swapping indices twice leaves $P$ unchanged.
  \end{itemize}
\end{proof}
\todo{make sure constructor names in code coincide}

\begin{remark}
  We encode the recursive structure of \textsc{Equals} in its inductive definition -- by indexing its type with \textsc{Rec}.
  This acts as a justification of the well-formedness of the recursion scheme, which Agda cannot immediately see as terminating due to the interaction between the transitive and symmetric cases.
\end{remark}

\subsection{Substitution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When function abstraction and application come together in the \lambdacalc{} with de Bruijn indices, every reference to the innermost variable in the body of the abstraction gets replaced with the argument of the application.
In the \picalc{} however substitution takes another form: every reference to the innermost variable in the receiving process gets replaced with the reference to the data that is being sent over the channel.
In a resource-aware \picalc{}, that means that instead of exhausting all $m$ multiplicities of the most recent variable, we leave those unaltered and exhaust them from the variable that is being received.

\begin{nitheorem}
  \label{thm:substitution}
  Let $P$ be a process where the innermost variable has all its $m$ multiplities exhausted, such that $\types{\gamma , t}{\Gamma , m}{P}{\Psi , \ell_{\o}}$.
  Let $j$ be the index of the data that is being received.
  This data has at least $m$ multiplicities, such that $\contains{\gamma}{\Psi}{j}{t}{m}{\Xi}$.
  Then, we can substitute the most recent variable by $j$.
  As a result, we will exhaust no multiplicities on the innermost variable and exhaust them in $j$ instead, therefore $\types{\gamma , t}{\Gamma , m}{\subst{P}{j}{\constr{zero}}}{\Xi , m}$.
\end{nitheorem}

\begin{proof}
  By induction on the typing derivation on $P$.
  To be able to proceed under scope restriction, we need to generalize the theorem so that the variable that is being substituted need not be $\constr{zero}$, but any variable $i$.
  We introduce such generalization in Theorem \ref{thm:subst-generalization}.
  \todo{explain arguments}
\end{proof}

\begin{nitheorem}
  \label{thm:subst-generalization}

  We introduce an intermediate usage context $\Psi_m$.
  This intermediate context is the result of exhausting some $\Delta$ from the input context $\Gamma$, such that $\opctx{\Gamma}{\Delta}{\Psi_m}$.
  From $\Psi_m$, exhausting $m$ at index $i$ yields $\Psi_l$; exhausting it at index $j$ yields $\Psi_j$, such that $\contains{\gamma}{\Psi_m}{i}{t}{m}{\Psi_l}$ and $\contains{\gamma}{\Psi_m}{j}{t}{m}{\Psi_r}$.
  The input derivation on $P$ takes context $\Gamma$ and yields context $\Psi_l$, such that $\types{\gamma}{\Gamma}{P}{\Psi_l}$.
  The output derivation on $\subst{P}{j}{i}$ takes the same context $\Gamma$ but yields back $\Psi_r$, such that $\types{\gamma}{\Gamma}{\subst{P}{j}{i}}{\Psi_r}$.

  \begin{remark}
    \label{re:delta-zero}
    It is of uttermost importance that the variable that is being substituted has \emph{all} of its multiplicities substituted.
    To enforce this, we add an additional premise: that in going from $\Gamma$ to the intermediate context $\Psi_m$ we must exhaust no multiplicities at index $i$ -- so that $m$ indeed captures the totality of the multiplicities that are being exhausted between $\Gamma$ and $\Psi_l$.
    We capture this requirement by enforcing $\Delta_i \equiv \ell_{\o}$.
  \end{remark}
\end{nitheorem}

\begin{figure}[h]
  \begin{subfigure}{.5\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-l) at (0,6)   {$\Gamma_l$};
      \node (gamma-m)   at (0,3)   {$\Gamma$};
      \node (gamma-r) at (0,0)   {$\Gamma_r$};
      \node (xi-l)    at (3,5.5) {$\Xi_l$};
      \node (theta)   at (3,3.3) {$\Theta$};
      \node (delta-m) at (3,2.7) {};
      \node (xi-r)    at (3,0.5) {$\Xi_r$};
      \node (psi-l)   at (6,5)   {$\Psi_l$};
      \node (psi-m)   at (6,3)   {$\Psi$};
      \node (psi-r)   at (6,1)   {$\Psi_r$};

      \draw[-]  (gamma-m) -- (delta-m.center);
      \draw[->] (delta-m.center) -- node[align=center,below] {$\Delta$\\$\Delta_i = \ell_{\o}$}(psi-m);

      \draw[->,densely dotted] (gamma-m) -- (theta);
      \draw[->,densely dotted] (theta) -- (psi-m);
      
      \draw[->] (gamma-l) -- node[left] {$\ni_i m$} (gamma-m);
      \draw[->] (gamma-r) -- node[left] {$\ni_j m$} (gamma-m);
      \draw[->] (psi-l) -- node[right] {$\ni_i n$} (psi-m);
      \draw[->] (psi-r) -- node[right] {$\ni_j n$} (psi-m);

      \draw[->] (gamma-l) -- node[above] {$\vdash P$} (xi-l);
      \draw[->] (xi-l) -- node[above] {$\vdash Q$} (psi-l);
      \draw[->,densely dotted] (gamma-r) -- node[below] {$\vdash \subst{P}{j}{i}$} (xi-r);
      \draw[->,densely dotted] (xi-r) -- node[below] {$\vdash \subst{Q}{j}{i}$} (psi-r);
      \draw[->,densely dotted] (xi-l) -- node[left] {$\ni_i l$} (theta);
      \draw[->,densely dotted] (xi-r) -- node[left] {$\ni_j l$} (theta);
    \end{tikzpicture}
    \caption{
      Diagrammatic representation of the inductive substitution lemma.
      Continuous lines represent known facts, dotted lines proof obligations.
      From $\Delta_i = \ell_{\o}$, we can deduce that there exists some $\delta$ such that $\opsquared{m}{\delta}{n}$.
      From that, we can find first $\ni_i l$ and then $\ni_j l$, splitting the diagram across its vertical axis, making it possible to inductively derive both $\vdash \subst{P}{j}{i}$ and $\vdash \subst{P}{j}{i}$.
    }
    \label{fig:subst}
  \end{subfigure}
  \hspace{\fill} % DO NOT LEAVE EMPTY LINE
  \begin{subfigure}{.4\textwidth}
    \centering
    \begin{tikzpicture}
      \node (gamma-l) at (0,4)   {};
      \node (gamma-m) at (0,2)   {};
      \node (gamma-r) at (0,0)   {};
      \node (xi-l)    at (2,5)   {};
      \node (xi-m)    at (2,3.5) {};
      \node (xi-r)    at (2,2)   {};
      \node (psi-m)   at (4,3.5) {};

      \draw[->] (gamma-l) -- (xi-r);
      \draw[->] (gamma-m) -- (xi-r);
      \draw[->] (gamma-r) -- (xi-r);
      \draw[->] (gamma-l) -- (gamma-m);
      \draw[->] (gamma-r) -- (gamma-m);
      \draw[->] (xi-l)    -- (xi-m);
      \draw[->] (xi-r)    -- (xi-m);
      \draw[->] (xi-l)    -- (psi-m);
      \draw[->] (xi-m)    -- (psi-m);
      \draw[->] (xi-r)    -- (psi-m);
    \end{tikzpicture}
    \caption{
      Alternative approach without arrows $\ni_i n$ and $\ni_j n$.
      These are not strictly necessary, but they ease the composition of the inductive hypotheses.
      Without them, framing lemmas would have to be used extensively.
    }
    \label{fig:subst-compositionality}
  \end{subfigure}
\end{figure}

\begin{proof}
  \todo{BIG TODO}
\end{proof}

\subsection{Subject Reduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Subject reduction (aka type preservation) relates the operational semantics and the typing system of a language.
In its usual form, it states that if $P$ reduces to $Q$ and $P$ is well-typed under context $\Gamma$, then $Q$ is well-typed under $\Gamma$ too.
In the linear \picalc{} however, reduction \emph{is} meant to transform the context: each time communication occurs over a channel, that channel is exhausted.
In our case, and because we generalize linearity to a partial monoid, the channel over which the communication occurs will loose a multiplicity $\one$ on both its input and output capabilities.
In \S \ref{semantics}, we made sure to lift the index of the communicating channel to the type level, now we use it to state subject reduction.

\begin{nitheorem}
  Let $P \reduce{c} Q$.
  If $c$ is $\constr{internal}$ to the process, the context must not be modified and thus $\Gamma' \equiv \Gamma$.
  If $c$ is $\constr{external}\; i$, the input usage context at index $i$ must be decremented, and therefore $\containsusage{\Gamma'}{i}{\ell_\#}{\Gamma}$.
  Then the typing derivation $\types{\gamma}{\Gamma'}{P}{\Xi}$ can be transformed into $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}
  \hfill{}\\
  \begin{itemize}
    \item
    In the base case $\constr{comm}$ we need to construct a typing derivation $\types{\gamma}{\Gamma}{lower \; 0 \allowbreak \; (\subst{P}{\suc j}{\constr{zero}})}{\Xi}$ starting from the assumptions in Figure \ref{fig:subject-reduction:a}.
    We start by using framing (Theorem \ref{thm:framing}) to rearrange the consumption of the input and output multiplicities of the communicating channel and then apply substitution (Theorem \ref{thm:substitution}) and strengthening (Theorem \ref{thm:strengthening}).

    \begin{figure}[h]
      \setlength{\mathindent}{0pt}
      \begin{subfigure}{.3\textwidth}
        \begin{alignat*}{2}
          \containsusage{&\Gamma'}{i}{\ell_\# &&}{\Gamma} \\
          \contains{\gamma}{&\Gamma'}{i}{\channel{t}{m}}{\ell_i &&}{\Psi} \\
          \types{\gamma , t}{&\Psi , m}{P &&}{\Delta , \ell_{\o}} \\
          \contains{\gamma}{&\Delta }{i}{\channel{t}{m}}{\ell_o &&}{\Theta} \\
          \contains{\gamma}{&\Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Initial assumptions.}
        \label{fig:subject-reduction:a}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{alignat*}{2}
          \types{\gamma , t}{& \Gamma , m}{P &&}{\Theta , \ell_{\o}} \\
          \contains{\gamma}{& \Theta}{j}{t}{m &&}{\Xi}
        \end{alignat*}
        \caption{Rearrange $\ell_o$ witness, and merge with $\ell_i$ witness into $\ell_\#$.}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{align*}
          \types{\gamma , t}{\Gamma , m}{\subst{P}{\suc j}{\constr{zero}}}{\Xi , m}
        \end{align*}
        \caption{Substitution.}
      \end{subfigure}
      % Do not leave empty space
      \begin{subfigure}{.5\textwidth}
        \begin{align*}
          \types{\gamma , t}{\Gamma , m}{lower \; 0 \; (\subst{P}{\suc j}{\constr{zero}})}{\Xi , m}
        \end{align*}
        \caption{Strengthening.}
      \end{subfigure}
      \caption{Proof steps for the $\constr{comm}$ case in subject reduction.}
    \end{figure}
  
    \item
    Reduction under composition with $\constr{par}$ proceeds by induction on the process that is being reduced.

    \item
    Reduction under scope restriction case splits on the channel $c$ on which communication occurs.
    If the channel is $\constr{internal}$ to the process subject reduction proceeds inductively.
    If the channel is $\constr{external}\; \constr{zero}$ -- i.e. the channel that is being introduced by the scope restriction -- we use the Lemma \ref{lm:comm-capable} to subtract $\ell_\#$ from the channel's multiplicity first, then apply the induction hypothesis.
    If the channel is $\constr{external}\; (\suc i)$ subject reduction proceeds inductively.

    \item
    Finally, in the $\constr{struct}$ case, we apply subject congruence (Theorem \ref{thm:subject-congruence}) and then the induction hypothesis.
  \end{itemize}
\end{proof}

\begin{nilemma}
  \label{lm:comm-capable}
  Every input usage context $\Gamma$ on a well-typed process $\types{\gamma}{\Gamma}{P}{\Delta}$ that reduces such that $P \reduce{\constr{external} \; i} Q$ has a multiplicity of at least $\ell_\#$ at index $i$.
\end{nilemma}
\begin{proof}
  By induction on the reduction derivation $P \reduce{\constr{external \; i}}Q$.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\cite{previous-work} polymorphic tokens, HOAS

\cite{typing-with-leftovers}

\cite{Higher-inductive-types-for-congruence}

\cite{LTS-semantics}

\cite{work-on-session-types}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permiting:

\begin{description}

\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

  Bidirectional typing rules needed.

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}


\bibliography{paper}
\end{document}
