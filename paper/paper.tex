\documentclass[]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{amsmath}
\usepackage{mathbbol}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{todonotes}

% Two column itemize
\usepackage{multicol}

% Example code
\usepackage{listings}

% Diagrams
\usepackage{tikz}

% Mathbb doesn't support digits
\usepackage{bbm}

% inference rules
\usepackage{mathpartir}

% Newline inside table
\usepackage{makecell}

% Continue examples later on
\usepackage{thmtools}
\renewcommand\thmcontinues[1]{Continued}

% Do not use italics in definitions and theorems
\theoremstyle{definition}
\newtheorem{nidefinition}{Definition}
\newtheorem{nitheorem}{Theorem}
\newtheorem{nilemma}{Lemma}
% \newtheorem{example}{Example}
\renewcommand{\nidefinitionautorefname}{Definition}%
\renewcommand{\nitheoremautorefname}{Theorem}%
\renewcommand{\nilemmaautorefname}{Lemma}%
\renewcommand{\sectionautorefname}{\S}%
\renewcommand{\subsectionautorefname}{\S}%
% \renewcommand{\exampleautorefname}{Example}

% Abbreviations
\newcommand{\lambdacalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}

% Typing rules
\newcommand{\stacked}[1]{\mprset{flushleft} \inferrule*{}{#1}}
\newcommand{\datatype}[2]{{\mprset{fraction={===}} \inferrule{#1}{#2}}}

\newcommand{\type}[1]{\textcolor{blue}{\operatorname{#1}}}
\newcommand{\constr}[1]{\textcolor{orange}{\operatorname{#1}}}
\newcommand{\func}[1]{\textcolor{teal}{\operatorname{#1}}}

% Constructors
\newcommand{\PO}{\constr{\mathbb{0}}}
\newcommand{\comp}[2]{#1 \, \constr{\parallel} \, #2}
\newcommand{\new}{\constr{\boldsymbol{\nu}} \,}
\newcommand{\send}[2]{#1 \, \constr{\langle} \, #2 \,\constr{\rangle} \,}
\newcommand{\recv}[2]{#1 \, \constr{\mathbb{(}} \, #2 \, \constr{\mathbb{)}} \,}
\newcommand{\suc}{\constr{\scriptstyle 1+}}
\newcommand{\unit}{\constr{\mathbbm{1}}}
\newcommand{\base}[1]{\constr{B[} \, #1 \, \constr{]}}
\newcommand{\channel}[2]{\constr{C[} \, #1 \, \constr{;} \, #2 \, \constr{]}}
\newcommand{\comma}{\, \constr{,} \,}

% Functions
\newcommand{\subst}[3]{#1 \, \func{[} \, #3 \, \func{\mapsto} \,#2 \, \func{]}}
\newcommand{\op}[3]{#1 \, \func{\coloneqq} \, #2 \, \func{\cdot} \, #3}
\newcommand{\opsquared}[3]{#1 \, \func{\coloneqq} \, #2 \, \func{\cdot^2} \, #3}
\newcommand{\opctx}[3]{#1 \, \func{\coloneqq} \, #2 \, \func{\otimes} \, #3}
\newcommand{\zero}{\func{0\cdot}}
\newcommand{\one}{\func{1\cdot}}
\newcommand{\li}{\func{\ell_i}}
\newcommand{\lo}{\func{\ell_o}}
\newcommand{\lz}{\func{\ell_{\varnothing}}}
\newcommand{\lio}{\func{\ell_{\#}}}

% Types
\newcommand{\Set}{\type{SET}}
\newcommand{\reduce}[1]{\, \type{\longrightarrow}_{#1} \,}
\newcommand{\types}[4]{#1 \, \type{;} \, #2 \, \type{\vdash} \, #3 \, \type{\triangleright} \, #4}
\newcommand{\contains}[6]{#1 \, \type{;} \, #2 \, \type{\ni}_{#3} \, #4 \, \type{;} \, #5 \, \type{\triangleright} \, #6}
\newcommand{\containsusage}[4]{#1 \, \type{\ni}_{#2} \, #3 \, \type{\triangleright} \, #4}
\newcommand{\Var}{\type{VAR}}
\newcommand{\Process}{\type{PROCESS}}
\newcommand{\Raw}{\type{RAW}}
\newcommand{\Name}{\type{NAME}}
\newcommand{\Names}{\type{NAMES}}
\newcommand{\Fresh}{\type{FRESH}}
\newcommand{\WellScoped}{\type{WELLSCOPED}}
\newcommand{\Unused}{\type{UNUSED}}
\newcommand{\PreCtx}{\type{PRECTX}}
\newcommand{\Ctx}{\type{CTX}}
\newcommand{\Type}{\type{TYPE}\,}
\newcommand{\Idx}{\type{IDX}\,}
\newcommand{\Idxs}{\type{IDXS}}
\newcommand{\Usage}{\type{USAGE}}
\newcommand{\N}{\type{\mathbb{N}}}
\newcommand{\Channel}{\type{CHANNEL}}
\newcommand{\Rec}{\type{REC}}
\newcommand{\Algebra}{\type{ALGEBRA}}
\newcommand{\eq}[1]{\, \type{\simeq}_{#1} \,}
\newcommand{\eqeq}{\, \type{\cong} \,}

% Example
\newcommand{\sender}{\textcolor{brown}{sender}}
\newcommand{\receiver}{\textcolor{purple}{receiver}}
\newcommand{\courier}{\textcolor{cyan}{courier}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{$\pi$ with leftovers: \\ a mechanisation in Agda}
\titlerunning{$\pi$ with leftovers: a mechanisation in Agda}
\author{Uma Zalakain}{University of Glasgow, Scotland}{u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}{ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\keywords{pi-calculus, linear types, leftover typing, concurrency, mechanisation, Agda}
\Copyright{U. Zalakain, and O. Dardha}
\ccsdesc[300]{Theory of computation~Process calculi}
% \supplement{\url{https://github.com/umazalakain/typing-linear-pi}}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{document}

\acknowledgements{We want to thank Erika Kreuter, Wen Kokke, James Wood, Guillaume Allais, Bob Atkey, and Conor McBride for their thoughts, patience, work, education and camaraderie.}

\funding{The authors would also like to thank the anonymous referees for their valuable comments and helpful suggestions. This work is supported by the UK EPSRC grant EP/K034413/1 ``From Data Types to Session Types: A Basis for Concurrency and Distribution'' (ABCD), and by the EU HORIZON 2020 MSCA RISE project 778233 ``Behavioural Application Program Interfaces'' (BehAPI).}

\maketitle

\begin{abstract}
  The \picalc{} is a computational model for communication and concurrency.
  The \emph{linear} \picalc{} is a typed version of the \picalc{} where channels must be used exactly once.
  It is an underlying theoretical and practical framework on top of which more advanced types and theories can be built, such as \emph{session types} \cite{H93,THK94,HVK98}.

  We present an untyped syntax and semantics for the \picalc{}, on top of which we provide a resource-aware type system parametrised by a set of multiplicity algebras.
  This allows the user to mix \emph{linear}, \emph{graded} and \emph{shared} types, under the same unified framework.
  We use leftover typing \cite{Allais2018a} to encode our typing rules, thus avoiding the ubiquitous context splitting proofs common when dealing with linear type systems.
  We provide a framing theorem, generalise the weakening and strengthening theorems, and use them to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.
%
  Our formalisation is fully mechanised in Agda.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The \picalc{} \cite{MilnerPW92,Milner99} is a computational model for communication and concurrency that boils concurrent processing down to the sending and receiving of data over communication channels.
Notably, it features channel mobility: channels themselves are first class values, and can therefore be sent and received.
The \picalc{} is at the basis of the design and implementation of programming languages for concurrency, such as Pict \cite{PierceT00} and more recently Go \footnote{https://golang.org}.
At the state-of-the-art, the \picalc{} features a wide plethora of types \cite{K07}: basic types, linear types, session types, and types for liveness properties, such as deadlock freedom, livelock freedom or termination.
These make of the \picalc{} a fully-fledged tool for modelling and verifying concurrent and distributed systems.

In the early '90s, \emph{linear types} for (functional) programming languages \cite{Wadler90,Bernardy2018} were introduced, following J.-Y. Girard's development of linear logic \cite{Girard87}.
Linear type systems guarantee that resources are used \emph{exactly once}.
Enforcing this ``no duplicating'' and ``no discarding'' of resources via linearity allows for resource-aware programming and more efficient implementations \cite{Wadler90}.
Later on, linearity also inspired unique types, as in Clean \cite{BarendsenS96}, and ownership types, as in Rust \cite{MatsakisK14}.

\todo{introduce shared and graded types sooner}

Linearity influenced the $\pi$-calculus as well.
Kobayashi et al. \cite{KPT96} introduced a typed version of the \picalc{} where the linear type system restricts the usage of channels to exactly once.
%
With the rise of session types \cite{H93,THK94,HVK98} linearity acquired a different flavour: linearity ensures that each channel endpoint is owned by exactly one communicating participant, even though the channel itself may be used multiple times, as specified by its session type.
Linearity in session types is the key ingredient that guarantees communication safety and session fidelity.

In recent years, an encoding of session types into linear types \cite{DardhaGS12,Dardha14,DardhaGS17} has pushed the linear \picalc{} \cite{KPT96} into the spotlight again.
The encoding has been used as a technique to implement session types in mainstream programming languages such as OCaml \cite{Padovani17} and Scala \cite{ScalasY16,ScalasDHY17}, thus allowing to use the target linear \picalc{} as an underlying theoretical and practical framework on top of which session types can be defined and implemented.
\todo{go back to linear \picalc{}}

In this paper we make the following contributions:

\todo{complete}
\begin{enumerate}
  \item We use \textbf{type-level {de Bruijn indices} \cite{deBruijn1972, Dybjer1994} to introduce a syntax for \picalc{} processes that is well-scoped by construction}: every free variable is accounted for in the type of the process that uses it (\autoref{syntax}).

  \item We \textbf{abstract our type system over a set of resource-aware usage algebras}:
    The user is able to choose any mix of algebras for the type system --- as long as they comply with the specification.
    This allows for linear, graded and shared types to be mixed in the same type system.
    While linear types are useful for resource-aware programming, graded and shared types are useful for a more flexible and mainstream programming.

  \item We \textbf{apply leftover typing to the \picalc{} and prove type preservation for the resulting type system} along the lines of Allais \cite{Allais2018a}.
\end{enumerate}



\subsection{Summary}
\todo{shorten}
\begin{enumerate}
\item \textbf{Formalisation of the syntax and the semantics of the \picalc{}}:
 \begin{itemize}
   \item \textbf{Syntax}: we use type level {de Bruijn indices} \cite{deBruijn1972, Dybjer1994} to introduce a syntax of \picalc{} processes that is \emph{well scoped by construction}: every free variable is accounted for in the type of the process that uses it (\autoref{syntax}).
   For convenience and readability, the user can convert from and to a syntax using channel names (\autoref{from_to_deBruijn}).
   These conversion functions are shown to be inverses of one another up to $\alpha$-conversion.
   
   \item \textbf{Semantics}: we provide an operational semantics for the \picalc{}, prior to any typing (\autoref{semantics}).
   Thanks to our well-scoped grammar  (\autoref{syntax}), the operational semantics is defined on \emph{the totality of the syntax} as a reduction relation on processes (\autoref{operational-semantics}).
   The reduction relation tracks at the type level the channel on which communication occurs. This information is later used to state the subject reduction theorem --- aka type preservation (\autoref{thm:subject-reduction}).
   The reduction relation is defined modulo \emph{structural congruence} (\autoref{structural-congruence}) --- a relation defined on processes that acts as a quotient type to remove unnecessary syntactic minutiae introduced by the syntax of the \picalc{}.
 \end{itemize}
  
  \item \textbf{Leftover typing for the \picalc{} with support for linear, graded and shared types}:
  we present our type system for a resource-aware \picalc{} in \autoref{type-system}.
  \begin{itemize}
    \item \textbf{Algebras on multiplicities}: The user can provide \emph{resource-aware} algebras, which are then applied to the type system (\autoref{multiplicities}).
    Any \emph{partial commutative monoid} that is \emph{decidable}, \emph{deterministic}, \emph{cancellative} and has a \emph{minimal element} is a valid such algebra --- linear types, graded types and shared types all satisfy these algebraic laws.

    Multiple algebras can be simultaneously used in a single type system --- usage contexts keep information about what algebra to use on which element (\autoref{contexts}).
    This allows for type systems combining linear, graded and shared types under the same framework.
    
    \item \textbf{Leftover typing}: Our type system uses \emph{leftover typing} to model the resource-aware \picalc{} (\autoref{leftover-typing}).
    This approach adds a leftover usage context to the typing judgements.
    Typing derivations take the resources of their input usage context, consume some of them, and leave the remaining as leftovers in the output usage context.
    Leftover typing \textbf{makes top-down context splits unnecessary}, allows for \emph{framing} (\autoref{thm:framing}) to be stated, and makes it possible to generalise \emph{weakening} (\autoref{thm:weakening}) and \emph{strengthening} (\autoref{thm:strengthening}) for the \picalc{}.
  \end{itemize}

  \item \textbf{Fully mechanised formalisation and type safety results}:
    The formalisation of the \picalc{} with leftover typing, from the syntax to the semantics and the type system, has been fully mechanised in Agda and is publicly available in our GitHub repository \cite{Zalakain2020Agda}

    We present the type safety results of our \picalc{} with leftovers in \autoref{type-safety}.
    We have fully mechanised \emph{framing} (\autoref{thm:framing}), \emph{weakening} (\autoref{thm:weakening}) and \emph{strengthening} (\autoref{thm:strengthening}).
    We use these results to then prove and mechanise \emph{subject congruence} (\autoref{thm:subject-congruence}), and together with \emph{substitution} (\autoref{thm:substitution}), to prove and mechanise \emph{subject reduction} (\autoref{thm:subject-reduction}).
\end{enumerate}

\subsection{Notation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\type{\N} : \Set}
    \; \textsc{Nat}

    \inferrule
    { }
    {\constr{0} : \type{\N}}

    \inferrule
    {n : \type{\N}}
    {\suc n : \type{\N}}
  \end{mathpar}
  \caption{Notation used in this paper.}
  \label{fig:notation}
\end{figure}

\autoref{fig:notation} illustrates the notation used in this paper.
Data type definitions ($\type{\N}$) use double inference lines and index-free synonyms (\textsc{Nat}) as rule names for ease of reference.
Constructors ($\constr{0}$ and $\suc$) are given as inference rules.
We maintain a close correspondence between the definitions presented in this paper and our mechanised definitions in Agda: inference rules become type constructors, premises become argument types and conclusions return types.
Universe levels and universe polymorphism are omitted for brevity --- all our types are of type $\Set$.
Implicit arguments are mentioned in type definitions but omitted by constructors.

We use colours to further distinguish the different entities in this paper.
$\type{TYPES}$ are blue and uppercased, with indices as subscripts, $\constr{constructors}$ are orange, $\func{functions}$ are teal, variables are black, and some constructor names are overloaded --- and disambiguated by context.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}
\label{syntax}

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Var_n : \Set}
    \; \textsc{Var}

    \inferrule
    {n : \N}
    {\constr{0} : \Var_{\suc n}}

    \inferrule
    {x : \Var_n}
    {\suc x : \Var_{\suc n}}

    \datatype
    {n : \N}
    {\Process_n : \Set}
    \; \textsc{Process}
  \end{mathpar}

  \begin{equation*}
    \begin{aligned}
      \Process_n ::=& \; \PO_n               &&\text{(inaction)}   \\ 
      |& \; \new{} \Process_{\suc n}         &&\text{(restriction)}          \\ 
      |& \; \comp{\Process_n}{\Process_n}    &&\text{(parallel)} \\ 
      |& \; \recv{\Var_n}{}\Process_{\suc n} &&\text{(input)}                \\ 
      |& \; \send{\Var_n}{\Var_n}\Process_n  &&\text{(output)}                  
    \end{aligned}
  \end{equation*}
  \caption{Well-scoped grammar with type-level de Bruijn indices.}
  \label{fig:syntax}
\end{figure}


In order to mechanise the \picalc{} syntax in Agda, we need to deal with bound names in continuation processes.
Names are cumbersome to mechanise: they are not inherently well scoped, one has to deal with alpha-conversion, and inserting new variables into a context entails proving that their names differ from all other names in context.
To overcome these challenges, we use de Bruijn indices \cite{deBruijn1972}, where a natural number $n$ (aka \emph{index}) is used to refer to the variable introduced $n$ binders ago.
That is, binders no longer introduce names; terms at different \emph{depths} use different indices to refer to the same binding.

A variable reference occurring under $n$ binders can refer to $n$ distinct variables.
References outside of that range are meaningless.
It is useful to rule out these ill-scoped terms syntactically.
In \autoref{fig:syntax} --- which presents the syntax of the \picalc{} using de Bruijn indices --- we do so by introducing the indexed family of types \cite{Dybjer1994} $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.
We index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
Every time we go under a binder, we increase the index of the continuation process, allowing the variable references within to refer to one more thing.

\todo{adapt to de bruijn}
Process $\PO$ denotes the terminated process, where no further communications can occur.
Process $\new{}\; P$ creates a new channel bound with scope $P$.
Process $\comp{P}{Q}$ is the parallel composition of processes $P$ and $Q$.
Processes $\recv{x}{} P$ and $\send{x}{y} P$ denote respectively, the input and output processes of a variable $y$ over a channel $x$, with continuation $P$.
Scope restriction $(\new{}x) \; P$ and input $\recv{x}{y} \; P$ are \emph{binders}, they are the only constructs that introduce bound names --- $x$ and $y$ in $P$, respectively.

\begin{example}[The courier system]
\label{example-process}

We present an example that highlights the ways in which linear, graded and shared types can be used to prevent errors in a concurrent and distributed system defined by \picalc{} processes in parallel.

A courier system consists of three \emph{roles}:
a \sender{}, who wants to send a package;
a \receiver{}, who receives the package sent by the sender;
and a \courier{}, who carries the package from the sender to the receiver.

Our courier system (given in \autoref{fig:example-process}) is defined by four \picalc{} processes in parallel instantiating the above three roles:
we have two \sender{} processes, $S_1$ and $S_2$, sending data over channels $x$ and $y$, respectively;
one \receiver{} process, $R$, which receives over channel $z$ the data sent from each of the senders -- hence receives twice;
and a \courier{} process $C$, which synchronises communication among $S_1$, $S_2$ and $R$.
The \courier{} process $C$ first receives data from $S_1$ and $S_2$ on its input channels $x$ and $y$, respectively, and then sends the received data to $R$ along its output channel $z$.


We will now define the courier system as \picalc{} processes.
In our work, the syntax of \picalc{} processes adopts \emph{de Bruijn indices} \cite{deBruijn1972} for channel names and variables (details in \autoref{syntax}).
In short, for the purposes of this example:
process $\new{} P$ creates a new channel and makes it available at index $0$ in the continuation process $P$;
$\comp{P}{Q}$ composes processes $P$ and $Q$ in parallel; process $\recv{x}{}P$ receives data along channel $x$ and makes that data available at index $0$ in the continuation process $P$;
process $\send{x}{y}{P}$ sends variable $y$ over channel $x$ and continues as process $P$.
Both variable references $\Var_n$ and processes $\Process_n$ are indexed by the number $n$ of free variables they can refer to.

\begin{figure}[t]
  \small
  \centering
  \begin{tikzpicture}[draw,circle]
    \node[draw,circle,fill opacity=0.3,text opacity=1,fill=brown] (send-x) at (0,2)   {$\func{send} \, x$};
    \node[draw,circle,fill opacity=0.3,text opacity=1,fill=brown] (send-y) at (0,0)   {$\func{send} \, y$};
    \node[draw,circle,fill opacity=0.3,text opacity=1,fill=purple] (recv-z) at (4,1)   {$\func{recv} \, z$};
    \node[draw,circle,fill opacity=0.3,text opacity=1,fill=cyan,align=center] (sync) at (2,1)   {$\func{carry}$\\$ \, x \, y \, z$};

    \draw[->] (send-x) -- node[above] {$x$} (sync);
    \draw[->] (send-y) -- node[below] {$y$} (sync);
    \draw[->] (sync.10) -- node[above] {$z$} (recv-z.170);
    \draw[->] (sync) -- (recv-z);
  \end{tikzpicture}
  \caption{The courier system: two \sender{} $S_1$ and $S_2$, one \receiver{} $R$ and one \courier{} $C$.}
  \label{fig:example-process}
\end{figure}
For the sake of clarity, we will define the four subprocesses in our courier system separately and parametrise them by the channels on which they operate.
Each role \sender{}, \receiver{} and \courier{} is defined as a function respectively, $\func{send}, \func{recv}$ and $\func{carry}$.

The \sender{} \emph{role} is defined below.
The \sender{} creates a new channel to be sent as data, and sends it over channel $c$, and then terminates, denoted by process $\PO$.
\begin{flalign*}
  & \func{send} \; : \; \Var_n \to \Process_n & \\
  & \func{send} \; c = \new{} \send{(\suc c)}{\constr{0}} \PO
\end{flalign*}
Each \sender{} \emph{process} $S_1$ and $S_2$ is an instantiation of $\func{send} \; c$.
In particular,
$S_1$ is defined as $\func{send} \; x$ and $S_2$ as $\func{send} \; y$, where data is sent over channels $x$ and $y$, respectively (see \autoref{fig:example-process}).

The \receiver{} role is defined below, where $\func{recv} \; c \;$ receives data \emph{twice} on a channel $c$ and then terminates with $\PO$.
\begin{flalign*}
  & \func{recv} \; : \; \Var_n \to \Process_n & \\
  & \func{recv} \; c \; = \recv{c}{} \recv{(\suc c)} \PO
\end{flalign*}
The \receiver{} process $R$ is defined as  $\func{recv} \; z$, with channel $z$ instantiating $c$, which is the channel used to receive data from \courier{} (see \autoref{fig:example-process}).

The \courier{} role is defined below.
The \courier{} process $C$ is defined as $\func{carry} \; x \; y \; z$.
It sequentially receives on the two input channels $x$ and $y$ -- instantiating $in0$ and $in1$, and then outputs the two pieces of received data on the output channel $z$ -- instantiating $out$ (see \autoref{fig:example-process}).
\begin{flalign*}
  & \func{carry} \; : \; \Var_n && \to \Var_n \to \Var_n \to \Process_n & \\
  & \func{carry} \; in0 \; in1 \; out \; &&= \\
  & && \recv{in0}{} \\
  & && \recv{(\suc \; in1)}{} \\
  & && \send{(\suc \suc \; out)}{\suc \constr{0}} \\
  & && \send{(\suc \suc \; out)}{\constr{0}} \PO
\end{flalign*}

Finally, we compose these processes together and create three communication channels: the first channel is shared between the \sender{} $S_1$ and the \courier{} $C$, the second between the \sender{} $S_2$ and the \courier{} $C$, and the third between the \receiver{} $R$ and the \courier{} $C$.
The result is the courier systems defined below.
\begin{flalign*}
  & \func{system} && : \; \Process_{\constr{0}} & \\
  & \func{system} && = \new{} ( \func{send} \; \constr{0} \\
  & && \comp{}{ \new{} ( \func{send} \; \constr{0} } \\
  & && \comp{}{ \new{} ( \func{recv} \; \constr{0} } \\
  & && \comp{}{ \func{carry} \; (\suc \suc \constr{0}) \; (\suc \constr{0}) \; \constr{0}))) } \\
\end{flalign*}

In order to type the courier system we will use all three typing disciplines: linear, graded and shared typing.
We will continue this example and provide the typing derivations in \autoref{leftover-typing}.
We use \textbf{linear types} for the \emph{usage annotations} of data and \textbf{shared types} for the \emph{data} itself that is being sent from the \sender{} processes to the \receiver{}.
We use \textbf{graded types} for the usage annotations of the communication channels $x$, $y$, and $z$: the \sender{} processes $\func{send} \; x$ and $\func{send} \; y$ each consume $1$ output multiplicity and the \receiver{} process $\func{recv} \; z$ consumes $2$ input multiplicities, as it receives twice on channel $z$.
Dually, the \courier{} process $\func{carry} \; x \; y \; z$ consumes one input multiplicity on $x$, one input multiplicity on $y$, and two output multiplicities on $z$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Operational Semantics}
\label{semantics}
Thanks to our well-scoped grammar in \autoref{fig:syntax}, the semantics of our language can now be defined on the totality of the syntax.
We define structural congruence in \autoref{structural-congruence} and provide a reduction relation in \autoref{operational-semantics}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Structural Congruence}
\label{structural-congruence}

We define the base cases of a structural congruence relation \textsc{StructCong} $\eqeq$ in \autoref{fig:struct-cong-base}.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  { }
  {P \eqeq Q : \Set}
  \; \textsc{StructCong}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{(\comp{Q}{R})} \eqeq \comp{(\comp{P}{Q})}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \eqeq \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \eqeq P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \eqeq \PO_n}
  
  \inferrule
  {uQ : \Unused_{\constr{0}} \; Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \eqeq \comp{(\new P)}{\func{lower}_{\constr{0}} \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \eqeq \new \new \func{exchange}_{\constr{0}} \; P}
\end{mathpar}
\caption{Base cases of structural congruence.}
\label{fig:struct-cong-base}
\end{figure}

The first three rules ($\constr{comp}-$*) state associativity, symmetry, and $\PO$ as being the neutral element of parallel composition, respectively.
The last three ($\constr{scope}-$*) state garbage collection, scope extrusion and commutativity of restrictions, respectively.
In $\constr{scope-ext}$ the type $\Unused_i \; Q$ is an inductive proof asserting that the variable index $i$ does not appear neither in the inputs nor in the outputs of $Q$ (see \autoref{app:definitions}).
The function $\func{lower}_i \; Q \; uQ$ traverses $Q$ decrementing every index greater than $i$.
In $\constr{scope-comm}$ the function $\func{exchange}_i \; P$ traverses $P$ (of type $\allowbreak \Process_{\suc \suc n}$) and swaps variable references $i$ and $\suc i$.
In all the above, $i$ is incremented every time we go under a binder.
  
We lift the relation \textsc{StrucCong} $\eqeq{}$ and close it under equivalence and congruence in \textsc{Equals} $\eq{}$ as shown in \autoref{fig:struct-cong1}.
The $\constr{cong-}$* rules define structural congruence under a context $\mathcal{C}[\cdot]$ \cite{Sangio01}, respectively scope restriction, parallel composition, input and output.
The remaining three rules close structural congruence under reflexivity, symmetry and transitivity, respectively. 
The transitivity rule makes it tricky to prove predicates by induction on \textsc{Equals}: Agda cannot immediately see that such doubly recursive calls terminate.
In order to remedy this, we model the recursive call structure syntactically and index \textsc{Equals} by a type \textsc{Rec}.

\begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Rec : \Set}
    \; \textsc{Rec}
  
    \inferrule
    { }
    {\constr{zero} : \Rec}
    
    \inferrule
    {r : \Rec}
    {\constr{one} \; r : \Rec}
  
    \inferrule
    {r \; s : \Rec}
    {\constr{two} \; r \; s : \Rec}
    
    \datatype
    {P \, Q : \Process_n \\ r : \Rec}
    {P \eq{r} Q : \Set}
    \; \textsc{Equals}
  
    \inferrule
    {eq : P \eqeq Q}
    {\constr{struct} \; eq : P \eq{\constr{zero}} Q}
  
    \inferrule
    {eq : P \eq{r} P'}
    {\constr{cong-scope} \; eq : \new P \eq{\constr{one} \; r} \new P'}
  
    \inferrule
    {eq : P \eq{r} P'}
    {\constr{cong-comp} \; eq : \comp{P}{Q} \eq{\constr{one} \; r} \comp{P'}{Q}}
  
    \inferrule
    {eq : P \eq{r} P'}
    {\constr{cong-recv} \; eq : \recv{x}{}P \eq{\constr{one} \; r} \recv{x}{}P'}
  
    \inferrule
    {eq : P \eq{r} P'}
    {\constr{cong-send} \; eq : \send{x}{y}P \eq{\constr{one} \; r} \send{x}{y}P'}
  
    \inferrule
    { }
    {\constr{refl} : P \eq{\constr{zero}} P}
  
    \inferrule
    {eq : P \eq{r} Q}
    {\constr{sym} \; eq : Q \eq{\constr{one} \; r} P}
  
    \inferrule
    {eq_1 : P \eq{r} Q \\ \; eq_2 : Q \eq{s} R}
    {\constr{trans} \; eq_1 \; eq_2 : P \eq{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.}
\label{fig:struct-cong1}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reduction Relation}
\label{operational-semantics}

The operational semantics of the \picalc{} is defined as a reduction relation \textsc{Reduces} $\reduce{c}$ indexed by the channel $c$ on which communication occurs (\autoref{fig:reduction}).
We keep track of channel $c$ so we can state subject reduction (\autoref{thm:subject-reduction}).

We distinguish between channels that are created inside of the process ($\constr{internal}$), and channels that are created outside ($\constr{external}\ i$), where $i$ is the index of the channel variable.
In rule $\constr{comm}$, parallel processes reduce when they communicate over a common channel with index ${i}$.
As a result of that communication, the continuation of the input process $P$ has all the references to its most immediate variable substituted with references to $\suc j$, the variable sent by the output process $\send{i}{j}{Q}$.
After this substitution, $\subst{P}{\suc j}{\constr{0}}$ is \emph{lowered} --- all variable references are decreased by one (we apply \autoref{lm:substitution-unused} to obtain a proof $\Unused_{\constr{0}} \; (\subst{P}{\suc j}{\constr{0}})$).
Reduction is closed under parallel composition (rule $\constr{par}$), restriction (rule $\constr{res}$) and structural congruence (rule $\constr{struct}$) 
--- notably, not under input nor output, as doing so would not preserve the sequencing of actions \cite{Sangio01}.

\begin{nilemma}
  \label{lm:substitution-unused}
  For every variables $i$ and $j$, if $i \type{\not\equiv} j$ then $\Unused_i \allowbreak (\subst{P}{j}{i})$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}

Rule $\constr{res}$ uses $\func{dec}$ to decrement the index of channel $c$ as we wrap processes $P$ and $Q$ inside a binder.
This function saturates at $\constr{internal}$: wrapping an internally reducing process with a binder will result in an internally reducing process.

\begin{figure}[h]
\begin{mathpar}
  \datatype
  {n : \N}
  {\Channel_n : \Set}
  \; \textsc{Channel}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  \datatype
  {c : \Channel_n \\ P \; Q : \Process_n}
  {P \reduce{c} Q : \Set}
  \; \textsc{Reduces}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n}
  {\constr{comm} : \comp{\recv{i}{}P}{\send{i}{j}{Q}} \reduce{\constr{external} \; i} \comp{\func{lower}_{\constr{0}} \; (\subst{P}{\suc j}{\constr{0}}) \; uP'}{Q}}

  \inferrule
  {red : P \reduce{c} P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce{c} \comp{P'}{Q}}

  \inferrule
  {red : P \reduce{c} Q}
  {\constr{res} \; red : \new P \reduce{\func{dec}\; c} \new Q}

  \inferrule
  {eq : P \eq{} P' \\ red : P' \reduce{c} Q}
  {\constr{struct} \; eq \; red : P \reduce{c} Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{fig:reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Type System}
\label{type-system}

In \autoref{multiplicities} we characterise a usage algebra for our type system.
It defines how resources are \emph{split} in parallel composition and \emph{consumed} in input and output.
We define typing and usage contexts in \autoref{contexts}.
We provide a type system for a resource-aware \picalc{} in \autoref{leftover-typing}.

\subsection{Multiplicities and Capabilities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{multiplicities}

In the linear \picalc{} each channel has an input and an output \emph{capability}, and each capability has a given \emph{multiplicity} of 0 (exhausted) or 1 (available).
We generalise over this notion by defining an algebra for multiplicities that is satisfied by linear, graded and shared types alike.
We then use pairs of multiplicities as usage annotations for a channel's input and output capabilities.

\begin{nidefinition}[Usage algebra]
  A \emph{usage algebra} is a ternary relation $\op{x}{y}{z}$ that is \emph{partial} (as not any two multiplicities can be combined), \emph{deterministic} and \emph{cancellative} (to aid equational reasoning), \emph{associative} and \emph{commutative} (following directly from subject congruence for parallel composition), and in which the leftovers can be \emph{computed} (as to automatically update the usage context every time input and output occurs).
  It has a \emph{neutral element} $\zero$ that is absorbed on either side, and that is also \emph{minimal} (so that new resources cannot arbitrarily spring into life).
  It has an element $\one$ that is used to count inputs and outputs.
  \autoref{fig:multiplicities} defines such an algebra as a record $\Algebra_C$ on a carrier $C$.

  \begin{figure}[h]
  \begin{equation*}
  \begin{aligned}
    &\zero                   &:{} &                 &        & C \\
    &\one                    &:{} &                 &        & C \\
    &\op{\_}{\_}{\_}         &:{} &                 &        & C \to C \to C \to \Set \\
    &\func{\cdot-compute^r}  &:{} &\forall x y       & \to \; & \type{DEC} \; (\type{\exists} z  \; (\op{x}{y}{z})) \\
    &\func{\cdot-unique}     &:{} &\forall x x' y z  & \to \; & \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
    &\func{\cdot-unique^l}   &:{} &\forall x y y' z  & \to \; & \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
    &\func{\cdot-min^l}      &:{} &\forall y z        & \to \; & \op{\zero}{y}{z} \to y \equiv \zero \\
    &\func{\cdot-id^l}       &:{} &\forall x         & \to \; & \op{x}{\zero}{x} \\
    &\func{\cdot-comm}       &:{} &\forall x y z     & \to \; & \op{x}{y}{z} \to \op{x}{z}{y} \\
    &\func{\cdot-assoc}      &:{} &\forall x y z u v & \to \; & \op{x}{y}{z} \to \op{y}{u}{v} \to \\
    &                        &    &                  &        & \type{\exists} w  \; (\op{x}{u}{w} \times \op{w}{v}{z})
  \end{aligned}
  \end{equation*}
  \caption{
    Usage algebra $\Algebra_C$ on a carrier $C$.
    We use $\forall$ for universal quantification.
    The dependent product $\type{\exists}$ uses the value of its first argument in the type of its second.
    The type $\type{DEC} \; P$ is a witness of either $P$ or $P \to \type{\bot}$, where $\type{\bot}$ is the empty type with no constructors.
  }
  \label{fig:multiplicities}
  \end{figure}
\end{nidefinition}

\autoref{fig:algebra-instances} sketches the implementation of linear, graded and shared types as instances of our usage algebra.
Their use in typing derivations is illustrated in \autoref{example-derivation} (Continued).

\begin{figure}[h]
\begin{tabular}{l | l | l}
  & carrier & operation \\
  \hline
  \textbf{linear} & \makecell[cl]{$\constr{0} \, : \, \type{Lin}$ \\ $\constr{1} \, : \, \type{Lin}$} & \makecell[cl]{$\op{\constr{0}}{\constr{0}}{\constr{0}}$ \\ $\op{\constr{1}}{\constr{1}}{\constr{0}}$ \\ $\op{\constr{1}}{\constr{0}}{\constr{1}}$} \\
  \hline
  \textbf{graded} & \makecell[cl]{$\constr{0} \, : \type{Gra}$ \\ $\suc \, : \type{Gra} \to \type{Gra}$} & \makecell[cl]{$\forall \, x \, y \, z$ \\ $\to x \, \type{\equiv} \, y \, \func{+} \, z$ \\ $\to \op{x}{y}{z}$} \\
  \hline
  \textbf{shared} & $\constr{\omega} \, : \, \type{Sha}$ & $\op{\constr{\omega}}{\constr{\omega}}{\constr{\omega}}$ \\
\end{tabular}
\caption{Example instances of $\Usage$ and a ternary relation that satisfies our $\Algebra$ interface.}
\label{fig:algebra-instances}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection{Typing Contexts}
\label{contexts}

We use indexed sets of usage algebras to allow several usage algebras to coexist in our type system with leftovers (\autoref{leftover-typing}).
\begin{nidefinition}[Indexed set of usage algebras]
  An \emph{indexed set of usage algebras} is a type $\Idx$ of indices that is nonempty ($\type{\exists IDX}$) together with an interpretation $\Usage$ of indices into types, and an interpretation $\type{ALGEBRAS}$ of indices into usage algebras of the corresponding type (\autoref{fig:indexed-multiplicities}).
  \begin{figure}[h]
    \begin{equation*}
      \begin{aligned}
        &\Idx               &:{} &\Set \\
        &\type{\exists IDX} &:{} &\Idx \\
        &\Usage             &:{} &\Idx \to \Set \\
        &\type{ALGEBRAS}    &:{} &(idx : \Idx) \to \Algebra_{\Usage_{idx}}
      \end{aligned}
    \end{equation*}
    \caption{Indexed set of usage algebras.}
    \label{fig:indexed-multiplicities}
  \end{figure}
\end{nidefinition}

We keep typing contexts ($\PreCtx$, in \autoref{fig:prectx}) and usage contexts ($\Ctx$ in \autoref{fig:ctx}) separate.
The former are preserved throughout typing derivations; the latter are transformed as a result of input, output, and context splits.

\begin{nidefinition}[\textsc{Type} and \textsc{PreCtx}: types and typing contexts]
  A \emph{type} is either a unit type ($\unit$), a base type ($\base{n}$) or a channel type ($\channel{t}{x}$) (first two rows of \autoref{fig:prectx}).
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    { }
    {\Type : \Set}
    \; \textsc{Type}
  
    \inferrule
    { }
    {\unit : \Type}

    \inferrule
    {n : \N}
    {\base{n} : \Type}
  
    \inferrule
    {t : \Type \\ \stacked{idx : \Idx \\\\ x : \Usage_{idx}^{\func{2}}}}
    {\channel{t}{x} : \Type}
  \end{mathpar}
  
  \begin{mathpar}
    \datatype
    {n : \N}
    {\PreCtx_n : \Set}
    \; \textsc{PreCtx}
  
    \inferrule
        { }
        {[] : \PreCtx_{\constr{0}}}
  
        \inferrule
            {\gamma : \PreCtx_n \\ t : \Type}
            {\gamma \comma t : \PreCtx_{\suc n}}
  \end{mathpar}
  \caption{Types and length-indexed typing contexts.}
  \label{fig:prectx}
  \end{figure}
The unit type $\unit$ serves as a proof of inhabitance for types.
The base type $\base{n}$ uses natural numbers as placeholders for types (the host language can then interpret the former into the latter --- e.g., $0$ as booleans, $1$ as natural numbers) so that we avoid having to deal with universe polymorphism.
The type $\channel{t}{x}$ of a channel determines what type ${t}$ of data and what usage annotations ${x}$ are sent over that channel.
This channel notation aligns with $[t]\ \mathbf{chan}_{(i^{y},o^{z})}$, where $y,z$ are the multiplicities of input $i$ and output $o$ capabilities, respectively \cite{K07}.

A \emph{typing context} (last two rows of \autoref{fig:prectx}) is a length-indexed list of types, and is either empty $[]$ or the result of appending a type $t$ to an existing context $\gamma$.
\end{nidefinition}


\begin{nidefinition}[\textsc{Ctx}: usage contexts]
  A \emph{usage context} is a context $\Ctx_{idxs}$ of pairs of usage annotations that is indexed by a length-indexed context of indices $\Idxs_n$ (\autoref{fig:ctx}).

  A usage context is either empty $[]$ or the result or appending a usage annotation $x$ to an existing context $\Gamma$.

  We use the notation $\type{C}^{\func{2}}$ to stand for a $\type{C} \constr{\times} \type{C}$ pair of input and output multiplicities, respectively.
  Henceforth, we use $\lz$ to denote the multiplicity pair $0 \comma 0$, $\li$ for the pair $1 \comma 0$, $\lo$ for $0 \comma 1$, and $\lio$ for $1 \comma 1$.
  This notation was originally used in the linear \picalc{} \cite{KPT96,Sangio01}.

  \begin{figure}[h]
  \begin{mathpar}
    \datatype
    {n : \N}
    {\Idxs_n : \Set}
    \; \textsc{Idxs}
  
    \inferrule
        { }
        {[] : \Idxs_{\constr{0}}}
  
    \inferrule
        {idxs : \Idxs_n \\ idx : \Idx}
        {idxs \comma idx : \Idxs_{\suc n}}
  
    \datatype
    {idxs : \Idxs_n}
    {\Ctx_{idxs} : \Set}
    \; \textsc{Ctx}
  
    
    \inferrule
        { }
        {[] : \Ctx_{[]}}
        
    \inferrule
        {\Gamma : \Ctx_{idxs} \\ x : \Usage_{idx} ^{\func{2}}}
        {\Gamma \comma x : \Ctx_{idxs \comma idx}}
  \end{mathpar}
  \caption{Length-indexed context of carrier indices with a context of usage annotations on top.}
  \label{fig:ctx}
  \end{figure}
\end{nidefinition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\subsection{Typing with Leftovers}
\label{leftover-typing}

We use \emph{leftover typing} \cite{Allais2018a} for our type system, an approach that, in addition to the usual typing context $\PreCtx_n$ and (input) usage context $\Ctx_{idxs}$, adds an extra \emph{(output) usage context} $\Ctx_{idxs}$ to the typing rules.
This output context contains the \emph{leftovers} (the unused multiplicities) of the process being typed.
These leftovers can then be used as an input to another typing derivation.

Typing judgments for linear calculi typically carry a single context of usage annotations and thus the typing rules require frequent top-down proofs of context splitting --- e.g., the typing rule for parallel composition would look like:
\begin{mathpar}
  \inferrule
  {\opctx{\Gamma}{\Delta}{\Xi} \\ \Delta \; \type{\vdash} \; P \\ \Xi \; \type{\vdash} \; Q}
  {\Gamma \; \type{\vdash} \; \comp{P}{Q}}
\end{mathpar}
Input requires a similar context split; output requires two such context splits.
This is rather cumbersome: for input and output, the proof of context split carries \emph{exactly} the same information as the typing rule for variables; for parallel composition it means that the typing derivations of both subprocesses will have no context information whatsoever until the context split is determined.

Leftover typing solves this problem by inverting the flow of information so that \textbf{the typing derivations of the subprocesses determine the context split}.
As a result, usage information is threaded bottom-up through the typing derivation, and top-down context split proofs are no longer needed.
In addition, it allows \emph{framing} (\autoref{thm:framing}) to be stated, and \emph{weakening} (\autoref{thm:weakening}) and \emph{strengthening} (\autoref{thm:strengthening}) to acquire a more general form.

Our type system with leftovers is composed of two typing relations: one for variable references (\autoref{def:varref}) and one for processes (\autoref{def:types}).
Both relations are indexed by a typing context $\gamma$, an input usage context $\Gamma$, and an output usage context $\Delta$ (the leftovers).

The \textbf{typing judgement for variables} $\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta}$ asserts that ``index $i$ in typing context $\gamma$ is of type $t$, and subtracting $y$ at position $i$ from input usage context $\Gamma$ results in leftovers $\Delta$''.
The \textbf{typing judgement for processes} $\types{\gamma}{\Gamma}{P}{\Delta}$ asserts that ``process $P$ is well typed under typing context $\gamma$, usage input context $\Gamma$ and leftovers $\Delta$''.


\begin{nidefinition}[\textsc{VarRef}: typing variable references]
  \label{def:varref}

  The \textsc{VarRef} typing relation for variable references is presented in \autoref{fig:variable-references}.

  \begin{figure}[h]
  \begin{mathpar}
    \mprset{sep=0.5em}
  
    \datatype{
      \gamma : \PreCtx_n \\
      i : \Var_n \\
      \stacked{
        t : \Type \\\\
        idx : \Idx \\\\
        y : \Usage_{idx}^{\func{2}}} \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma \; \Delta : \Ctx_{idxs}}}
    {\contains{\gamma}{\Gamma}{i}{t}{y}{\Delta} : \Set}
    \; \textsc{VarRef}
  
    \inferrule
    {\opsquared{x}{y}{z}}
    {\constr{0} : \contains{\gamma \comma t}{\Gamma \comma x}{\constr{0}}{t}{y}{\Gamma \comma z}}
    
    \inferrule
    {loc_i : \contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}}
    {\suc \; loc_i : \contains{\gamma \comma t'}{\Gamma \comma x'}{\suc i}{t}{x}{\Delta \comma x'}}
  \end{mathpar}
  \caption{Typing rules for variable references.}
  \label{fig:variable-references}
  \end{figure}

  We lift the operation $\op{x}{y}{z}$ and its algebraic properties to an operation $\opsquared{(x_l \comma x_r)}{(y_l \comma y_r)}{(z_l \comma z_r)}$ on pairs of multiplicities and an operation $\opctx{\Gamma}{\Delta}{\Xi}$ on usage contexts with the same underlying context of indices.

  The base case $\constr{0}$ splits the usage annotation $x$ of type $\Usage_{idx}$ into $y$ and $z$ (the leftovers).
  Note that the remaining context $\Gamma$ is preserved unused as a leftover.
  This splitting $\opsquared{x}{y}{z}$ is as per the usage algebra provided by the developer for the index $idx$.
  We use the \emph{computability} of the monoidal relation to alleviate the user from the proof burden $\opsquared{x}{y}{z}$.
  The inductive case $\suc$ appends the type $t'$ to the typing context, and the usage annotation $x'$ to both the input and output usage contexts. 
\end{nidefinition}

\begin{example}[Variable reference]
  \autoref{lst:channels} types a variable reference under a linear algebra.
  \begin{lstlisting}[label=lst:channels,xleftmargin=15pt,mathescape,numbers=left,caption=Typing variable reference $\suc \constr{0}$ with type $\channel{\unit}{\li}$ and usage $\li$.]
$\_ \; : \; \contains{\constr{[]} \comma \channel{\unit}{\li} \comma \unit} {\constr{[]} \comma \lio \comma \lio} {\suc \constr{0}} {\channel{\unit}{\li}} {\li} {\constr{[]} \comma \lo \comma \lio}$
$\_ \; = \; \suc \constr{0}$

$\_ \; : \; \contains{\constr{[]} \comma \channel{\unit}{\li}} {\constr{[]} \comma \lio} {\constr{0}} {\channel{\unit}{\li}} {\li} {\constr{[]} \comma \lo}$
$\_ \; = \; \constr{0}$
  \end{lstlisting}
  In Agda, the underscore \_ introduces an anonymous declaration immediately followed by its definition.
  We must show that the variable at position $\suc \constr{0}$ is of type $\channel{\unit}{\li}$ and has a usage annotation $\li$ in an environment with a typing context $\constr{[]} \comma \channel{\unit}{\li} \comma \unit$ and a usage context $\constr{[]} \comma \lio \comma \lio$.
  The \textsc{VarRef} constructors we must use are completely determined by $\suc \; \constr{0}$ in the type.
  The constructor $\suc$ steps under the outermost variable in the context, preserving its usage annotation $\lio$ from input to output, the result is the obligation on line 4.
  The constructor $\constr{0}$ asserts that the next variable is of type $\channel{\unit}{\li}$, and that the usage annotation $\lio$ can be split such that $\op{\lio}{\li}{\lo}$ --- we use $\func{\cdot-compute^r}$ to fulfill this proof obligation automatically.
\end{example}

\begin{nidefinition}[\textsc{Types}: typing processes]
  \label{def:types}

  The \textsc{Types} typing relation for \picalc{} processes is presented in \autoref{fig:types}.
  For convenience, we reuse the constructor names introduced for the syntax in \autoref{fig:syntax}.
  
  \begin{figure}[h]
  \begin{mathpar}
    \datatype{
      \gamma : \PreCtx_n \\
      P : \Process_n \\
      \stacked{
        idxs : \Idxs_n \\\\
        \Gamma \; \Delta : \Ctx_{idxs}}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : \Set}
    \; \textsc{Types}
    
    \inferrule
    { }
    {\PO : \types{\gamma}{\Gamma}{\PO}{\Gamma}}
  
    \inferrule
    {t : \Type \\ x : \Usage_{idx}^{\func{2}} \\ y : \Usage_{idx'} \\\\
     cont : \types{\gamma \comma \channel{t}{x}}{\Gamma \comma (y \comma y) }{P}{\Delta \comma \lz}}
    {\new \; t \; x \; y \; cont : \types{\gamma}{\Gamma}{\new P}{\Delta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma \hspace{1.0em}}{\Gamma \hspace{1.0em}}{i}{\channel{t}{x}}{\li}{\Xi} \\\\
            cont \hspace{0.5em} : \types{\gamma \comma t}{\Xi \comma x}{P \hspace{4.2em}}{\Theta \comma \lz}}}
        {\recv{chan_i}{} cont : \types{\gamma}{\Gamma}{\recv{i}{}P}{\Theta}}
  
    \inferrule
        {\stacked{
            chan_i : \contains{\gamma}{\Gamma \hspace{0.1em}}{i}{\channel{t}{x}}{\lo}{\Delta} \\\\
            loc_j \hspace{0.7em} : \contains{\gamma}{\Delta}{j}{t \hspace{2.8em}}{x \hspace{0.2em}}{\Xi} \\\\
            cont \hspace{0.5em} : \types{\gamma}{\Xi}{\hspace{0.4em}P\hspace{4.0em}}{\Theta}}}
        {\send{chan_i}{loc_j} cont : \types{\gamma}{\Gamma}{\send{i}{j}P}{\Theta}}
  
    \inferrule
    {l : \types{\gamma}{\Gamma}{P\hspace{0.3em}}{\Delta} \\\\
     r : \types{\gamma}{\Delta}{Q}{\Xi}}
    {\comp{l}{r} : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
  \end{mathpar}
  \caption{Leftover typing for a resource-aware type system.}
  \label{fig:types}
  \end{figure}

  The inaction process in rule $\PO$ does not change usage annotations.
  The scope restriction in rule $\new$ expects three arguments: the type $t$ of data being transmitted; the usage annotation $x$ of what is being transmitted; and the multiplicity $y$ given to the channel itself.
  This multiplicity $y$ is used for both input and output, so that they are balanced.
  The continuation process $P$ is provided with the new channel with usage annotation $y \comma y$, which it must completely exhaust.
%
  The input process in rule $\recv{}{}$ requires a channel $chan_i$ at index $i$ with usage $\li$ available, such that data with type $t$ and usage $x$ can be sent over it.
  Note that the index $i$ is used in the syntax of the typed process.
  We use the leftovers $\Xi$ to type the continuation process, which is also provided with the received element --- of type $t$ and multiplicity $x$ --- at index $\constr{0}$.
  The received element $x$ must be completely exhausted by the continuation process.
%
  Similarly to input, the output process in rule $\send{}{}$ requires a channel $chan_i$ at index $i$ with usage $\lo$ available, such that data with type $t$ and usage $x$ can be sent over it.
  We use the leftover context $\Delta$ to type the transmitted data, which needs an element $loc_j$ at index $j$ with type $t$ and usage $x$, as per the type of the channel $chan_i$.
  The leftovers $\Xi$ are used to type the continuation process.
  Note that both indices $i$ and $j$ are used in the syntax of the typed process.
%
  Parallel composition in rule $\comp{}{}$ uses the leftovers of the left-hand process to type the right-hand process.
  By keeping track in the typing derivation of $P$ of the resources $P$ uses, we can use them to type $Q$ and save the user from having to provide a top-down proof of context split.
\end{nidefinition}

\begin{example}[Typing derivation, continues=example-process]
\label{example-derivation}

We provide the typing derivation for the courier system defined in \autoref{example-process}.
For the sake of simplicity, we instantiate these processes with concrete variable references before typing them.

The \receiver{} defined by the $\func{recv}$ process receives data along the channel with index $0$, thus that variable needs to be of channel type $\channel{t}{u}$ for some $t$ and $u$.
After receiving twice, the process ends, and we should not be left with any unused multiplicities: $u$ needs to be $\lz$.
We will use graded types to keep track of the exact number of times communication happens.
Whatever the input multiplicity of the channel, we will consume $2$ of it and leave the remaining as leftovers.
Once the types are given, the typing derivation is completely syntax directed.
\begin{flalign*}
  & \func{\vdash recv} \; \types{\gamma \comma \channel{t}{\lz}}{\Gamma \comma (\suc \suc l \comma r)}{\func{recv} \; \constr{0}}{\Gamma \comma (l \comma r)} & \\
  & \func{\vdash recv} \; = \; \recv{\constr{0}}{} \recv{(\suc \constr{0})}{} \PO
\end{flalign*}

The \sender{} defined by the $\func{send}$ process sends data along the channel with index $0$, thus that variable needs to be of channel type $\channel{t}{u}$ for some $t$ and $u$.
We instantiate $t$ (the type of data that the \sender{} sends) to $\channel{\unit}{\func{\omega}}$, as that is a value we can easily construct.
As per the type of the process $\func{recv}$, the transmitted multiplicities $u$ are $\lz$.
We will transmit once, thus use a single output multiplicity, and leave the rest as leftovers.
Agda can uniquely determine the arguments required by the $\new{}$ constructor, and thus we can omit them using underscores.
\begin{flalign*}
  & \func{\vdash send} \; \types{\gamma \comma \channel{\channel{\unit}{\func{\omega}}}{\lz}}{\Gamma \comma (l \comma \suc r)}{\func{send} \; \constr{0}}{\Gamma \comma (l \comma r)} & \\
  & \func{\vdash send} \; = \; \new{} \; \_ \; \_ \; \zero \; \send{(\suc \constr{0})}{\constr{0}} \PO
\end{flalign*}

Dually, the \courier{} defined by the $\func{carry}$ process expects input multiplicities for the channels shared with $\func{send}$ and output multiplicities for the channel shared with $\func{recv}$.
The typing derivation here is uniquely determined by the type and syntax of the process.
\begin{flalign*}
& \func{\vdash carry} && : \types{\gamma \comma \channel{t}{\lz} \comma \channel{t}{\lz} \comma \channel{t}{\lz}\\ & &&}{\Gamma \comma (\suc lx \comma rx) \comma (\suc ly \comma ry) \comma (lz \comma \suc \suc rz)\\ & &&}{\func{carry} \; (\suc \suc \constr{0}) \; (\suc \constr{0}) \; \constr{0}\\ & &&}{\Gamma \comma (lx \comma rx) \comma (ly \comma ry) \comma (lz \comma rz)} & \\
& \func{\vdash carry} && = \\
& && \recv{(\suc \suc \constr{0})}{} \\
& && \recv{(\suc \suc \constr{0})}{} \\
& && \send{(\suc \suc \constr{0})}{\suc \constr{0}} \\
& && \send{(\suc \suc \constr{0})}{\constr{0}} \PO
\end{flalign*}

We can now compose these processes in parallel and type the courier system.
Specifying the types of the channels is not required: Agda can infer them from the types of the processes.
\begin{flalign*}
& \func{\vdash system} && : \; \types{\constr{[]}}{\constr{[]}}{\func{system}}{\constr{[]}} & \\
& \func{\vdash system} && = \new{} \; \_ \; \_ \; \_ \; ( \func{\vdash send} \\
& && \comp{}{ \new{} \; \_ \; \_ \; \_ } \; ( \func{\vdash send} \\
& && \comp{}{ \new{} \; \_ \; \_ \; \_ } \; ( \func{\vdash recv} \\
& && \comp{}{ \func{\vdash carry} })))
\end{flalign*}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Type Safety}
\label{type-safety}
\subsection{Auxiliary Results}
We will start this section with auxiliary results which are needed to prove two main theorems: subject congruence (\autoref{thm:subject-congruence}) and subject reduction (\autoref{thm:subject-reduction}) for our \picalc{} with leftovers.

\paragraph*{Framing}
This property asserts that the well-typedness of a process is independent of its leftover resources.

\begin{nitheorem}[Framing]
  \label{thm:framing}
  Let $P$ be well typed in $\types{\gamma}{\Gamma_l}{P}{\Xi_l}$.
  Let $\Delta$ be such that $\opctx{\Gamma_l}{\Delta}{\Xi_l}$.
  Let $\Gamma_r$ and $\Xi_r$ be arbitrary contexts such that $\opctx{\Gamma_r}{\Delta}{\Xi_r}$.
  Then $\types{\gamma}{\Gamma_r}{P}{\Xi_r}$.
\end{nitheorem}

\paragraph*{Weakening}
This property states that inserting a new variable into the context preserves the well-typedness of a process as long as the usage annotation of the inserted variable is preserved as a leftover.
Let $\func{ins}_i$ insert an element into a context at position $i$ --- for simplicity, we use it both to insert types into typing contexts and usage annotations into usage contexts.
\begin{nitheorem}[Weakening]
  \label{thm:weakening}
  Let $P$ be well typed in $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then, lifting every variable greater than or equal to $i$ in $P$ is well typed in
  $\types{\func{ins}_i \; t \; \gamma}{\func{ins}_i \; x \; \Gamma}{\func{lift}_i \; P}{\func{ins}_i \; x \; \Xi}$.
\end{nitheorem}

\paragraph*{Strengthening}
This property states that removing an unused variable preserves the well-typedness of a process.
Let $\func{del}_i$ delete the element at position $i$ from a context --- for simplicity, we use it both to delete types from typing contexts and usage annotations from usage contexts.
\begin{nitheorem}[Strengthening]
  \label{thm:strengthening} 
  Let $P$ be well typed in $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Let $i$ be a variable not in $P$, such that $uP \; : \; \Unused_i \; P$.
  Then lowering every variable greater than $i$ in $P$ is well typed in $\types{\func{del}_i \; \gamma}{\func{del}_i \; \Gamma}{\func{lower}_i \; P \; uP}{\func{del}_i \; \Xi}$.
\end{nitheorem}

\paragraph*{Exchange}
This property states that the exchange of two variables preserves the well-typedness of a process.
We extend $\func{exchange}_i$  introduced in \autoref{structural-congruence} to exchange types in typing contexts and usage annotations in usage contexts.
\begin{nitheorem}[Exchange]
  \label{thm:exchange}
  Let $P$ be well typed in $\types{\gamma}{\Gamma}{P}{\Xi}$.
  Then, $\types{\func{exchange}_i \; \gamma}{\func{exchange}_i \; \Gamma}{\allowbreak \func{exchange}_i \; P}{\func{exchange}_i \; \Xi}$.
\end{nitheorem}

\begin{proof}[Proof]
  All the above theorems are proved by induction on \textsc{Types} and \textsc{VarRef}.
  For details, refer to our mechanisation in Agda \cite{Zalakain2020Agda}.
\end{proof}

\subsection{Towards Subject Reduction}
\paragraph*{Subject Congruence}
This property states that applying structural congruence (\autoref{structural-congruence}) to a well-typed process preserves its well-typedness.
To prove this result, we must first introduce lemmas that establish that certain syntactic manipulations can be inverted (\autoref{lm:lower-lift}, \autoref{lm:exchange-exchange}) and how unused variables relate to the preservation of leftovers (\autoref{lm:types-unused}).

\begin{nilemma}
  \label{lm:lower-lift}
  The function $\func{lower}_i \; P \; uP$ has an inverse $\func{lift}_i \; P$ that increments every $\textsc{Var}$ greater than or equal to $i$, such that $\func{lift}_i \; (\func{lower}_i \; P \; uP) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\begin{nilemma}
  \label{lm:exchange-exchange}
  The function $\func{exchange}_i \; P$ is its own inverse: $\func{exchange}_i \; (\func{exchange}_i \; P) \equiv P$.
\end{nilemma}
\begin{proof}
  By structural induction on \textsc{Process} and \textsc{Var}.
\end{proof}

\begin{nilemma}
  \label{lm:types-unused}
  For all well-typed processes $\types{\gamma}{\Gamma}{P}{\Xi}$, if the variable $i$ is unused within $P$, then $\Gamma$ at $i$ is equivalent to $\Xi$ at $i$.
\end{nilemma}
\begin{proof}
  By induction on \textsc{Process} and \textsc{Var}.
\end{proof}

We are now in a position to prove subject congruence.

\begin{nitheorem}[Subject congruence]
  \label{thm:subject-congruence}
  If $P \eq{} Q$ and $\types{\gamma}{\Gamma}{P}{\Xi}$, then $\types{\gamma}{\Gamma}{Q}{\Xi}$.
\end{nitheorem}

\begin{proof}[Proof]
  The proof is by induction on \textsc{Equals} $\eq{}$.
  Here we only consider those cases that are not purely inductive: the base cases for $\constr{struct}$ and their symmetric variants.
  Full proof in \cite{Zalakain2020Agda}.
  We proceed by induction on \textsc{StructCong} $\eqeq$:
  \begin{itemize}
    \item
      Case $\constr{comp-assoc}$: trivial, as leftover typing is naturally associative.
    \item
      Case $\constr{comp-sym}$ for $\comp{P}{Q}$: we use framing (\autoref{thm:framing}) to shift the output context of $P$ to the one of $Q$; and the input context of $Q$ to the one of $P$.
    \item
      Case $\constr{comp-end}$: trivial, as the typing rule for $\PO$ has the same input and output contexts.
    \item
      Case $\constr{scope-end}$: we show that the usage annotation of the newly created channel must be $\lz$, making the proof trivial.
      In the opposite direction, we instantiate the newly created channel to a type $\unit$ and a usage annotation $\lz$.
    \item
      Case $\constr{scope-ext}$ for $\new \comp{P}{Q}$: we to show that $P$ preserves the usage annotations of the unused variable (\autoref{lm:types-unused}) and then use strengthening (\autoref{thm:strengthening}).
      In the reverse direction, we use weakening (\autoref{thm:weakening}) on $P$ and show that lowering and then lifting $P$ results in $P$ (\autoref{lm:lower-lift}).
    \item
      Case $\constr{scope-comm}$:
      we use exchange (\autoref{thm:exchange}), and for the reverse direction exchange and \autoref{lm:exchange-exchange} to show that exchanging two elements in $P$ twice leaves $P$ unchanged. \qedhere
  \end{itemize}
\end{proof}

\paragraph*{Substitution}
This result is key to proving subject reduction.
In \autoref{thm:substitution-generalization} we prove a generalised version of substitution, where the substitition $\subst{P}{j}{i}$ is on any variable $i$.
Then, in \autoref{thm:substitution} we instantiate the generalised version to the concrete case where $i$ is the most recently introduced variable $\constr{0}$, as required by subject reduction.

\begin{nitheorem}[Generalised substitution]
  \label{thm:substitution-generalization}
  Let process $P$ be well typed in $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$.
  Then, there must exist some $\Gamma$, $\Psi$, $\Gamma_j$ and $\Psi_j$ such that:
  \begin{multicols}{2}
  \begin{itemize}
    \item $\contains{\gamma}{\Gamma_i}{i}{t}{m}{\Gamma}$
    \item $\contains{\gamma}{\Gamma_j}{j}{t}{m}{\Gamma}$
    \item $\contains{\gamma}{\Psi_i}{i}{t}{n}{\Psi}$
    \item $\contains{\gamma}{\Psi_j}{j}{t}{n}{\Psi}$
  \end{itemize}
  \end{multicols}
  Let $\Gamma$ and $\Psi$ be such that $\opctx{\Gamma}{\Delta}{\Psi}$ for some $\Delta$.
  Let $\Delta$ at position $i$ have usage $\lz$, meaning all consumption from $m$ to $n$ must happen in $P$.
  Then substituting $i$ to $j$ in $P$ will be well typed in $\types{\gamma}{\Gamma_j}{\subst{P}{j}{i}}{\Psi_j}$.
\end{nitheorem}

\begin{proof}[Proof]
  By induction on $\types{\gamma}{\Gamma_i}{P}{\Psi_i}$.
  Full proof can be found in \autoref{app:substitution-generalization}.
  \begin{itemize}
   \item
     Constructor $\PO$: observe that $\Gamma_i \equiv \Psi_i$ and thus $\Gamma_j \equiv \Psi_j$.
   \item
     Constructor $\new$: we proceed inductively.
   \item
     Constructors $\recv{}{}$, $\send{}{}$ and $\comp{}{}$: we must find $\Theta$ in \autoref{fig:subst} and split the diagram along its vertical axis to proceed by induction. \qedhere
 \end{itemize}
\end{proof}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,4)   {$\Gamma_i$};
      \node (gamma-m) at (0,2)   {$\Gamma$};
      \node (gamma-j) at (0,0)   {$\Gamma_j$};
      \node (xi-i)    at (3,3.5) {$\Xi_i$};
      \node (theta)   at (3,2.3) {$\Theta$};
      \node (delta-m) at (3,1.7) {};
      \node (xi-j)    at (3,0.5) {$\Xi_j$};
      \node (psi-i)   at (6,3)   {$\Psi_i$};
      \node (psi-m)   at (6,2)   {$\Psi$};
      \node (psi-j)   at (6,1)   {$\Psi_j$};

      \draw[-]  (gamma-m) -- (delta-m.center);
      \draw[->] (delta-m.center) -- node[align=center,below] {$\Delta$\\$\Delta_i = \lz$}(psi-m);

      \draw[->,densely dotted] (gamma-m) -- (theta);
      \draw[->,densely dotted] (theta) -- (psi-m);
      
      \draw[->] (gamma-i) -- node[left] {$\ni_i m$} (gamma-m);
      \draw[->] (gamma-j) -- node[left] {$\ni_j m$} (gamma-m);
      \draw[->] (psi-i) -- node[right] {$\ni_i n$} (psi-m);
      \draw[->] (psi-j) -- node[right] {$\ni_j n$} (psi-m);

      \draw[->] (gamma-i) -- node[above] {$\vdash P$} (xi-i);
      \draw[->] (xi-i) -- node[above] {$\vdash Q$} (psi-i);
      \draw[->,densely dotted] (gamma-j) -- node[below] {$\vdash \subst{P}{j}{i}$} (xi-j);
      \draw[->,densely dotted] (xi-j) -- node[below] {$\vdash \subst{Q}{j}{i}$} (psi-j);
      \draw[->,densely dotted] (xi-i) -- node[left] {$\ni_i l$} (theta);
      \draw[->,densely dotted] (xi-j) -- node[left] {$\ni_j l$} (theta);
    \end{tikzpicture}
    \caption{
      Diagrammatic representation of the $\comp{}{}$ case for substitution.
      Continuous lines represent known facts, dotted lines proof obligations.
    }
    \label{fig:subst}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \node (gamma-i) at (0,2)   {};
      \node (gamma-m) at (0,1)   {};
      \node (gamma-j) at (0,0)   {};
      \node (xi-i)    at (2,3)   {};
      \node (xi-m)    at (2,2) {};
      \node (xi-j)    at (2,1)   {};
      \node (psi-m)   at (4,2) {};

      \draw[->] (gamma-i) -- (xi-j);
      \draw[->] (gamma-m) -- (xi-j);
      \draw[->,densely dotted] (gamma-j) -- (xi-j);
      \draw[->] (gamma-i) -- (gamma-m);
      \draw[->] (gamma-j) -- (gamma-m);
      \draw[->] (xi-i)    -- (xi-m);
      \draw[->] (xi-j)    -- (xi-m);
      \draw[->] (xi-i)    -- (psi-m);
      \draw[->] (xi-m)    -- (psi-m);
      \draw[->,densely dotted] (xi-j)    -- (psi-m);
    \end{tikzpicture}
    \caption{
      Alternative approach without arrows $\ni_i n$ and $\ni_j n$.
      This approach makes composing typing derivations before and after subsitution more difficult.
    }
    \label{fig:subst-alternative}
\end{figure}

\begin{nitheorem}[Substitution]
  \label{thm:substitution}
  Let process $P$ be well typed in $\types{\gamma \comma t}{\Gamma \comma m}{P}{\Psi \comma \lz}$.
  Let $\contains{\gamma}{\Psi}{j}{t}{m}{\Xi}$.
  Then, we can substitute the variable references to $\constr{0}$ in $P$ with $\suc j$ so that the result is well typed in $\types{\gamma \comma t}{\Gamma \comma m}{\subst{P}{\suc j}{\constr{0}}}{\Xi \comma m}$.
\end{nitheorem}
\begin{proof}[Proof]
  For $\contains{\gamma}{\Gamma}{j}{t}{m}{\Theta}$ and $\types{\gamma \comma t}{\Theta \comma m}{P}{\Xi \comma \lz}$ for some $\Theta$, we use framing to derive them.
  Then, we use these to apply \autoref{thm:substitution-generalization}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

% \begin{note}
  We use $\containsusage{\Gamma}{i}{x}{\Delta}$ to stand for $\contains{\gamma}{\Gamma}{i}{t}{x}{\Delta}$ for some $\gamma$ and $t$.
% \end{note}

\paragraph*{Subject Reduction}
Finally we are ready to present our main result, stating  that if $P$ is well typed and it reduces to $Q$, then $Q$ is well typed.
The relation between the typing contexts used to type $P$ and $Q$ will be explained in \autoref{thm:subject-reduction}.
In the \picalc{} we distinguish between a reduction $P \reduce{\constr{internal}} Q$ on a channel internal to $P$, and a reduction $P \reduce{\constr{external} \; i} Q$ on a channel $i$ external to $P$ (refer to \autoref{operational-semantics}).
We first introduce an auxiliary lemma:

\begin{nilemma}
  \label{lm:comm-capable}
  Every input usage context $\Gamma$ of a well-typed process $\types{\gamma}{\Gamma}{P}{\Delta}$ that reduces by communicating on a channel external (that is, $P \reduce{\constr{external} \; i} Q$ for some $Q$) has a multiplicity of at least $\lio$ at index $i$.
\end{nilemma}

\begin{proof}
  By induction on the reduction derivation $P \reduce{\constr{external \; i}}Q$.
\end{proof}

\begin{nitheorem}[Subject reduction]
  \label{thm:subject-reduction}
  Let $P$ be well typed in $\types{\gamma}{\Gamma}{P}{\Xi}$ and reduce such that $P \reduce{c} Q$.
  \begin{itemize}
    \item If $c$ is $\constr{internal}$, then $\types{\gamma}{\Gamma}{Q}{\Xi}$.
    \item If $c$ is $\constr{external} \; i$ and $\containsusage{\Gamma}{i}{\lio}{\Delta}$, then $\types{\gamma}{\Delta}{Q}{\Xi}$.
  \end{itemize}
\end{nitheorem}

\begin{proof}[Proof]
  By induction on $P \reduce{c} Q$. For the full details refer to our mechanisation in Agda.  
  \begin{itemize}
    \item
    Case $\constr{comm}$: we apply framing (\autoref{thm:framing}) (to rearrange the assumptions), substitution (\autoref{thm:substitution}) and strengthening (\autoref{thm:strengthening}).
  
    \item
    Case $\constr{par}$: by induction on the process that is being reduced.

    \item
    Case $\constr{res}$: case split on channel $c$:
    if $\constr{internal}$ proceed inductively;
    if $\constr{external}\; \constr{0}$ (i.e. the channel introduced by scope restriction) use \autoref{lm:comm-capable} to subtract $\lio$ from the channel's usage annotation and proceed inductively;
    if $\constr{external}\; (\suc i)$ proceed inductively.

    \item
    Case $\constr{struct}$: we apply subject congruence (\autoref{thm:subject-congruence}) and proceed inductively. \qedhere
  \end{itemize}
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\paragraph*{Extrinsic Encodings}

Extrinsic encodings define a syntax (often well-scoped) and a runtime semantics prior to any type system.
This allows one to talk about ill-typed terms, and defers the proof of subject reduction to a later stage.

To the best of our knowledge, leftover typing makes its appearance in 1994, when Ian Mackie first uses it to formulate intuitionistic linear logic \cite{Mackie}.
Allais \cite{Allais2018a} uses leftover typing to mechanise in Agda a bidirectional type system for the linear \lambdacalc{}.
He proves type preservation and provides a decision procedure for type checking and type inference.
In this paper, we follow Allais \cite{Allais2018a} and apply leftover typing to the \picalc{} for the first time.
We generalise the usage algebra, leading to linear, graded and shared type systems.
Drawing from quantitative type theory (by McBride and Atkey \cite{McBride2016, Atkey2018}), in our work we too are able to talk about fully consumed resources --- e.g., we can transmit $\lz$ multiplicities of a fully exhausted channel.

Recent years have seen an increase in the efforts to mechanise resource-aware process algebras, but one of the earliest works is the mechanisation of the linear \picalc{} in Isabelle/HOL by Gay \cite{Gay2001}.
Gay encodes the \picalc{} with linear and shared types using de Bruijn indices, a reduction relation and a type system posterior to the syntax.
However, in his work typing rules demand user-provided context splits, and variables with consumed usage annotations are erased from context.
We remove the demand for context splits, preserve the ability to talk about consumed resources, and adopt a more general usage algebra.

Orchard et al. introduce Granule \cite{Orchard}, a fully-fledged functional language with graded modal types, linear types, indexed types and polymorphism.
Modalities include exact usages, security levels and intervals; resource algebras are pre-ordered semirings with partial addition.
The authors provide bidirectional typing rules, and show the type safety of their semantics.

The work by Goto et al. \cite{Goto2016a} is, to the best of our knowledge, the first formalisation of session types which comes along with a mechanised proof of type safety in Coq.
The authors extend session types with polymorphism and pattern matching.
They use a locally-nameless encoding for variable references, a syntax prior to types, and an LTS semantics that encodes session-typed processes into the \picalc{}.
Their type system uses reordering of contexts and extrinsic context splits, which are not needed in our work. 

\paragraph*{Intrinsic Encodings}
 
Intrinsic encodings merge syntax and type system.
As a result, one can only ever talk about well-typed terms, and the reduction relation by construction carries a proof of subject reduction.
Significantly, by merging the syntax and static semantics of the object language one can fully use the expressive power of the host language.

Thiemann formalises in Agda the MicroSession (minimal GV \cite{Gay2010}) calculus with support for recursion and subtyping \cite{Thiemann2019}.
As Gay does \cite{Gay2001}, context splits are given extrinsically, and exhausted resources are removed from typing contexts altogether.
The runtime semantics are given as an intrinsically typed CEK machine with a global context of session-typed channels.

In their recent paper, Ciccone and Padovani mechanise a dependently-typed linear \picalc{} in Agda \cite{Ciccone}.
Their intrinsic encoding allows them to leverage Agda's dependent types to provide a dependently-typed interpretation of messages --- to avoid linearity violations the interpretation of channel types is erased.
Message input is modeled as a dependent function in Agda, and as a result message predicates, branching, and variable-length conversations can be encoded.
In contrast to our work, their algebra is on the multiplicities $0$, $1$, $\omega$, and top-down context splitting proofs must be provided.

In another recent work, Rouvoet et al. provide an intrinsic type system for a \lambdacalc{} with session types \cite{Rouvoet2020}.
They use proof relevant separation logic and a notion of a supply and demand \emph{market} to make context splits transparent to the user.
Their separation logic is based on a partial commutative monoid that need not be deterministic nor cancellative.
Their typing rules preserve the balance between supply and demand, and are extremely elegant.
They distill their typing rules even further by modelling the supply and demand market as a state monad.

\paragraph*{Other Work}

Castro et al. \cite{Castro2020} provide tooling for locally-nameless representations of process calculi in Coq, where de Bruijn indices are not as popular as in Agda or Idris.
As a use-case, they use their tool to help automate proofs of subject reduction for a type system with session types.

Orchard and Yoshida \cite{OrchardY16} embed a small effectul imperative language into the session-typed \picalc{}, showing that session types are expressive enough to encode effect systems.

Based on contextual type theory \cite{Pientkaa, Pientka}, LINCX \cite{Georges2017} extends the linear logical framework LLF \cite{Cervesato1996} by internalising the notion of bindings and contexts.
The result is a meta-theory in which HOAS encodings with both linear and dependent types can be described.
The developer obtains for free an equational theory of substitution and decidable typechecking without having to encode context splits within the object language.

Further work on mechanising the \picalc{} \cite{Henry-Gerard1999, Honsell2001a, Bengtson2013, Despeyroux2000, Affeldt2008}, focuses on non-linear variations, whereas we present a range of linear, graded and shared types.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Conclusion and Future Work}

In this paper we provide a well-scoped syntax and a semantics for the \picalc{}, extrinsically define a type system on top of the syntax capable of handling linear, graded and shared types under the same unified framework and show that reduction preserves the well-typedness of processes.
We avoid the need for extrinsic context splits by defining a type system based on leftover typing \cite{Allais2018a}, which is defined here for the first time for the \picalc{}.
As a result, theorems like framing, weakening and strengthening can now be stated for the linear \picalc{}.
Our work is fully mechanised in around 1850 lines of code in Agda \cite{Zalakain2020Agda}.

As future work, we intend to prove further properties of our type system, such as that reduction preserves the balancing of channels.
We intend to add support for products, sum types and recursion to both our syntax and our type system.
Orthogonally, making our typing rules bidirectional would allow us to provide a decision procedure for type checking processes in a given set of algebras.
Furthermore, it might also be worth identifying correspondences between our usage algebra and particular state machines.
Finally, we will use our \picalc{} with leftovers as an underlying framework on top of which we can implement session types and other advanced type theories.

\bibliographystyle{plainurl}
\bibliography{paper}

%%
\appendix
\input{appendix.tex}
\end{document}
