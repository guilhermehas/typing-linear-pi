\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,authorcolumns]{lipics-v2019}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{todonotes}
\usepackage{enumitem}
\setlist{parsep=0pt,listparindent=\parindent}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsbsy}
\usepackage[many]{tcolorbox}
\bibliographystyle{plainurl}

% Inference rules
\usepackage{mathpartir}

% TODO notes -- TODO: remove
\usepackage{todonotes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Typing a linear \picalc}
\author{Uma Zalakain}{University of Glasgow, Scotland}
       {u.zalakain.1@research.gla.ac.uk}{https://orcid.org/0000-0002-3268-9338}{}
\author{Ornela Dardha}{University of Glasgow, Scotland}
       {ornela.dardha@glasgow.ac.uk}{https://orcid.org/0000-0001-9927-7875}{}
\authorrunning{U. Zalakain and O. Dardha}
\Copyright{Uma Zalakain and Ornela Dardha}
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003752.10003753.10003761.10003764</concept_id>
<concept_desc>Theory of computation~Process calculi</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
\ccsdesc[300]{Theory of computation~Process calculi}
\keywords{pi calculus, linear, types, concurrency}
\supplement{\url{https://github/umazalakain/typing-linear-pi}}
\acknowledgements{I want to thank \dots}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Processes
\newcommand{\PO}{\mathbf{0}}
\newcommand{\comp}[2]{#1 \parallel #2}
\newcommand{\new}{\boldsymbol{\nu} \,}
\newcommand{\send}[2]{#1 \, \langle#2\rangle \,}
\newcommand{\recv}[1]{#1 \, \mathbb{()} \,}

\newcommand{\subst}[3]{#1[#2/#3]}
\newcommand{\lamcalc}{$\lambda$-calculus}
\newcommand{\picalc}{$\pi$-calculus}
\newcommand{\Picalc}{$\pi$-Calculus}
\newcommand{\reduce}{\longrightarrow}
\newcommand{\types}[4]{#1 \propto #2 \vdash #3 \boxtimes #4}
\newcommand{\contains}[5]{#1 \propto #2 \ni #3 \propto #4 \boxtimes #5}
\newcommand{\suc}{{\scriptscriptstyle 1+}}
\newcommand{\op}[3]{#1 := #2 \cdot #3}

% Types
\newcommand{\Var}{\mathrm{VAR}}
\newcommand{\Process}{\mathrm{PROCESS}}
\newcommand{\Unused}{\mathrm{UNUSED}}
\newcommand{\PreCtx}{\mathrm{PRECTX}}
\newcommand{\Ctx}{\mathrm{CTX}}
\newcommand{\Type}{\mathrm{TYPE}\;}
\newcommand{\Idx}{\mathrm{IDX}\;}
\newcommand{\Idxs}{\mathrm{IDXS}}
\newcommand{\Carrier}{\mathrm{CARRIER}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Channel}{\mathrm{CHANNEL}}
\newcommand{\Rec}{\mathrm{REC}}
\newcommand{\Quantifier}{\mathrm{QUANTIFIER}}
\newcommand{\Quantifiers}{\mathrm{QUANTIFIERS}}
\newcommand{\constr}[1]{\mathtt{#1}}


\begin{document}

\maketitle
\todo{remove todo notes}

\begin{abstract}
  We present the syntax, operational semantics, and typing rules of a \picalc{} with linear and shared types.
  We use leftover typing \cite{Allais2018a} to encode our typing rules in a way that propagates linearity constraints into process continuations.
  We generalize the algebras on multiplicities using indexed sets of \emph{partial commutative monoids}, allowing the user to choose a mix of linear, affine, gradual and shared typing.
  We provide framing, weakening and strengthening proofs that we then use to prove subject congruence.
  We show that the type system is stable under substitution and prove subject reduction.

  This formalization has been fully mechanized with Agda and is available at \url{https://github.com/umazalakain/typing-linear-pi}.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The \picalc models communication.

why resource-aware typing

extensional typing rules for a given syntax and operational semantics

leftover typing

\subsection{Contribution}

\begin{description}
  \item [Machine verified formalisation of the linear pi calculus]

  \item [Typing with leftovers applied to the pi calculus]

  \item [Abstraction over multiplicities]

  \item [Full formalisation available in Agda]
\end{description}

\subsection{Notation}

\begin{figure}[h]
  \begin{mathpar}
    {\mprset{fraction={===}}
      \inferrule
      { }
      {\N : Set}}

    \inferrule
    { }
    {0 : \N}

    \inferrule
    {n : \N}
    {\suc n : \N}
  \end{mathpar}
  \caption{Notation used in this paper}
\end{figure}

Double rule for type-level definitions.
We omit universe levels for brevity.
Constructors are $\constr{teletyped}$ unless they are symbols.
Some constructors are shared across types. They can however always be disambiguated through the type of the goal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Syntax}

Abstraction is one of the key reasoning tools in a language: it allows for features to be defined over a range of inputs.
Such is the case of the \picalc{} too, where both scope restriction and input introduce abstractions.
The bodies of these constructs must have a way of referring to their argument.
Using names as variable references is a popular option amongst humans.
However, names are cumbersome to mechanize: inserting a new variable into an environment means proving that the name of such variable is different to all other variable names in the environment.
Moreover, to a machine names are of no significance whatsoever.

Machines prefer things they can algorithmically act upon. Like natural numbers!
What does it mean to use a number as a variable reference?
The idea de Bruijn had \cite{} was to use the index $n$ to refer to the variable introduced $n$ binders ago.
The binders themselves introduce no names anymore.
The expression $\lambda g . (\lambda f . f g) g$ in the \lamcalc{} would translate as $\lambda (\lambda 0 1) 0$.
That is, terms at different \emph{depths} must use different indices to refer to the same binding.
Humans find this often confusing.
There is however no reason not to keep the original names bestowed by the humans together with the indices.
Machines can then manipulate references mechanically and still use names to present them to humans.

A variable occurring under $n$ abstractions has $n$ things to refer to.
References outside of that range have no associated meaning.
It is useful to rule out these nonsensical terms syntactically.
In Figure \ref{var} we do so by introducing the indexed family of types $\Var_n$: for all naturals $n$, the type $\Var_n$ has $n$ distinct elements.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Var_n : Set}}

  \inferrule
  {n : \N}
  {0 : \Var_{\suc n}}

  \inferrule
  {x : \Var_n}
  {\suc x : \Var_{\suc n}}
\end{mathpar}
\caption{Types of size $n$}
\label{var}
\end{figure}

Every time we go under a binder, the number of binders a variable might refer to increments by one.
To propagate this information, we index processes according to their \emph{depth}: for all naturals $n$, a process of type $\Process_n$ contains variables that can refer to $n$ distinct elements.
As shown in Figure \ref{process}, we increase the \emph{depth} counter every time we create a new channel or receive some input.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Process_n : Set}}
\end{mathpar}
  
\begin{equation*} \label{pi-calc-syntax}
\begin{split}
  \Process_n ::=& \; \PO_n                    \\
              |& \; \new{} \Process_{\suc n}          \\
              |& \; \comp{\Process_n}{\Process_n}          \\
              |& \; \recv{\Var_n}{}\Process_{\suc n} \\
              |& \; \send{\Var_n}{\Var_n}\Process_n
\end{split}
\end{equation*}
\caption{Well-scoped grammar using de Bruijn indices}
\label{process}
\end{figure}

Unlike with names, using type-level de Bruijn indices makes our syntax well-scoped by construction.
As a consequence, the semantics of our language can be defined on the totality of the syntax.
User-friendliness can still be recovered through a function that converts processes with names into (possibly) processes with indices.
This function would keep track of what index is associated with what name, and would traverse the process recursively, taking note of new binders and substituting variable references.
If the process is ill-scoped, the function would return nothing.
To print things back to the user names can be substituted with an index together with the name.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semantics}

In the \lamcalc{} $\beta$-reduction operates on syntactically adjacent terms.
In the \picalc{} wowever, the syntax introduces unnecessary distinctions
(e.g. semantically parallel composition is defined modulo associativity and commutativity).
There are several ways around this, a structural congruence relation being one of the historical ones.
(Others include labeled transition systems and higher inductive types.)

\subsection{Structural Congruence}

Structural congruence is a congruent equivalence relation on processes.
Any two structurally congruent processes are strongly bisimilar: they are can follow each other's reduction steps \cite{}.
Figure \ref{struct-cong-base} lists the base cases of structural congruence.
The type $\Unused_0 \; Q$ witnesses that index $0$ does not appear nor in the inputs nor in the outputs of process $Q$ --- it does so by traversing $Q$.
The function $lower \; 0 \; Q \; uQ$ traverses $Q$ decrementing every index bigger than $0$.
Finally, $swap \; 0 \; P$ traverses $P$ (scoped under $\suc \suc n$) and swaps variable references $0$ and $\suc 0$.

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    { }
    {P \equiv Q : Set}}

  \inferrule
  { }
  {\constr{comp-assoc} : \comp{P}{\comp{Q}{R}} \equiv \comp{\comp{P}{Q}}{R}}

  \inferrule
  { }
  {\constr{comp-sym} : \comp{P}{Q} \equiv \comp{Q}{P}}
  
  \inferrule
  { }
  {\constr{comp-end} : \comp{P}{\PO_n} \equiv P}
  
  \inferrule
  { }
  {\constr{scope-end} : \new \PO_{\suc n} \equiv \PO_n}
  
  \inferrule
  {uQ : \Unused_0 \, Q}
  {\constr{scope-ext} : \new (\comp{P}{Q}) \equiv \comp{(\new P)}{lower \; 0 \; \; Q \; uQ}}

  \inferrule
  { }
  {\constr{scope-comm} : \new \new P \equiv \new \new swap \; 0 \; P}
\end{mathpar}
\caption{Structural rewriting rules. Premises $P$, $Q$ and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong-base}
\end{figure}

Structural congruence is a congruent equivalence relation ship.
As such, rewrites can happen at any point in a process' recursive definition, and they are closed under reflexivity, symmetry and transitivity as shown in Figure \ref{struct-cong}.
In \S \ref{subject-congruence} we will prove that if two processes $P$ and $Q$ are structurally congruent and $P$ is well-typed, then $Q$ is well-typed.
Specifically, in the case of transitivity we must prove that if $P$ is structurally congruent with $Q$ and $Q$ with $R$, and $P$ is well-typed, then so is $R$.
To do so, we will have to proceed by induction and first get a proof of the well-typedness of $Q$, then use that to reach $R$.
To show that the doubly recursive call terminates we index the equivalence relation $=$ by the type $\Rec$, which models the structure of the recursion.

\begin{figure}[h]
\begin{mathpar}
  \mprset{flushleft}
  
  {\mprset{fraction={===}}
    \inferrule
    { }
    {\Rec : Set}}

  \inferrule
  { }
  {\constr{zero} : \Rec}
  
  \inferrule
  {r : \Rec}
  {\constr{one} \; r : \Rec}

  \inferrule
  {r \; s : \Rec}
  {\constr{two} \; r \; s : \Rec}
  
  {\mprset{fraction={===}}
    \inferrule
    {P \, Q : \Process_n \\ r : \Rec}
    {P =_r Q : Set}}

  \inferrule
  {eq : P \equiv Q}
  {\constr{struct} \; eq : P =_{\constr{zero}} Q}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-scope} \; eq : \new P =_{\constr{one} \; r} \new P'}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-comp} \; eq : \comp{P}{Q} =_{\constr{one} \; r} \comp{P'}{Q}}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-recv} \; eq : \recv{x}P =_{\constr{one} \; r} \recv{x}P'}

  \inferrule
  {eq : P =_r P'}
  {\constr{cong-send} \; eq : \send{x}{y}P =_{\constr{one} \; r} \send{x}{y}P'}

  \inferrule
  { }
  {\constr{refl} : P =_{\constr{zero}} P}

  \inferrule
  {eq : P =_r Q}
  {\constr{sym} \; eq : Q =_{\constr{one} \; r} P}

  \inferrule
  {eq_1 : P =_r Q \\ \; eq_2 : Q =_s R}
  {\constr{trans} \; eq_1 \; eq_2 : P =_{\constr{two} \; r \; s} R}
\end{mathpar}
\caption{Structural rewriting rules lifted to a congruent equivalence relation indexed by a recursion tree.
  Premises $P$, $P'$, $Q$, and $R$ are of type $\Process_n$ where $n$ can be inferred.}
\label{struct-cong}
\end{figure}
  
\subsection{Operational Semantics}

Figure \ref{reduction} models the operational semantics of the \picalc{}.
Processes put in parallel reduce when they communicate over a common variable.
The receiving process substitutes references to its most immediate variable with references to the variable sent by the process doing the output, and is then \emph{lowered} --- all variable references are decreased by one.
Reduction is closed under structural congruence and goes under parallel composition and scope restriction
--- but notably not under input nor output, otherwise the sequencing of actions would not be preserved.
In \S \ref{subject-reduction} we prove that if $P$ reduces to $Q$ and $P$ is well-typed, so is $Q$.
However, this reduction operation is effectful: it consumes the variable over which communication happens.
If this variable is external to $P$ (it resides in its context) then the context in which $Q$ is typed must change.
To keep track of this information, we lift the variable index over which communication occurs to the type level.
Every time we come out of a binder we decrement this variable.
To do so, we make use of a $dec$ function that saturates at $\constr{internal}$ --- as opposed to an $inc$ function that would not.


\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Channel_n : Set}}

  \inferrule
  { }
  {\constr{internal} : \Channel_n}

  \inferrule
  {i : \Var_n}
  {\constr{external} \; i : \Channel_n}

  {\mprset{fraction={===}}
    \inferrule
    {i : \Channel_n \\ P \; Q : \Process_n}
    {P \reduce_i Q : Set}}

  \inferrule
  {i \; j : \Var_n \\ P : \Process_{\suc n} \\ Q : \Process_n \\ uP : \Unused_0 \, P}
  {\constr{comm} : \comp{\recv{i}P}{\send{i}{j}{Q}} \reduce_{external \; i} \comp{lower \; 0 \; \subst{P}{j}{0} \; uP}{Q}}

  \inferrule
  {red : P \reduce_i P'}
  {\constr{par} \; red : \comp{P}{Q} \reduce_i \comp{P'}{Q}}

  \inferrule
  {red : P \reduce_i Q}
  {\constr{res} \; red : \new P \reduce_{dec\; i} \new Q}

  \inferrule
  {eq : P = P' \\ red : P' \reduce_i Q}
  {\constr{struct} \; eq \; red : P \reduce_i Q}
\end{mathpar}
\caption{Operational semantics indexed by the channel over which reduction occurs.}
\label{reduction}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resource-aware Typing System}

\subsection{Multiplicities}

A type system with both linear and shared resources has multiplicities $0$, $1$ and $\omega$.

\begin{figure}[h]
\begin{equation}
\begin{split}
  \constr{0\cdot}          &: C \\
  \constr{+\cdot}          &: C \\
  \constr{-\cdot}          &: C \\
  \constr{\op{\_}{\_}{\_}} &: C \to C \to C \to Set \\
  \constr{1\cdot}          &: C \\
  \constr{\cdot-join}      &: \forall \{x y z\} \to \op{x}{y}{+\cdot} \to \op{x}{z}{-\cdot} \to \exists w . (\op{x}{w}{1\cdot}) \\
  \constr{\cdot-compute}   &: \forall y z \to Dec (\exists x . (\op{x}{y}{z})) \\
  \constr{\cdot-compute^l} &: \forall x z \to Dec (\exists y . (\op{x}{y}{z})) \\
  \constr{\cdot-unique}    &: \forall \{x x' y z\} \to \op{x'}{y}{z} \to \op{x}{y}{z} \to x' \equiv x \\
  \constr{\cdot-unique^l}  &: \forall \{x y y' z\} \to \op{x}{y'}{z} \to \op{x}{y}{z} \to y' \equiv y \\
  \constr{\cdot-id^l}      &: \forall x \to \op{x}{0\cdot}{x} \\
  \constr{\cdot-comm}      &: \forall \{x y z\} \to \op{x}{y}{z} \to \op{x}{z}{y} \\
  \constr{\cdot-assoc}     &: \forall \{x y z u v\} \to \op{x}{y}{z} \to \op{y}{u}{v} \to \exists w . (\op{x}{u}{w} \times \op{w}{v}{z})
\end{split}
\end{equation}
\caption{Partial commutative monoid}
\end{figure}
\todo{alignment, get rid of $1\cdot$, $\cdot-join$, $\cdot-compute^l$}

\begin{figure}[h]
\begin{equation}
\begin{split}
  \constr{\Idx}          &: Set \\
  \constr{\exists \Idx}  &: Idx \\
  \constr{\Carrier}      &: \Idx \to Set \\
  \constr{\Quantifiers}  &: \forall i : \Idx \to \Quantifier_{\Carrier_i}
\end{split}
\end{equation}
\caption{Indexed set of partial commutative monoids}
\end{figure}

\subsubsection{Example Type Systems}

Shared. Gradual. Affine. Linear.

\subsection{Contexts}

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\PreCtx_n : Set}
  }

  \inferrule
  { }
  {[] : \PreCtx_0}

  \inferrule
  {\gamma : \PreCtx_n \\ t : \Type}
  {\gamma , t : \PreCtx_{\suc n}}
\end{mathpar}
\caption{This is...}
\end{figure}
  
\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule
    {n : \N}
    {\Idxs_n : Set}}

  \inferrule
  { }
  {[] : \Idxs_0}

  \inferrule
  {is : \Idxs_n \\ i : \Idx}
  {is , i : \Idxs_{\suc n}}

  \\
  
  {\mprset{fraction={===}}
    \inferrule
    {is : \Idxs_n}
    {\Ctx_{is} : Set}}
  
  \inferrule
  { }
  {[] : Ctx_{[]}}
  
  \inferrule
  {\Gamma : \Ctx_{is} \\ x : \Carrier_i}
  {\Gamma , x : \Ctx_{is , i}}
\end{mathpar}
\caption{This is...}
\end{figure}
two-layered approach: types on one hand, capabilities on the other
removing from context vs keeping in context but marking it used

\subsection{Typing with Leftovers}

Variable references as proofs of capability

Context splits at each variable reference

\begin{figure}[h]
\begin{mathpar}
  {\mprset{fraction={===}}
    \inferrule{
      \gamma : \PreCtx_n \\
      \inferrule*{}{
        is : \Idxs_n \\\\
        \Gamma : \Ctx_{is}} \\
      t : \Type \\
      x : \Carrier_i \\
      \Delta : \Ctx_{is}}
    {\contains{\gamma}{\Gamma}{t}{x}{\Delta} : Set}}

  \inferrule
  {\Gamma : \Ctx_{is} \\ y \; z : \Carrier_i \\ True (\constr{\cdot-compute} \; y \; z)}
  {\constr{zero} : \contains{\gamma , t}{\Gamma , x}{t}{y}{\Gamma , z}}
  
  \inferrule
  {\Gamma : \Ctx_{is} \\ x : \Carrier_i \\ x' : \Carrier_j \\ \Delta : \Ctx_{is} \\\\
    loc_x : \contains{\gamma}{\Gamma}{t}{x}{\Delta}}
  {\constr{suc} \; loc_x : \contains{\gamma , t}{\Gamma , x'}{t}{x}{\Delta , x'}}
\end{mathpar}
\caption{This is...}
\end{figure}

\begin{figure}[h]
\begin{mathpar}
  \mprset{flushleft}
  
  {\mprset{fraction={===}}
    \inferrule{
      \gamma : \PreCtx_n \\
      \inferrule*{}{
        is : \Idxs_n \\\\
        \Gamma : \Ctx_{is}} \\
      P : \Process_n \\
      \Delta : \Ctx_{is}}
    {\types{\gamma}{\Gamma}{P}{\Delta} : Set}}
  
  \inferrule
  { }
  {\constr{end} : \types{\gamma}{\Gamma}{\PO}{\Gamma}}

  \inferrule
  {t : \Type \\ x : \Carrier_i \\ y : \Carrier_j \\\\
   cont : \types{\gamma , C[ t \propto x ]}{\Gamma , y}{P}{\Delta , 0.}}
  {\constr{chan} \; t \; x \; y : \types{\gamma}{\Gamma}{\new P}{\Delta}}

  \inferrule
  {chan_x : \contains{\gamma}{\Gamma}{C[ t \propto x]}{+\cdot}{\Xi} \\\\
   cont : \types{\gamma , t}{\Xi , x}{P}{\Theta , 0\cdot}}
  {\constr{recv} \; chan_x \; cont : \types{\gamma}{\Gamma}{\recv{toFin \; chan_x}{P}}{\Theta}}

  \inferrule
  {chan_x : \contains{\gamma}{\Gamma}{C[t \propto x]}{-\cdot}{\Delta} \\\\
   loc_y : \contains{\gamma}{\Delta}{t}{x}{\Xi} \\\\
   cont : \types{\gamma}{\Xi}{P}{\Theta}}
  {\constr{send} \; chan_x \; loc_y \; cont : \types{\gamma}{\Gamma}{\send{toFin \; chan_x}{toFin \; loc_y}P}{\Theta}}

  \inferrule
  {l : \types{\gamma}{\Gamma}{P}{\Delta} \\\\
   r : \types{\gamma}{\Delta}{Q}{\Xi}}
  {\constr{comp} \; l \; r : \types{\gamma}{\Gamma}{\comp{P}{Q}}{\Xi}}
\end{mathpar}
\caption{This is...}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Subject Reduction}\label{subject-reduction}

\subsection{Framing}


\subsection{Weakening}

Order preserving embeddings model a series of insertions. We only ever need one insertion to prove subject congruence, but there is no loss of generality.

\subsection{Strengthening}

\subsection{Swapping}

\subsection{Subject Congruence}\label{subject-congruence}

\subsection{Substitution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}

\cite{previous-work} polymorphic tokens, HOAS

\cite{typing-with-leftovers}

\cite{Higher-inductive-types-for-congruence}

\cite{LTS-semantics}

\cite{work-on-session-types}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}

Work that will be done time permiting:

\begin{description}

\item [Affine types]
  
\item [Proof of progress]

\item [Product types]

\item [Sum types]

\item [Decidable typechecking]

\item [Soundness and completeness with respect to an alternative formalization.]

\item [Encoding of session types]

\end{description}


\bibliography{paper}
\end{document}
